{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6765a8f0-fb11-4b72-a14b-013271277ea7",
   "metadata": {},
   "source": [
    "## Baseline training - Models only using metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78587da1-c87f-4db0-b78e-d67b5281ff02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import mode\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from confidenceinterval import roc_auc_score, accuracy_score\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12efbc58-f382-4d4d-ae70-3a2583d055c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############################\n",
    "## Load data\n",
    "############################\n",
    "\n",
    "df_train = pd.read_csv('train_ids_labels_with_covars_all.csv')\n",
    "df_val = pd.read_csv('val_ids_labels_with_covars_all.csv')\n",
    "df_test = pd.read_csv('test_ids_labels_with_covars_all.csv')\n",
    "df_all = pd.read_csv('all_ids_labels_tested_with_covars_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3174158c-fc74-4959-ba91-8065b7f52895",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>patient_ngsci_id</th>\n",
       "      <th>ecg_id</th>\n",
       "      <th>date</th>\n",
       "      <th>p-r-t_axes</th>\n",
       "      <th>p_axes</th>\n",
       "      <th>r_axes</th>\n",
       "      <th>t_axes</th>\n",
       "      <th>pr_interval</th>\n",
       "      <th>pr_interval_units</th>\n",
       "      <th>...</th>\n",
       "      <th>race_white</th>\n",
       "      <th>race_other</th>\n",
       "      <th>agi_under_25k</th>\n",
       "      <th>agi_25k_to_50k</th>\n",
       "      <th>agi_50k_to_75k</th>\n",
       "      <th>agi_75k_to_100k</th>\n",
       "      <th>agi_100k_to_200k</th>\n",
       "      <th>agi_above_200k</th>\n",
       "      <th>female</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>pat001162d6</td>\n",
       "      <td>ecg162c83f05d</td>\n",
       "      <td>2114-06-21T21:04:34Z</td>\n",
       "      <td>45 59 0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>ms</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.274465</td>\n",
       "      <td>0.181957</td>\n",
       "      <td>0.137615</td>\n",
       "      <td>0.106269</td>\n",
       "      <td>0.212538</td>\n",
       "      <td>0.087156</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>pat001162d6</td>\n",
       "      <td>ecg86065367ee</td>\n",
       "      <td>2114-06-21T21:04:34Z</td>\n",
       "      <td>45 59 0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>ms</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.274465</td>\n",
       "      <td>0.181957</td>\n",
       "      <td>0.137615</td>\n",
       "      <td>0.106269</td>\n",
       "      <td>0.212538</td>\n",
       "      <td>0.087156</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89</td>\n",
       "      <td>pat004815f1</td>\n",
       "      <td>ecgdd0d198786</td>\n",
       "      <td>2112-05-05T08:36:38Z</td>\n",
       "      <td>72 91 40</td>\n",
       "      <td>72.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>ms</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.254731</td>\n",
       "      <td>0.084425</td>\n",
       "      <td>0.061135</td>\n",
       "      <td>0.049491</td>\n",
       "      <td>0.142649</td>\n",
       "      <td>0.407569</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333</td>\n",
       "      <td>pat00bc255b</td>\n",
       "      <td>ecge81f90e55f</td>\n",
       "      <td>2110-03-16T00:48:37Z</td>\n",
       "      <td>21 63 82</td>\n",
       "      <td>21.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>ms</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.283726</td>\n",
       "      <td>0.230193</td>\n",
       "      <td>0.171306</td>\n",
       "      <td>0.110278</td>\n",
       "      <td>0.162741</td>\n",
       "      <td>0.041756</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>523</td>\n",
       "      <td>pat011385ba</td>\n",
       "      <td>ecg7bad30ef89</td>\n",
       "      <td>2112-03-31T15:26:35Z</td>\n",
       "      <td>43 64 48</td>\n",
       "      <td>43.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>ms</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.233711</td>\n",
       "      <td>0.191926</td>\n",
       "      <td>0.157224</td>\n",
       "      <td>0.109065</td>\n",
       "      <td>0.218130</td>\n",
       "      <td>0.089943</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 patient_ngsci_id         ecg_id                  date   \n",
       "0          26      pat001162d6  ecg162c83f05d  2114-06-21T21:04:34Z  \\\n",
       "1          27      pat001162d6  ecg86065367ee  2114-06-21T21:04:34Z   \n",
       "2          89      pat004815f1  ecgdd0d198786  2112-05-05T08:36:38Z   \n",
       "3         333      pat00bc255b  ecge81f90e55f  2110-03-16T00:48:37Z   \n",
       "4         523      pat011385ba  ecg7bad30ef89  2112-03-31T15:26:35Z   \n",
       "\n",
       "  p-r-t_axes  p_axes  r_axes  t_axes  pr_interval pr_interval_units  ...   \n",
       "0    45 59 0    45.0    59.0     0.0        224.0                ms  ...  \\\n",
       "1    45 59 0    45.0    59.0     0.0        224.0                ms  ...   \n",
       "2   72 91 40    72.0    91.0    40.0        144.0                ms  ...   \n",
       "3   21 63 82    21.0    63.0    82.0        166.0                ms  ...   \n",
       "4   43 64 48    43.0    64.0    48.0        162.0                ms  ...   \n",
       "\n",
       "   race_white race_other agi_under_25k  agi_25k_to_50k agi_50k_to_75k   \n",
       "0           1          0      0.274465        0.181957       0.137615  \\\n",
       "1           1          0      0.274465        0.181957       0.137615   \n",
       "2           1          0      0.254731        0.084425       0.061135   \n",
       "3           1          0      0.283726        0.230193       0.171306   \n",
       "4           1          0      0.233711        0.191926       0.157224   \n",
       "\n",
       "   agi_75k_to_100k agi_100k_to_200k  agi_above_200k female  split  \n",
       "0         0.106269         0.212538        0.087156      1  train  \n",
       "1         0.106269         0.212538        0.087156      1  train  \n",
       "2         0.049491         0.142649        0.407569      1  train  \n",
       "3         0.110278         0.162741        0.041756      0  train  \n",
       "4         0.109065         0.218130        0.089943      0  train  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'patient_ngsci_id', 'ecg_id', 'date', 'p-r-t_axes',\n",
      "       'p_axes', 'r_axes', 't_axes', 'pr_interval', 'pr_interval_units',\n",
      "       'qrs_duration', 'qrs_duration_units', 'qtqtc', 'qt_interval',\n",
      "       'qt_interval_units', 'qtc_interval', 'qtc_interval_units', 'vent_rate',\n",
      "       'vent_rate_units', 'has_bbb', 'has_afib', 'has_st', 'has_pacemaker',\n",
      "       'has_lvh', 'has_normal', 'has_normal_ecg', 'has_normal_sinus',\n",
      "       'has_depress', 'has_st_eleva', 'has_twave', 'has_aberran_bbb',\n",
      "       'has_jpoint_repol', 'has_jpoint_eleva', 'has_twave_inver',\n",
      "       'has_twave_abnormal', 'has_nonspecific', 'has_rhythm_disturbance',\n",
      "       'has_prolonged_qt', 'has_lead_reversal', 'has_poor_or_quality',\n",
      "       'ecg_id_new', 'ed_enc_id', 'start_datetime', 'end_datetime',\n",
      "       'age_at_admit', 'macetrop_030_pos', 'death_030_day',\n",
      "       'macetrop_pos_or_death_030', 'stent_010_day', 'cabg_010_day',\n",
      "       'stent_or_cabg_010_day', 'ami_day_of', 'days_to_ami', 'maxtrop_sameday',\n",
      "       'tn_group_sameday', 'disch_disp', 'disch_obs', 'test_010_day',\n",
      "       'stress_010_day', 'cath_010_day', 'days_to_stress', 'days_to_cath',\n",
      "       'first_test', 'excl_flag_c_int', 'excl_flag_chronic', 'excl_flag_death',\n",
      "       'exclude_modeling', 'exclude', 'sex', 'race_black', 'race_hispanic',\n",
      "       'race_white', 'race_other', 'agi_under_25k', 'agi_25k_to_50k',\n",
      "       'agi_50k_to_75k', 'agi_75k_to_100k', 'agi_100k_to_200k',\n",
      "       'agi_above_200k', 'female', 'split'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "display(df_train.head())\n",
    "print(df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e268b13-5ffc-4956-a463-f1ddfd09648b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                     int64\n",
      "patient_ngsci_id              object\n",
      "ecg_id                        object\n",
      "date                          object\n",
      "p-r-t_axes                    object\n",
      "p_axes                       float64\n",
      "r_axes                       float64\n",
      "t_axes                       float64\n",
      "pr_interval                  float64\n",
      "pr_interval_units             object\n",
      "qrs_duration                   int64\n",
      "qrs_duration_units            object\n",
      "qtqtc                         object\n",
      "qt_interval                    int64\n",
      "qt_interval_units             object\n",
      "qtc_interval                   int64\n",
      "qtc_interval_units            object\n",
      "vent_rate                      int64\n",
      "vent_rate_units               object\n",
      "has_bbb                        int64\n",
      "has_afib                       int64\n",
      "has_st                         int64\n",
      "has_pacemaker                  int64\n",
      "has_lvh                        int64\n",
      "has_normal                     int64\n",
      "has_normal_ecg                 int64\n",
      "has_normal_sinus               int64\n",
      "has_depress                    int64\n",
      "has_st_eleva                   int64\n",
      "has_twave                      int64\n",
      "has_aberran_bbb                int64\n",
      "has_jpoint_repol               int64\n",
      "has_jpoint_eleva               int64\n",
      "has_twave_inver                int64\n",
      "has_twave_abnormal             int64\n",
      "has_nonspecific                int64\n",
      "has_rhythm_disturbance         int64\n",
      "has_prolonged_qt               int64\n",
      "has_lead_reversal              int64\n",
      "has_poor_or_quality            int64\n",
      "ecg_id_new                    object\n",
      "ed_enc_id                     object\n",
      "start_datetime                object\n",
      "end_datetime                  object\n",
      "age_at_admit                 float64\n",
      "macetrop_030_pos                bool\n",
      "death_030_day                   bool\n",
      "macetrop_pos_or_death_030       bool\n",
      "stent_010_day                   bool\n",
      "cabg_010_day                    bool\n",
      "stent_or_cabg_010_day           bool\n",
      "ami_day_of                      bool\n",
      "days_to_ami                  float64\n",
      "maxtrop_sameday              float64\n",
      "tn_group_sameday              object\n",
      "disch_disp                    object\n",
      "disch_obs                       bool\n",
      "test_010_day                    bool\n",
      "stress_010_day                  bool\n",
      "cath_010_day                    bool\n",
      "days_to_stress               float64\n",
      "days_to_cath                 float64\n",
      "first_test                    object\n",
      "excl_flag_c_int                 bool\n",
      "excl_flag_chronic               bool\n",
      "excl_flag_death                 bool\n",
      "exclude_modeling                bool\n",
      "exclude                         bool\n",
      "sex                           object\n",
      "race_black                     int64\n",
      "race_hispanic                  int64\n",
      "race_white                     int64\n",
      "race_other                     int64\n",
      "agi_under_25k                float64\n",
      "agi_25k_to_50k               float64\n",
      "agi_50k_to_75k               float64\n",
      "agi_75k_to_100k              float64\n",
      "agi_100k_to_200k             float64\n",
      "agi_above_200k               float64\n",
      "female                         int64\n",
      "split                         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Set the display option to show all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "#print(df_all.isna().sum())\n",
    "print(df_all.dtypes)\n",
    "\n",
    "#Define X and y variables\n",
    "human_waveform_vars = [ 'r_axes',\n",
    "       'qrs_duration',  'qt_interval', #'p-r-t_axes', 'qtqtc',\n",
    "        'qtc_interval',  'vent_rate',\n",
    "        'has_bbb', 'has_afib', 'has_st', 'has_pacemaker',\n",
    "       'has_lvh', 'has_normal', 'has_normal_ecg', 'has_normal_sinus',\n",
    "       'has_depress', 'has_st_eleva', 'has_twave', 'has_aberran_bbb',\n",
    "       'has_jpoint_repol', 'has_jpoint_eleva', 'has_twave_inver',\n",
    "       'has_twave_abnormal', 'has_nonspecific', 'has_rhythm_disturbance',\n",
    "       'has_prolonged_qt', 'has_lead_reversal', 'has_poor_or_quality', 'ste_std_twi'] #'p_axes', 'maxtrop_sameday','vent_rate_units','pr_interval','t_axes',\n",
    "\n",
    "human_waveform_age_sex_vars = [ 'r_axes',\n",
    "       'qrs_duration',  'qt_interval', #'p-r-t_axes', 'qtqtc',\n",
    "        'qtc_interval',  'vent_rate',\n",
    "        'has_bbb', 'has_afib', 'has_st', 'has_pacemaker',\n",
    "       'has_lvh', 'has_normal', 'has_normal_ecg', 'has_normal_sinus',\n",
    "       'has_depress', 'has_st_eleva', 'has_twave', 'has_aberran_bbb',\n",
    "       'has_jpoint_repol', 'has_jpoint_eleva', 'has_twave_inver',\n",
    "       'has_twave_abnormal', 'has_nonspecific', 'has_rhythm_disturbance',\n",
    "       'has_prolonged_qt', 'has_lead_reversal', 'has_poor_or_quality',\n",
    "        'age_at_admit', 'female','ste_std_twi'] #'p_axes', 'maxtrop_sameday','vent_rate_units','pr_interval','t_axes',\n",
    "\n",
    "human_waveform_age_sex_race_vars = [ 'r_axes',\n",
    "       'qrs_duration',  'qt_interval', #'p-r-t_axes', 'qtqtc',\n",
    "        'qtc_interval',  'vent_rate',\n",
    "        'has_bbb', 'has_afib', 'has_st', 'has_pacemaker',\n",
    "       'has_lvh', 'has_normal', 'has_normal_ecg', 'has_normal_sinus',\n",
    "       'has_depress', 'has_st_eleva', 'has_twave', 'has_aberran_bbb',\n",
    "       'has_jpoint_repol', 'has_jpoint_eleva', 'has_twave_inver',\n",
    "       'has_twave_abnormal', 'has_nonspecific', 'has_rhythm_disturbance',\n",
    "       'has_prolonged_qt', 'has_lead_reversal', 'has_poor_or_quality',\n",
    "        'age_at_admit', 'female', 'race_black', 'race_hispanic', 'race_white', 'race_other',\n",
    "        'ste_std_twi'] #'p_axes', 'maxtrop_sameday','vent_rate_units','pr_interval','t_axes',\n",
    "\n",
    "human_waveform_age_sex_race_agi_vars = [ 'r_axes',\n",
    "       'qrs_duration',  'qt_interval', #'p-r-t_axes', 'qtqtc',\n",
    "        'qtc_interval',  'vent_rate',\n",
    "        'has_bbb', 'has_afib', 'has_st', 'has_pacemaker',\n",
    "       'has_lvh', 'has_normal', 'has_normal_ecg', 'has_normal_sinus',\n",
    "       'has_depress', 'has_st_eleva', 'has_twave', 'has_aberran_bbb',\n",
    "       'has_jpoint_repol', 'has_jpoint_eleva', 'has_twave_inver',\n",
    "       'has_twave_abnormal', 'has_nonspecific', 'has_rhythm_disturbance',\n",
    "       'has_prolonged_qt', 'has_lead_reversal', 'has_poor_or_quality',\n",
    "        'age_at_admit', 'female', 'race_black', 'race_hispanic', 'race_white', 'race_other',\n",
    "       'agi_under_25k', 'agi_25k_to_50k', 'agi_50k_to_75k', 'agi_75k_to_100k',\n",
    "       'agi_100k_to_200k', 'agi_above_200k', 'ste_std_twi'] #'p_axes', 'maxtrop_sameday','vent_rate_units','pr_interval','t_axes',\n",
    "\n",
    "human_waveform_age_sex_race_agi_tropt_vars = [ 'r_axes',\n",
    "       'qrs_duration',  'qt_interval', #'p-r-t_axes', 'qtqtc',\n",
    "        'qtc_interval',  'vent_rate',\n",
    "        'has_bbb', 'has_afib', 'has_st', 'has_pacemaker',\n",
    "       'has_lvh', 'has_normal', 'has_normal_ecg', 'has_normal_sinus',\n",
    "       'has_depress', 'has_st_eleva', 'has_twave', 'has_aberran_bbb',\n",
    "       'has_jpoint_repol', 'has_jpoint_eleva', 'has_twave_inver',\n",
    "       'has_twave_abnormal', 'has_nonspecific', 'has_rhythm_disturbance',\n",
    "       'has_prolonged_qt', 'has_lead_reversal', 'has_poor_or_quality',\n",
    "        'age_at_admit', 'female', 'race_black', 'race_hispanic', 'race_white', 'race_other',\n",
    "       'agi_under_25k', 'agi_25k_to_50k', 'agi_50k_to_75k', 'agi_75k_to_100k',\n",
    "       'agi_100k_to_200k', 'agi_above_200k', 'ste_std_twi', 'maxtrop_sameday'] #'p_axes','vent_rate_units','pr_interval','t_axes',\n",
    "\n",
    "human_waveform_age_sex_tropt_vars = [ 'r_axes',\n",
    "       'qrs_duration',  'qt_interval', #'p-r-t_axes', 'qtqtc',\n",
    "        'qtc_interval',  'vent_rate',\n",
    "        'has_bbb', 'has_afib', 'has_st', 'has_pacemaker',\n",
    "       'has_lvh', 'has_normal', 'has_normal_ecg', 'has_normal_sinus',\n",
    "       'has_depress', 'has_st_eleva', 'has_twave', 'has_aberran_bbb',\n",
    "       'has_jpoint_repol', 'has_jpoint_eleva', 'has_twave_inver',\n",
    "       'has_twave_abnormal', 'has_nonspecific', 'has_rhythm_disturbance',\n",
    "       'has_prolonged_qt', 'has_lead_reversal', 'has_poor_or_quality',\n",
    "        'age_at_admit', 'female', 'ste_std_twi', 'maxtrop_sameday'] #'p_axes','vent_rate_units','pr_interval','t_axes',\n",
    "\n",
    "human_waveform_age_sex_race_tropt_vars = [ 'r_axes',\n",
    "       'qrs_duration',  'qt_interval', #'p-r-t_axes', 'qtqtc',\n",
    "        'qtc_interval',  'vent_rate',\n",
    "        'has_bbb', 'has_afib', 'has_st', 'has_pacemaker',\n",
    "       'has_lvh', 'has_normal', 'has_normal_ecg', 'has_normal_sinus',\n",
    "       'has_depress', 'has_st_eleva', 'has_twave', 'has_aberran_bbb',\n",
    "       'has_jpoint_repol', 'has_jpoint_eleva', 'has_twave_inver',\n",
    "       'has_twave_abnormal', 'has_nonspecific', 'has_rhythm_disturbance',\n",
    "       'has_prolonged_qt', 'has_lead_reversal', 'has_poor_or_quality',\n",
    "        'race_black', 'race_hispanic', 'race_white', 'race_other',\n",
    "        'age_at_admit', 'female', 'ste_std_twi', 'maxtrop_sameday'] #'p_axes','vent_rate_units','pr_interval','t_axes',\n",
    "\n",
    "ste = [\n",
    "       'has_depress', 'has_st_eleva', 'has_twave_inver'] #'p_axes','vent_rate_units','pr_interval','t_axes',\n",
    "\n",
    "groundtruth_ami = 'stent_or_cabg_010_day'\n",
    "adverse_event = 'macetrop_pos_or_death_030'\n",
    "\n",
    "# input_spec_list = [human_waveform_vars, human_waveform_age_sex_vars, human_waveform_age_sex_race_vars, \n",
    "#                    human_waveform_age_sex_race_agi_vars, human_waveform_age_sex_race_agi_tropt_vars, human_waveform_age_sex_tropt_vars, human_waveform_age_sex_race_tropt_vars]\n",
    "\n",
    "# input_spec_name = ['human ECG labels', 'human ECG labels + age + sex', 'human ECG labels + age + sex + race', \n",
    "#                    'human ECG labels + age + sex + agi', 'human ECG labels + age + sex + agi + tropt (KNN imputed)', 'human ECG labels + age + sex + tropt (KNN imputed)', \n",
    "#                    'human ECG labels + age + sex + race + tropt (KNN imputed)']\n",
    "\n",
    "# input_spec_list = [human_waveform_vars, human_waveform_age_sex_vars, human_waveform_age_sex_race_vars, \n",
    "#                    human_waveform_age_sex_race_agi_vars, human_waveform_age_sex_race_agi_tropt_vars, human_waveform_age_sex_race_tropt_vars, human_waveform_age_sex_tropt_vars,]\n",
    "\n",
    "# input_spec_name = ['human ECG labels', 'human ECG labels + age + sex', 'human ECG labels + age + sex + race', \n",
    "#                    'human ECG labels + age + sex + agi', 'human ECG labels + age + sex + agi + tropt (KNN imputed)', \n",
    "#                    'human ECG labels + age + sex + race + tropt (KNN imputed)', 'human ECG labels + age + sex + tropt (KNN imputed)']\n",
    "\n",
    "# input_spec_list = [human_waveform_age_sex_vars, human_waveform_age_sex_race_vars, \n",
    "#                    human_waveform_age_sex_race_agi_vars, human_waveform_age_sex_race_agi_tropt_vars, human_waveform_age_sex_tropt_vars, human_waveform_age_sex_race_tropt_vars,\n",
    "#                   human_waveform_vars, ste]\n",
    "\n",
    "input_spec_list = [ste]\n",
    "\n",
    "input_spec_name = ['St elevation, T-wave inversion, ST depression']\n",
    "\n",
    "# relevant_vars = [ 'r_axes',\n",
    "#        'qrs_duration',  'qt_interval',\n",
    "#         'qtc_interval',  'vent_rate',\n",
    "#         'has_bbb', 'has_afib', 'has_st', 'has_pacemaker',\n",
    "#        'has_lvh', 'has_normal', 'has_normal_ecg', 'has_normal_sinus',\n",
    "#        'has_depress', 'has_st_eleva', 'has_twave', 'has_aberran_bbb',\n",
    "#        'has_jpoint_repol', 'has_jpoint_eleva', 'has_twave_inver',\n",
    "#        'has_twave_abnormal', 'has_nonspecific', 'has_rhythm_disturbance',\n",
    "#        'has_prolonged_qt', 'has_lead_reversal', 'has_poor_or_quality',\n",
    "#         'age_at_admit', 'female', 'race_black', 'race_hispanic', 'race_white', 'race_other',\n",
    "#        'agi_under_25k', 'agi_25k_to_50k', 'agi_50k_to_75k', 'agi_75k_to_100k',\n",
    "#        'agi_100k_to_200k', 'agi_above_200k', 'ste_std_twi', 'stent_or_cabg_010_day', 'maxtrop_sameday', 'p_axes'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4a49a5-5173-443e-b1cb-86cb2ba7ce92",
   "metadata": {},
   "source": [
    "## Analysis in tested set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef761e18-883d-415c-b807-7950db287238",
   "metadata": {},
   "source": [
    "### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50ee6eb-14da-474e-83d5-92a1f3746bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables, name = input_spec_list[-1], input_spec_name[-1]\n",
    "\n",
    "print(f\"LASSO: {name}\")\n",
    "\n",
    "if name == 'human ECG labels + age + sex + agi + tropt (KNN imputed)' or 'human ECG labels + age + sex + tropt (KNN imputed)' or 'human ECG labels + age + sex + race + tropt (KNN imputed)':\n",
    "    # Compute the median of the 'maxtrop_sameday' column\n",
    "    median_maxtrop = df_train['maxtrop_sameday'].median()\n",
    "\n",
    "    # Replace missing values with the median\n",
    "    #imputer = SimpleImputer(strategy='median')\n",
    "    imputer = KNNImputer(n_neighbors=5) \n",
    "    df_train_t['maxtrop_sameday'] = imputer.fit_transform(df_train_t[['maxtrop_sameday']])\n",
    "    df_val_t['maxtrop_sameday'] = imputer.transform(df_val_t[['maxtrop_sameday']])\n",
    "\n",
    "variables_incl_y = variables + [adverse_event]\n",
    "\n",
    "df_train_rel = df_train_t[variables_incl_y].dropna()\n",
    "df_val_rel = df_test_t[variables_incl_y].dropna() \n",
    "\n",
    "# Prepare the training data\n",
    "X_train = df_train_rel[variables]\n",
    "y_train = df_train_rel[adverse_event]\n",
    "\n",
    "# Prepare the validation data\n",
    "X_val = df_val_rel[variables]\n",
    "y_val = df_val_rel[adverse_event]\n",
    "\n",
    "# Scale the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Initialize the LASSO Logistic Regression classifier\n",
    "lasso_classifier = LogisticRegression(penalty='l1', solver='liblinear', C=0.07, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "lasso_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "joblib.dump(lasso_classifier, \"structured_feature_logreg_mace.pkl\")\n",
    "\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred = lasso_classifier.predict_proba(X_val_scaled)[:, 1]  # get probabilities for the positive class\n",
    "\n",
    "# # Calculate AUC\n",
    "# auc_score = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "# print(f\"AUC Score on Validation Set: {auc_score}\")\n",
    "\n",
    "auc, ci = roc_auc_score(y_val, y_val_pred,\n",
    "                        confidence_level=0.95)\n",
    "# ,\n",
    "#                         method='bootstrap_bca',\n",
    "#                         n_resamples=1000)\n",
    "    \n",
    "print(f'Test AUC Score: {auc} ({ci[0]}, {ci[1]})')\n",
    "\n",
    "# Step 2: Calculate the optimal threshold using Youden's J statistic\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_val_pred)\n",
    "youden_j = tpr - fpr\n",
    "optimal_idx = np.argmax(youden_j)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# Step 3: Binarize the predictions based on the optimal threshold\n",
    "y_val_class = (y_val_pred >= optimal_threshold).astype(int)\n",
    "\n",
    "acc, ci_acc = accuracy_score(y_val, y_val_class,\n",
    "                    confidence_level=0.95)\n",
    "# ,\n",
    "#                     method='bootstrap_bca',\n",
    "#                     n_resamples=1000)\n",
    "\n",
    "print(f'Test Accuracy Score: {acc} ({ci_acc[0]}, {ci_acc[1]})')\n",
    "\n",
    "df_test_t['preds_ste_sti_twi_logist'] = y_val_pred\n",
    "df_test_t['binary_preds_ste_sti_twi_logist'] = y_val_class\n",
    "df_test_t.to_csv('test_ids_labels_untested_with_covars_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8208a19b-34da-4154-8d17-0769de1b861d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO: St elevation, T-wave inversion, ST depression\n",
      "Test AUC Score: 0.5209991931915283 (0.5123868370868708, 0.5296115492961858)\n",
      "Test Accuracy Score: 0.8771692115274375 (0.8724493045938633, 0.8817381371696147)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SequenceNotStr' from 'pandas._typing' (/opt/venv/default/lib/python3.10/site-packages/pandas/_typing.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 77\u001b[0m\n\u001b[1;32m     75\u001b[0m df_test_t[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds_ste_sti_twi_logist\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_val_pred\n\u001b[1;32m     76\u001b[0m df_test_t[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_preds_ste_sti_twi_logist\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_val_class\n\u001b[0;32m---> 77\u001b[0m \u001b[43mdf_test_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_ids_labels_untested_with_covars_all.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/default/lib/python3.10/site-packages/pandas/core/generic.py:3772\u001b[0m, in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3743\u001b[0m \u001b[38;5;129m@overload\u001b[39m\n\u001b[1;32m   3744\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_csv\u001b[39m(\n\u001b[1;32m   3745\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3766\u001b[0m     storage_options: StorageOptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3767\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m   3768\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m   3770\u001b[0m \u001b[38;5;129m@overload\u001b[39m\n\u001b[1;32m   3771\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_csv\u001b[39m(\n\u001b[0;32m-> 3772\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3773\u001b[0m     path_or_buf: FilePath \u001b[38;5;241m|\u001b[39m WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m|\u001b[39m WriteBuffer[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   3774\u001b[0m     sep: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3775\u001b[0m     na_rep: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3776\u001b[0m     float_format: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m Callable \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3777\u001b[0m     columns: Sequence[Hashable] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3778\u001b[0m     header: bool_t \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3779\u001b[0m     index: bool_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3780\u001b[0m     index_label: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3781\u001b[0m     mode: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3782\u001b[0m     encoding: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3783\u001b[0m     compression: CompressionOptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3784\u001b[0m     quoting: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3785\u001b[0m     quotechar: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3786\u001b[0m     lineterminator: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3787\u001b[0m     chunksize: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3788\u001b[0m     date_format: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3789\u001b[0m     doublequote: bool_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3790\u001b[0m     escapechar: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3791\u001b[0m     decimal: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3792\u001b[0m     errors: OpenFileErrors \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3793\u001b[0m     storage_options: StorageOptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3794\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3795\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m   3797\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(\n\u001b[1;32m   3799\u001b[0m     version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.0\u001b[39m\u001b[38;5;124m\"\u001b[39m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath_or_buf\u001b[39m\u001b[38;5;124m\"\u001b[39m], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3827\u001b[0m     storage_options: StorageOptions \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3828\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/venv/default/lib/python3.10/site-packages/pandas/io/formats/format.py:1159\u001b[0m, in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m digits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1145\u001b[0m     digits \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay.precision\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1147\u001b[0m fmt_obj \u001b[38;5;241m=\u001b[39m fmt_klass(\n\u001b[1;32m   1148\u001b[0m     values,\n\u001b[1;32m   1149\u001b[0m     digits\u001b[38;5;241m=\u001b[39mdigits,\n\u001b[1;32m   1150\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   1151\u001b[0m     float_format\u001b[38;5;241m=\u001b[39mfloat_format,\n\u001b[1;32m   1152\u001b[0m     formatter\u001b[38;5;241m=\u001b[39mformatter,\n\u001b[1;32m   1153\u001b[0m     space\u001b[38;5;241m=\u001b[39mspace,\n\u001b[1;32m   1154\u001b[0m     justify\u001b[38;5;241m=\u001b[39mjustify,\n\u001b[1;32m   1155\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   1156\u001b[0m     leading_space\u001b[38;5;241m=\u001b[39mleading_space,\n\u001b[1;32m   1157\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[1;32m   1158\u001b[0m     fallback_formatter\u001b[38;5;241m=\u001b[39mfallback_formatter,\n\u001b[0;32m-> 1159\u001b[0m )\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fmt_obj\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m/opt/venv/default/lib/python3.10/site-packages/pandas/io/formats/csvs.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m writers \u001b[38;5;28;01mas\u001b[39;00m libwriters\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SequenceNotStr\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cache_readonly\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     ABCDatetimeIndex,\n\u001b[1;32m     29\u001b[0m     ABCIndex,\n\u001b[1;32m     30\u001b[0m     ABCMultiIndex,\n\u001b[1;32m     31\u001b[0m     ABCPeriodIndex,\n\u001b[1;32m     32\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'SequenceNotStr' from 'pandas._typing' (/opt/venv/default/lib/python3.10/site-packages/pandas/_typing.py)"
     ]
    }
   ],
   "source": [
    "# Assuming df_train and df_val are your training and validation DataFrames\n",
    "# input_vars and output are defined as provided\n",
    "\n",
    "for variables, name in zip(input_spec_list, input_spec_name):\n",
    "    \n",
    "    print(f\"LASSO: {name}\")\n",
    "    \n",
    "    if name == 'human ECG labels + age + sex + agi + tropt (KNN imputed)' or 'human ECG labels + age + sex + tropt (KNN imputed)' or 'human ECG labels + age + sex + race + tropt (KNN imputed)':\n",
    "        # Compute the median of the 'maxtrop_sameday' column\n",
    "        median_maxtrop = df_train['maxtrop_sameday'].median()\n",
    "\n",
    "        # Replace missing values with the median\n",
    "        #imputer = SimpleImputer(strategy='median')\n",
    "        imputer = KNNImputer(n_neighbors=5) \n",
    "        df_train['maxtrop_sameday'] = imputer.fit_transform(df_train[['maxtrop_sameday']])\n",
    "        df_val['maxtrop_sameday'] = imputer.transform(df_val[['maxtrop_sameday']])\n",
    "    \n",
    "    variables_incl_y = variables + [groundtruth_ami]\n",
    "    \n",
    "    df_train_rel = df_train[variables_incl_y].dropna()\n",
    "    df_val_rel = df_val[variables_incl_y].dropna() \n",
    "\n",
    "    # Prepare the training data\n",
    "    X_train = df_train_rel[variables]\n",
    "    y_train = df_train_rel[groundtruth_ami]\n",
    "\n",
    "    # Prepare the validation data\n",
    "    X_val = df_val_rel[variables]\n",
    "    y_val = df_val_rel[groundtruth_ami]\n",
    "    \n",
    "    # Scale the data using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Initialize the LASSO Logistic Regression classifier\n",
    "    lasso_classifier = LogisticRegression(penalty='l1', solver='liblinear', C=0.07, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    lasso_classifier.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    joblib.dump(lasso_classifier, \"structured_feature_logreg_acs.pkl\")\n",
    "\n",
    "    # Predict on validation set\n",
    "    y_val_pred = lasso_classifier.predict_proba(X_val_scaled)[:, 1]  # get probabilities for the positive class\n",
    "\n",
    "    # Calculate AUC\n",
    "#     auc_score = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "#     print(f\"AUC Score on Validation Set: {auc_score}\")\n",
    "    \n",
    "    auc, ci = roc_auc_score(y_val, y_val_pred,\n",
    "                        confidence_level=0.95,\n",
    "                        method='bootstrap_bca',\n",
    "                        n_resamples=1000)\n",
    "    \n",
    "    print(f'Test AUC Score: {auc} ({ci[0]}, {ci[1]})')\n",
    "    \n",
    "    # Step 2: Calculate the optimal threshold using Youden's J statistic\n",
    "    fpr, tpr, thresholds = roc_curve(y_val, y_val_pred)\n",
    "    youden_j = tpr - fpr\n",
    "    optimal_idx = np.argmax(youden_j)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "    # Step 3: Binarize the predictions based on the optimal threshold\n",
    "    y_val_class = (y_val_pred >= optimal_threshold).astype(int)\n",
    "    \n",
    "    acc, ci_acc = roc_auc_score(y_val, y_val_class,\n",
    "                        confidence_level=0.95,\n",
    "                        method='bootstrap_bca',\n",
    "                        n_resamples=1000)\n",
    "    \n",
    "    print(f'Test Accuracy Score: {acc} ({ci_acc[0]}, {ci_acc[1]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ea5261-dd1d-4298-8dc4-3c3616e090d0",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "871b26d7-d821-4397-8af9-3782e1833e5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: St elevation, T-wave inversion, ST depression\n",
      "Test AUC Score: 0.5883535271622037 (0.5624532170548846, 0.6160186151969017)\n",
      "Test Accuracy Score: 0.581600751371318 (0.5566160026926681, 0.6077904836131369)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "warnings.filterwarnings(\"ignore\")#category=ConvergenceWarning\n",
    "\n",
    "for variables, name in zip(input_spec_list, input_spec_name):\n",
    "    \n",
    "    print(f\"SVM: {name}\")\n",
    "    \n",
    "    if name == 'human ECG labels + age + sex + agi + tropt (KNN imputed)' or 'human ECG labels + age + sex + tropt (KNN imputed)' or 'human ECG labels + age + sex + race + tropt (KNN imputed)':\n",
    "        # Compute the median of the 'maxtrop_sameday' column\n",
    "        median_maxtrop = df_train['maxtrop_sameday'].median()\n",
    "\n",
    "        # Replace missing values with the median\n",
    "        #imputer = SimpleImputer(strategy='median')\n",
    "        imputer = KNNImputer(n_neighbors=5) \n",
    "        df_train['maxtrop_sameday'] = imputer.fit_transform(df_train[['maxtrop_sameday']])\n",
    "        df_val['maxtrop_sameday'] = imputer.transform(df_val[['maxtrop_sameday']])\n",
    "    \n",
    "    variables_incl_y = variables + [groundtruth_ami]\n",
    "    \n",
    "    df_train_rel = df_train[variables_incl_y].dropna()\n",
    "    df_val_rel = df_val[variables_incl_y].dropna() \n",
    "\n",
    "    # Prepare the training data\n",
    "    X_train = df_train_rel[variables]\n",
    "    y_train = df_train_rel[groundtruth_ami]\n",
    "\n",
    "    # Prepare the validation data\n",
    "    X_val = df_val_rel[variables]\n",
    "    y_val = df_val_rel[groundtruth_ami]\n",
    "    \n",
    "    # Scale the data using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Initialize the Non-Linear Support Vector Machine (SVM) classifier with a kernel (e.g., 'rbf')\n",
    "    svm_classifier = LinearSVC(random_state=42, C=0.05)\n",
    "\n",
    "    # Train the model\n",
    "    svm_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict on validation set\n",
    "    y_val_pred = svm_classifier.decision_function(X_val_scaled)  # get probabilities for non-linear SVM\n",
    "\n",
    "#     # Calculate AUC\n",
    "#     auc_score = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "#     print(f\"AUC Score on Validation Set: {auc_score}\")\n",
    "    \n",
    "    auc, ci = roc_auc_score(y_val, y_val_pred,\n",
    "                        confidence_level=0.95,\n",
    "                        method='bootstrap_bca',\n",
    "                        n_resamples=1000)\n",
    "    \n",
    "    print(f'Test AUC Score: {auc} ({ci[0]}, {ci[1]})')\n",
    "    \n",
    "    # Step 2: Calculate the optimal threshold using Youden's J statistic\n",
    "    fpr, tpr, thresholds = roc_curve(y_val, y_val_pred)\n",
    "    youden_j = tpr - fpr\n",
    "    optimal_idx = np.argmax(youden_j)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "    # Step 3: Binarize the predictions based on the optimal threshold\n",
    "    y_val_class = (y_val_pred >= optimal_threshold).astype(int)\n",
    "    \n",
    "    acc, ci_acc = roc_auc_score(y_val, y_val_class,\n",
    "                        confidence_level=0.95,\n",
    "                        method='bootstrap_bca',\n",
    "                        n_resamples=1000)\n",
    "    \n",
    "    print(f'Test Accuracy Score: {acc} ({ci_acc[0]}, {ci_acc[1]})')\n",
    "\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f610fe0-ce03-401c-bc6c-0f4d199413f6",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7785c15f-31b6-4156-83c4-d581128d1f85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: human ECG labels + age + sex\n",
      "AUC Score on Validation Set: 0.6606830518697225\n",
      "Random Forest: human ECG labels + age + sex + race\n",
      "AUC Score on Validation Set: 0.6428716827503016\n",
      "Random Forest: human ECG labels + age + sex + agi\n",
      "AUC Score on Validation Set: 0.6275250090626519\n",
      "Random Forest: human ECG labels + age + sex + agi + tropt (KNN imputed)\n",
      "AUC Score on Validation Set: 0.7186432246072209\n",
      "Random Forest: human ECG labels + age + sex + tropt (KNN imputed)\n",
      "AUC Score on Validation Set: 0.7353023220747888\n",
      "Random Forest: human ECG labels + age + sex + race + tropt (KNN imputed)\n",
      "AUC Score on Validation Set: 0.7255710946924004\n",
      "Random Forest: human ECG labels\n",
      "AUC Score on Validation Set: 0.6398032267792522\n",
      "Random Forest: St elevation, twi, st depression\n",
      "AUC Score on Validation Set: 0.5688546064535586\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for variables, name in zip(input_spec_list, input_spec_name):\n",
    "    \n",
    "    print(f\"Random Forest: {name}\")\n",
    "    \n",
    "    if name == 'human ECG labels + age + sex + agi + tropt (KNN imputed)' or 'human ECG labels + age + sex + tropt (KNN imputed)' or 'human ECG labels + age + sex + race + tropt (KNN imputed)':\n",
    "        # Compute the median of the 'maxtrop_sameday' column\n",
    "        median_maxtrop = df_train['maxtrop_sameday'].median()\n",
    "\n",
    "        # Replace missing values with the median\n",
    "        #imputer = SimpleImputer(strategy='median')\n",
    "        imputer = KNNImputer(n_neighbors=5) \n",
    "        df_train['maxtrop_sameday'] = imputer.fit_transform(df_train[['maxtrop_sameday']])\n",
    "        df_val['maxtrop_sameday'] = imputer.transform(df_val[['maxtrop_sameday']])\n",
    "    \n",
    "    variables_incl_y = variables + [groundtruth_ami]\n",
    "    \n",
    "    df_train_rel = df_train[variables_incl_y].dropna()\n",
    "    df_val_rel = df_val[variables_incl_y].dropna() \n",
    "\n",
    "    # Prepare the training data\n",
    "    X_train = df_train_rel[variables]\n",
    "    y_train = df_train_rel[groundtruth_ami]\n",
    "\n",
    "    # Prepare the validation data\n",
    "    X_val = df_val_rel[variables]\n",
    "    y_val = df_val_rel[groundtruth_ami]\n",
    "    \n",
    "    # Scale the data using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Initialize the Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=200, min_samples_leaf=75,max_depth=5, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    rf_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict on validation set\n",
    "    y_val_pred = rf_classifier.predict_proba(X_val_scaled)[:, 1]  # get probabilities for the positive class\n",
    "\n",
    "    # Calculate AUC\n",
    "#     auc_score = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "#     print(f\"AUC Score on Validation Set: {auc_score}\")\n",
    "    \n",
    "    auc, ci = roc_auc_score(y_val, y_val_pred,\n",
    "                        confidence_level=0.95,\n",
    "                        method='bootstrap_bca',\n",
    "                        n_resamples=1000)\n",
    "    \n",
    "    print(f'Test AUC Score: {auc} ({ci[0]}, {ci[1]})')\n",
    "    \n",
    "    # Step 2: Calculate the optimal threshold using Youden's J statistic\n",
    "    fpr, tpr, thresholds = roc_curve(y_val, y_val_pred)\n",
    "    youden_j = tpr - fpr\n",
    "    optimal_idx = np.argmax(youden_j)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "    # Step 3: Binarize the predictions based on the optimal threshold\n",
    "    y_val_class = (y_val_pred >= optimal_threshold).astype(int)\n",
    "    \n",
    "    acc, ci_acc = roc_auc_score(y_val, y_val_class,\n",
    "                        confidence_level=0.95,\n",
    "                        method='bootstrap_bca',\n",
    "                        n_resamples=1000)\n",
    "    \n",
    "    print(f'Test Accuracy Score: {acc} ({ci_acc[0]}, {ci_acc[1]})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44610b26-d996-483c-9cc2-039bd653abaa",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "babb9f71-91e7-41f6-ad2b-623f24cc6042",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosted Trees: human ECG labels + age + sex\n",
      "AUC Score on Validation Set: 0.6631992611580217\n",
      "Gradient Boosted Trees: human ECG labels + age + sex + race\n",
      "AUC Score on Validation Set: 0.6610675512665862\n",
      "Gradient Boosted Trees: human ECG labels + age + sex + agi\n",
      "AUC Score on Validation Set: 0.6653278366100283\n",
      "Gradient Boosted Trees: human ECG labels + age + sex + agi + tropt (KNN imputed)\n",
      "AUC Score on Validation Set: 0.7384692216917464\n",
      "Gradient Boosted Trees: human ECG labels + age + sex + tropt (KNN imputed)\n",
      "AUC Score on Validation Set: 0.7596040033172496\n",
      "Gradient Boosted Trees: human ECG labels + age + sex + race + tropt (KNN imputed)\n",
      "AUC Score on Validation Set: 0.759741593787696\n",
      "Gradient Boosted Trees: human ECG labels\n",
      "AUC Score on Validation Set: 0.6176982810615199\n",
      "Gradient Boosted Trees: St elevation, twi, st depression\n",
      "AUC Score on Validation Set: 0.5688376432448734\n"
     ]
    }
   ],
   "source": [
    "for variables, name in zip(input_spec_list, input_spec_name):\n",
    "    \n",
    "    print(f\"Gradient Boosted Trees: {name}\")\n",
    "    \n",
    "    if name == 'human ECG labels + age + sex + agi + tropt (KNN imputed)' or 'human ECG labels + age + sex + tropt (KNN imputed)' or 'human ECG labels + age + sex + race + tropt (KNN imputed)':\n",
    "        # Compute the median of the 'maxtrop_sameday' column\n",
    "        median_maxtrop = df_train['maxtrop_sameday'].median()\n",
    "\n",
    "        # Replace missing values with the median\n",
    "        #imputer = SimpleImputer(strategy='median')\n",
    "        imputer = KNNImputer(n_neighbors=5) \n",
    "        df_train['maxtrop_sameday'] = imputer.fit_transform(df_train[['maxtrop_sameday']])\n",
    "        df_val['maxtrop_sameday'] = imputer.transform(df_val[['maxtrop_sameday']])\n",
    "    \n",
    "    variables_incl_y = variables + [groundtruth_ami]\n",
    "    \n",
    "    df_train_rel = df_train[variables_incl_y].dropna()\n",
    "    df_val_rel = df_val[variables_incl_y].dropna() \n",
    "\n",
    "    # Prepare the training data\n",
    "    X_train = df_train_rel[variables]\n",
    "    y_train = df_train_rel[groundtruth_ami]\n",
    "\n",
    "    # Prepare the validation data\n",
    "    X_val = df_val_rel[variables]\n",
    "    y_val = df_val_rel[groundtruth_ami]\n",
    "    \n",
    "    # Scale the data using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Initialize the Gradient Boosting classifier\n",
    "    gb_classifier = GradientBoostingClassifier( learning_rate=0.02, n_estimators=200, min_samples_leaf=50, max_depth=7, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    gb_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict on validation set\n",
    "    y_val_pred = gb_classifier.predict_proba(X_val_scaled)[:, 1]  # get probabilities for the positive class\n",
    "\n",
    "#     # Calculate AUC\n",
    "#     auc_score = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "#     print(f\"AUC Score on Validation Set: {auc_score}\")\n",
    "    \n",
    "    auc, ci = roc_auc_score(y_val, y_val_pred,\n",
    "                        confidence_level=0.95,\n",
    "                        method='bootstrap_bca',\n",
    "                        n_resamples=1000)\n",
    "    \n",
    "    print(f'Test AUC Score: {auc} ({ci[0]}, {ci[1]})')\n",
    "    \n",
    "    # Step 2: Calculate the optimal threshold using Youden's J statistic\n",
    "    fpr, tpr, thresholds = roc_curve(y_val, y_val_pred)\n",
    "    youden_j = tpr - fpr\n",
    "    optimal_idx = np.argmax(youden_j)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "    # Step 3: Binarize the predictions based on the optimal threshold\n",
    "    y_val_class = (y_val_pred >= optimal_threshold).astype(int)\n",
    "    \n",
    "    acc, ci_acc = roc_auc_score(y_val, y_val_class,\n",
    "                        confidence_level=0.95,\n",
    "                        method='bootstrap_bca',\n",
    "                        n_resamples=1000)\n",
    "    \n",
    "    print(f'Test Accuracy Score: {acc} ({ci_acc[0]}, {ci_acc[1]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164caba2-1514-425a-bcfc-da96d571959b",
   "metadata": {},
   "source": [
    "### Summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb5f37a7-7d3c-42d1-81d3-55e63ef6a193",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Define the data with updated AUC scores\n",
    "# data = {\n",
    "#     'Model Class': ['LASSO', 'LASSO', 'LASSO', 'LASSO', 'LASSO', 'SVM', 'SVM', 'SVM', 'SVM', 'SVM',\n",
    "#                     'Random Forest', 'Random Forest', 'Random Forest', 'Random Forest', 'Random Forest',\n",
    "#                     'Gradient Boosted Trees', 'Gradient Boosted Trees', 'Gradient Boosted Trees', 'Gradient Boosted Trees', 'Gradient Boosted Trees'],\n",
    "#     'Input Specification': ['human ECG labels', 'human ECG labels + age + sex', 'human ECG labels + age + sex + race', 'human ECG labels + age + sex + agi', 'human ECG labels + age + sex + agi + tropt (KNN imputed)',\n",
    "#                             'human ECG labels', 'human ECG labels + age + sex', 'human ECG labels + age + sex + race', 'human ECG labels + age + sex + agi', 'human ECG labels + age + sex + agi + tropt (KNN imputed)',\n",
    "#                             'human ECG labels', 'human ECG labels + age + sex', 'human ECG labels + age + sex + race', 'human ECG labels + age + sex + agi', 'human ECG labels + age + sex + agi + tropt (KNN imputed)',\n",
    "#                             'human ECG labels', 'human ECG labels + age + sex', 'human ECG labels + age + sex + race', 'human ECG labels + age + sex + agi', 'human ECG labels + age + sex + agi + tropt (KNN imputed)'],\n",
    "#     'AUC Score on Validation Set': [0.7066463395854508, 0.7297206566263205, 0.7400597492993317, 0.7411108050693185, 0.8028468218615151,\n",
    "#                                     0.6963565246850842, 0.7202808833040747, 0.728156087344852, 0.7185059250746372, 0.7870613972601872,\n",
    "#                                     0.6974929933167022, 0.7192244910530043, 0.7408173950537436, 0.7488705474876607, 0.8137788457581024,\n",
    "#                                     0.6548307616495734, 0.6753395546521298, 0.7007299270072993, 0.7125096165718464, 0.8048698636425518]\n",
    "# }\n",
    "\n",
    "# # Create a DataFrame\n",
    "# summary_df = pd.DataFrame(data)\n",
    "\n",
    "# # Specify the desired order of rows and columns\n",
    "# desired_row_order = ['LASSO', 'SVM', 'Random Forest', 'Gradient Boosted Trees']\n",
    "# desired_column_order = ['human ECG labels', 'human ECG labels + age + sex', 'human ECG labels + age + sex + race', 'human ECG labels + age + sex + agi', 'human ECG labels + age + sex + agi + tropt (KNN imputed)']\n",
    "\n",
    "# # Filter the DataFrame to match the desired row order\n",
    "# summary_df_filtered = summary_df[summary_df['Model Class'].isin(desired_row_order)]\n",
    "\n",
    "# # Pivot the DataFrame\n",
    "# summary_df_pivot = summary_df_filtered.pivot(index='Model Class', columns='Input Specification', values='AUC Score on Validation Set')\n",
    "\n",
    "# # Reorder the rows and columns in the DataFrame\n",
    "# summary_df_pivot = summary_df_pivot.reindex(desired_row_order)[desired_column_order]\n",
    "\n",
    "# # Print the summary table with the desired ordering\n",
    "# display(summary_df_pivot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad9f21d1-cff4-4cae-add2-9aa08e82ad30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Input Specification</th>\n",
       "      <th>human ECG labels</th>\n",
       "      <th>human ECG labels + age + sex</th>\n",
       "      <th>human ECG labels + age + sex + race</th>\n",
       "      <th>human ECG labels + age + sex + agi</th>\n",
       "      <th>human ECG labels + age + sex + agi + tropt (KNN imputed)</th>\n",
       "      <th>human ECG labels + age + sex + tropt (KNN imputed)</th>\n",
       "      <th>human ECG labels + age + sex + race + tropt (KNN imputed)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LASSO</th>\n",
       "      <td>0.727098</td>\n",
       "      <td>0.766590</td>\n",
       "      <td>0.768723</td>\n",
       "      <td>0.772262</td>\n",
       "      <td>0.813529</td>\n",
       "      <td>0.811678</td>\n",
       "      <td>0.812194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.720315</td>\n",
       "      <td>0.762524</td>\n",
       "      <td>0.765333</td>\n",
       "      <td>0.770483</td>\n",
       "      <td>0.817160</td>\n",
       "      <td>0.813802</td>\n",
       "      <td>0.812893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.733381</td>\n",
       "      <td>0.758559</td>\n",
       "      <td>0.755965</td>\n",
       "      <td>0.734943</td>\n",
       "      <td>0.823556</td>\n",
       "      <td>0.851330</td>\n",
       "      <td>0.847376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosted Trees</th>\n",
       "      <td>0.678167</td>\n",
       "      <td>0.716124</td>\n",
       "      <td>0.722875</td>\n",
       "      <td>0.711432</td>\n",
       "      <td>0.821884</td>\n",
       "      <td>0.838190</td>\n",
       "      <td>0.827392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Input Specification     human ECG labels  human ECG labels + age + sex   \n",
       "Model Class                                                              \n",
       "LASSO                           0.727098                      0.766590  \\\n",
       "SVM                             0.720315                      0.762524   \n",
       "Random Forest                   0.733381                      0.758559   \n",
       "Gradient Boosted Trees          0.678167                      0.716124   \n",
       "\n",
       "Input Specification     human ECG labels + age + sex + race   \n",
       "Model Class                                                   \n",
       "LASSO                                              0.768723  \\\n",
       "SVM                                                0.765333   \n",
       "Random Forest                                      0.755965   \n",
       "Gradient Boosted Trees                             0.722875   \n",
       "\n",
       "Input Specification     human ECG labels + age + sex + agi   \n",
       "Model Class                                                  \n",
       "LASSO                                             0.772262  \\\n",
       "SVM                                               0.770483   \n",
       "Random Forest                                     0.734943   \n",
       "Gradient Boosted Trees                            0.711432   \n",
       "\n",
       "Input Specification     human ECG labels + age + sex + agi + tropt (KNN imputed)   \n",
       "Model Class                                                                        \n",
       "LASSO                                                            0.813529         \\\n",
       "SVM                                                              0.817160          \n",
       "Random Forest                                                    0.823556          \n",
       "Gradient Boosted Trees                                           0.821884          \n",
       "\n",
       "Input Specification     human ECG labels + age + sex + tropt (KNN imputed)   \n",
       "Model Class                                                                  \n",
       "LASSO                                                            0.811678   \\\n",
       "SVM                                                              0.813802    \n",
       "Random Forest                                                    0.851330    \n",
       "Gradient Boosted Trees                                           0.838190    \n",
       "\n",
       "Input Specification     human ECG labels + age + sex + race + tropt (KNN imputed)  \n",
       "Model Class                                                                        \n",
       "LASSO                                                            0.812194          \n",
       "SVM                                                              0.812893          \n",
       "Random Forest                                                    0.847376          \n",
       "Gradient Boosted Trees                                           0.827392          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the data with updated AUC scores\n",
    "data = {\n",
    "    'Model Class': ['LASSO', 'LASSO', 'LASSO', 'LASSO', 'LASSO', 'LASSO', 'LASSO',\n",
    "                    'SVM', 'SVM', 'SVM', 'SVM', 'SVM', 'SVM', 'SVM',\n",
    "                    'Random Forest', 'Random Forest', 'Random Forest', 'Random Forest', 'Random Forest', 'Random Forest', 'Random Forest',\n",
    "                    'Gradient Boosted Trees', 'Gradient Boosted Trees', 'Gradient Boosted Trees', 'Gradient Boosted Trees', 'Gradient Boosted Trees', 'Gradient Boosted Trees', 'Gradient Boosted Trees'],\n",
    "    'Input Specification': ['human ECG labels', 'human ECG labels + age + sex', 'human ECG labels + age + sex + race', 'human ECG labels + age + sex + agi', 'human ECG labels + age + sex + agi + tropt (KNN imputed)',\n",
    "                            'human ECG labels + age + sex + tropt (KNN imputed)', 'human ECG labels + age + sex + race + tropt (KNN imputed)',\n",
    "                            'human ECG labels', 'human ECG labels + age + sex', 'human ECG labels + age + sex + race', 'human ECG labels + age + sex + agi', 'human ECG labels + age + sex + agi + tropt (KNN imputed)',\n",
    "                            'human ECG labels + age + sex + tropt (KNN imputed)', 'human ECG labels + age + sex + race + tropt (KNN imputed)',\n",
    "                            'human ECG labels', 'human ECG labels + age + sex', 'human ECG labels + age + sex + race', 'human ECG labels + age + sex + agi', 'human ECG labels + age + sex + agi + tropt (KNN imputed)',\n",
    "                            'human ECG labels + age + sex + tropt (KNN imputed)', 'human ECG labels + age + sex + race + tropt (KNN imputed)',\n",
    "                            'human ECG labels', 'human ECG labels + age + sex', 'human ECG labels + age + sex + race', 'human ECG labels + age + sex + agi', 'human ECG labels + age + sex + agi + tropt (KNN imputed)',\n",
    "                            'human ECG labels + age + sex + tropt (KNN imputed)', 'human ECG labels + age + sex + race + tropt (KNN imputed)'],\n",
    "    'AUC Score on Validation Set': [0.7270976694135304, 0.7665902075722821, 0.7687225667601167, 0.7722616001201459, 0.8135293753883394, 0.8116784187126553, 0.8121938096451732,\n",
    "                                    0.7203154645597938, 0.7625237164783507, 0.7653328802424036, 0.7704829690182486, 0.8171602564291329, 0.8138022824455582, 0.8128932687678758,\n",
    "                                    0.7333814742446124, 0.7585591708435986, 0.7559652252711466, 0.7349427392685821, 0.8235562609876115, 0.8513295386967972, 0.8473763203352873,\n",
    "                                    0.6781666808257583, 0.7161243734601987, 0.7228754283125195, 0.7114318274845621, 0.8218836410109928, 0.8381899017359047, 0.8273921785178262]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "summary_df = pd.DataFrame(data)\n",
    "\n",
    "# Specify the desired order of rows and columns\n",
    "desired_row_order = ['LASSO', 'SVM', 'Random Forest', 'Gradient Boosted Trees']\n",
    "desired_column_order = ['human ECG labels', 'human ECG labels + age + sex', 'human ECG labels + age + sex + race', 'human ECG labels + age + sex + agi', 'human ECG labels + age + sex + agi + tropt (KNN imputed)', \n",
    "                        'human ECG labels + age + sex + tropt (KNN imputed)', 'human ECG labels + age + sex + race + tropt (KNN imputed)']\n",
    "\n",
    "# Filter the DataFrame to match the desired row order\n",
    "summary_df_filtered = summary_df[summary_df['Model Class'].isin(desired_row_order)]\n",
    "\n",
    "# Pivot the DataFrame\n",
    "summary_df_pivot = summary_df_filtered.pivot(index='Model Class', columns='Input Specification', values='AUC Score on Validation Set')\n",
    "\n",
    "# Reorder the rows and columns in the DataFrame\n",
    "summary_df_pivot = summary_df_pivot.reindex(desired_row_order)[desired_column_order]\n",
    "\n",
    "# Print the summary table with the desired ordering\n",
    "display(summary_df_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64d174bd-5329-45a1-a327-85c3cbdc1638",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Input Specification</th>\n",
       "      <th>human ECG labels</th>\n",
       "      <th>human ECG labels + age + sex + tropt (KNN imputed)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LASSO</th>\n",
       "      <td>0.727098</td>\n",
       "      <td>0.811678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.720315</td>\n",
       "      <td>0.813802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.733381</td>\n",
       "      <td>0.851330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosted Trees</th>\n",
       "      <td>0.678167</td>\n",
       "      <td>0.838190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Input Specification     human ECG labels   \n",
       "Model Class                                \n",
       "LASSO                           0.727098  \\\n",
       "SVM                             0.720315   \n",
       "Random Forest                   0.733381   \n",
       "Gradient Boosted Trees          0.678167   \n",
       "\n",
       "Input Specification     human ECG labels + age + sex + tropt (KNN imputed)  \n",
       "Model Class                                                                 \n",
       "LASSO                                                            0.811678   \n",
       "SVM                                                              0.813802   \n",
       "Random Forest                                                    0.851330   \n",
       "Gradient Boosted Trees                                           0.838190   "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df_pivot[['human ECG labels','human ECG labels + age + sex + tropt (KNN imputed)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907ebe62-4298-4ecf-a80d-8dde602fa583",
   "metadata": {},
   "source": [
    "## Analysis in untested population\n",
    "\n",
    "Evaluate how well AMI models trained above do in predicting Mace_death_30 in the untested population. Only done for Tropt_imputed model for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c1a3922-c887-4fbc-83ed-52767c1df6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "## Load data tested\n",
    "############################\n",
    "\n",
    "df_train_t = pd.read_csv('train_ids_labels_untested_with_covars_all.csv')\n",
    "df_val_t = pd.read_csv('val_ids_labels_untested_with_covars_all.csv')\n",
    "df_test_t = pd.read_csv('test_ids_labels_untested_with_covars_all.csv')\n",
    "df_all_t = pd.read_csv('all_ids_labels_untested_with_covars_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75111eca-a890-4b47-b196-c6f77f688042",
   "metadata": {},
   "source": [
    "### Lasso test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1080853-f445-494b-9b4f-7743f0928e49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO: St elevation, twi, st depression\n",
      "AUC Score on Validation Set: 0.5274126257863443\n"
     ]
    }
   ],
   "source": [
    "variables, name = input_spec_list[-1], input_spec_name[-1]\n",
    "\n",
    "print(f\"LASSO: {name}\")\n",
    "\n",
    "if name == 'human ECG labels + age + sex + agi + tropt (KNN imputed)' or 'human ECG labels + age + sex + tropt (KNN imputed)' or 'human ECG labels + age + sex + race + tropt (KNN imputed)':\n",
    "    # Compute the median of the 'maxtrop_sameday' column\n",
    "    median_maxtrop = df_train['maxtrop_sameday'].median()\n",
    "\n",
    "    # Replace missing values with the median\n",
    "    #imputer = SimpleImputer(strategy='median')\n",
    "    imputer = KNNImputer(n_neighbors=5) \n",
    "    df_train_t['maxtrop_sameday'] = imputer.fit_transform(df_train_t[['maxtrop_sameday']])\n",
    "    df_val_t['maxtrop_sameday'] = imputer.transform(df_val_t[['maxtrop_sameday']])\n",
    "\n",
    "variables_incl_y = variables + [adverse_event]\n",
    "\n",
    "df_train_rel = df_train_t[variables_incl_y].dropna()\n",
    "df_val_rel = df_train_t[variables_incl_y].dropna() \n",
    "\n",
    "# Prepare the training data\n",
    "X_train = df_train_rel[variables]\n",
    "y_train = df_train_rel[adverse_event]\n",
    "\n",
    "# Prepare the validation data\n",
    "X_val = df_val_rel[variables]\n",
    "y_val = df_val_rel[adverse_event]\n",
    "\n",
    "# Scale the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "#     # Initialize the LASSO Logistic Regression classifier\n",
    "#     lasso_classifier = LogisticRegression(penalty='l1', solver='liblinear', C=1, random_state=42)\n",
    "\n",
    "#     # Train the model\n",
    "#     lasso_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred = lasso_classifier.predict_proba(X_val_scaled)[:, 1]  # get probabilities for the positive class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"AUC Score on Validation Set: {auc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb9fe6c-3c56-4979-bae3-dbac96f95f8b",
   "metadata": {},
   "source": [
    "### SVM Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ba9e069-152a-4e2f-b9a6-ce67083f88ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: St elevation, twi, st depression\n",
      "AUC Score on Validation Set: 0.5274126257863443\n"
     ]
    }
   ],
   "source": [
    "variables, name = input_spec_list[-1], input_spec_name[-1]\n",
    "\n",
    "print(f\"SVM: {name}\")\n",
    "\n",
    "if name == 'human ECG labels + age + sex + agi + tropt (KNN imputed)' or 'human ECG labels + age + sex + tropt (KNN imputed)' or 'human ECG labels + age + sex + race + tropt (KNN imputed)':\n",
    "    # Compute the median of the 'maxtrop_sameday' column\n",
    "    median_maxtrop = df_train['maxtrop_sameday'].median()\n",
    "\n",
    "    # Replace missing values with the median\n",
    "    #imputer = SimpleImputer(strategy='median')\n",
    "    imputer = KNNImputer(n_neighbors=5) \n",
    "    df_train_t['maxtrop_sameday'] = imputer.fit_transform(df_train_t[['maxtrop_sameday']])\n",
    "    df_val_t['maxtrop_sameday'] = imputer.transform(df_val_t[['maxtrop_sameday']])\n",
    "\n",
    "variables_incl_y = variables + [adverse_event]\n",
    "\n",
    "df_train_rel = df_train_t[variables_incl_y].dropna()\n",
    "df_val_rel = df_train_t[variables_incl_y].dropna() \n",
    "\n",
    "# Prepare the training data\n",
    "X_train = df_train_rel[variables]\n",
    "y_train = df_train_rel[adverse_event]\n",
    "\n",
    "# Prepare the validation data\n",
    "X_val = df_val_rel[variables]\n",
    "y_val = df_val_rel[adverse_event]\n",
    "\n",
    "# Scale the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "#     # Initialize the LASSO Logistic Regression classifier\n",
    "#     lasso_classifier = LogisticRegression(penalty='l1', solver='liblinear', C=1, random_state=42)\n",
    "\n",
    "#     # Train the model\n",
    "#     lasso_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred = svm_classifier.decision_function(X_val_scaled)  # get probabilities for non-linear SVM\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"AUC Score on Validation Set: {auc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494cf8e5-158e-4634-89f2-ad5b6f231656",
   "metadata": {},
   "source": [
    "### Random Forest Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36e256cb-8cf8-4905-9633-7c16390affff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: St elevation, twi, st depression\n",
      "AUC Score on Validation Set: 0.5273914211928595\n"
     ]
    }
   ],
   "source": [
    "variables, name = input_spec_list[-1], input_spec_name[-1]\n",
    "\n",
    "print(f\"Random Forest: {name}\")\n",
    "\n",
    "if name == 'human ECG labels + age + sex + agi + tropt (KNN imputed)' or 'human ECG labels + age + sex + tropt (KNN imputed)' or 'human ECG labels + age + sex + race + tropt (KNN imputed)':\n",
    "    # Compute the median of the 'maxtrop_sameday' column\n",
    "    median_maxtrop = df_train['maxtrop_sameday'].median()\n",
    "\n",
    "    # Replace missing values with the median\n",
    "    #imputer = SimpleImputer(strategy='median')\n",
    "    imputer = KNNImputer(n_neighbors=5) \n",
    "    df_train_t['maxtrop_sameday'] = imputer.fit_transform(df_train_t[['maxtrop_sameday']])\n",
    "    df_val_t['maxtrop_sameday'] = imputer.transform(df_val_t[['maxtrop_sameday']])\n",
    "\n",
    "variables_incl_y = variables + [adverse_event]\n",
    "\n",
    "df_train_rel = df_train_t[variables_incl_y].dropna()\n",
    "df_val_rel = df_train_t[variables_incl_y].dropna() \n",
    "\n",
    "# Prepare the training data\n",
    "X_train = df_train_rel[variables]\n",
    "y_train = df_train_rel[adverse_event]\n",
    "\n",
    "# Prepare the validation data\n",
    "X_val = df_val_rel[variables]\n",
    "y_val = df_val_rel[adverse_event]\n",
    "\n",
    "# Scale the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "#     # Initialize the LASSO Logistic Regression classifier\n",
    "#     lasso_classifier = LogisticRegression(penalty='l1', solver='liblinear', C=1, random_state=42)\n",
    "\n",
    "#     # Train the model\n",
    "#     lasso_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred = rf_classifier.predict_proba(X_val_scaled)[:, 1]  # get probabilities for the positive class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"AUC Score on Validation Set: {auc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867acf79-7430-4466-a0d3-f60f7bc32007",
   "metadata": {},
   "source": [
    "### Gradient Boosted Tree Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56a00551-5c6b-4239-b66a-591f4e810aad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosted Trees: St elevation, twi, st depression\n",
      "AUC Score on Validation Set: 0.5274073681296189\n"
     ]
    }
   ],
   "source": [
    "variables, name = input_spec_list[-1], input_spec_name[-1]\n",
    "\n",
    "print(f\"Gradient Boosted Trees: {name}\")\n",
    "\n",
    "if name == 'human ECG labels + age + sex + agi + tropt (KNN imputed)' or 'human ECG labels + age + sex + tropt (KNN imputed)' or 'human ECG labels + age + sex + race + tropt (KNN imputed)':\n",
    "    # Compute the median of the 'maxtrop_sameday' column\n",
    "    median_maxtrop = df_train['maxtrop_sameday'].median()\n",
    "\n",
    "    # Replace missing values with the median\n",
    "    #imputer = SimpleImputer(strategy='median')\n",
    "    imputer = KNNImputer(n_neighbors=5) \n",
    "    df_train_t['maxtrop_sameday'] = imputer.fit_transform(df_train_t[['maxtrop_sameday']])\n",
    "    df_val_t['maxtrop_sameday'] = imputer.transform(df_val_t[['maxtrop_sameday']])\n",
    "\n",
    "variables_incl_y = variables + [adverse_event]\n",
    "\n",
    "df_train_rel = df_train_t[variables_incl_y].dropna()\n",
    "df_val_rel = df_train_t[variables_incl_y].dropna() \n",
    "\n",
    "# Prepare the training data\n",
    "X_train = df_train_rel[variables]\n",
    "y_train = df_train_rel[adverse_event]\n",
    "\n",
    "# Prepare the validation data\n",
    "X_val = df_val_rel[variables]\n",
    "y_val = df_val_rel[adverse_event]\n",
    "\n",
    "# Scale the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "#     # Initialize the LASSO Logistic Regression classifier\n",
    "#     lasso_classifier = LogisticRegression(penalty='l1', solver='liblinear', C=1, random_state=42)\n",
    "\n",
    "#     # Train the model\n",
    "#     lasso_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred = gb_classifier.predict_proba(X_val_scaled)[:, 1]  # get probabilities for the positive class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"AUC Score on Validation Set: {auc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c1fa021-e25a-4f05-8136-a72bd68218ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Input Specification</th>\n",
       "      <th>human ECG labels + age + sex + tropt (KNN imputed)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model Class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gradient Boosted Trees</th>\n",
       "      <td>0.497394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO</th>\n",
       "      <td>0.603370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.608423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.585305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Input Specification     human ECG labels + age + sex + tropt (KNN imputed)\n",
       "Model Class                                                               \n",
       "Gradient Boosted Trees                                           0.497394 \n",
       "LASSO                                                            0.603370 \n",
       "Random Forest                                                    0.608423 \n",
       "SVM                                                              0.585305 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Define the data for the new table\n",
    "# adverse_event_data = {\n",
    "#     'Model Class': ['LASSO', 'SVM', 'Random Forest', 'Gradient Boosted Trees'],\n",
    "#     'Input Specification': ['human ECG labels + age + sex + race + tropt (KNN imputed)'] * 4,\n",
    "#     'AUC Score on Validation Set': [\n",
    "#         0.6205558850177413,\n",
    "#         0.6051718104474512,\n",
    "#         0.6307197244884056,\n",
    "#         0.5623672827896413\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# # Create a DataFrame for the untested patient population model performance\n",
    "# adverse_event_df = pd.DataFrame(adverse_event_data)\n",
    "\n",
    "# # Pivot the DataFrame for better readability\n",
    "# adverse_event_df_pivot = adverse_event_df.pivot(index='Model Class', columns='Input Specification', values='AUC Score on Validation Set')\n",
    "\n",
    "# # Display the summary table\n",
    "# display(adverse_event_df_pivot)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Define the updated data for the new table\n",
    "adverse_event_data = {\n",
    "    'Model Class': ['LASSO', 'SVM', 'Random Forest', 'Gradient Boosted Trees'],\n",
    "    'Input Specification': ['human ECG labels + age + sex + tropt (KNN imputed)', \n",
    "                            'human ECG labels + age + sex + tropt (KNN imputed)', \n",
    "                            'human ECG labels + age + sex + tropt (KNN imputed)', \n",
    "                            'human ECG labels + age + sex + tropt (KNN imputed)'],\n",
    "    'AUC Score on Validation Set': [\n",
    "        0.6033697663004493,  # Updated AUC for LASSO\n",
    "        0.585304960924227,   # Updated AUC for SVM\n",
    "        0.6084229055763204,  # Updated AUC for Random Forest\n",
    "        0.4973938866236267   # Updated AUC for Gradient Boosted Trees\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a DataFrame for the updated model performance\n",
    "adverse_event_df = pd.DataFrame(adverse_event_data)\n",
    "\n",
    "# Pivot the DataFrame for better readability\n",
    "adverse_event_df_pivot = adverse_event_df.pivot(index='Model Class', columns='Input Specification', values='AUC Score on Validation Set')\n",
    "\n",
    "# Display the updated summary table\n",
    "display(adverse_event_df_pivot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f6b97ca-200c-464e-a399-ba7a5fe4ad59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Input Specification</th>\n",
       "      <th>human ECG labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model Class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gradient Boosted Trees</th>\n",
       "      <td>0.476140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO</th>\n",
       "      <td>0.508170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.569293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.501262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Input Specification     human ECG labels\n",
       "Model Class                             \n",
       "Gradient Boosted Trees          0.476140\n",
       "LASSO                           0.508170\n",
       "Random Forest                   0.569293\n",
       "SVM                             0.501262"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the updated data for the table\n",
    "data_untested = {\n",
    "    'Model Class': ['LASSO', 'SVM', 'Random Forest', 'Gradient Boosted Trees'],\n",
    "    'Input Specification': ['human ECG labels'] * 4,  # Same input specification for all models\n",
    "    'AUC Score on Validation Set': [\n",
    "        0.508169668139087,   # Updated AUC for LASSO\n",
    "        0.5012620342054592,  # Updated AUC for SVM\n",
    "        0.5692929078415827,  # Updated AUC for Random Forest\n",
    "        0.47613980443236303  # Updated AUC for Gradient Boosted Trees\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the updated data\n",
    "untested_df = pd.DataFrame(data_untested)\n",
    "\n",
    "# Pivot the DataFrame to align models and their scores\n",
    "untested_df_pivot = untested_df.pivot(index='Model Class', columns='Input Specification', values='AUC Score on Validation Set')\n",
    "\n",
    "# Display the updated table\n",
    "display(untested_df_pivot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd236e24-146a-4834-8558-b7c2cfee05ee",
   "metadata": {},
   "source": [
    "### Off-topic waveform processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2bdf36f-5ec8-46e1-8c7b-2bc2b3444eb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'waveform_arr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming 'arr' is your original numpy array with shape [leads, time]\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m short_lead_arr \u001b[38;5;241m=\u001b[39m \u001b[43mwaveform_arr\u001b[49m[:\u001b[38;5;241m12\u001b[39m]\n\u001b[1;32m      3\u001b[0m long_lead_arr \u001b[38;5;241m=\u001b[39m waveform_arr[\u001b[38;5;241m12\u001b[39m:]\n\u001b[1;32m      4\u001b[0m short_lead_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan_to_num(short_lead_arr)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'waveform_arr' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming 'arr' is your original numpy array with shape [leads, time]\n",
    "short_lead_arr = waveform_arr[:12]\n",
    "long_lead_arr = waveform_arr[12:]\n",
    "short_lead_arr = np.nan_to_num(short_lead_arr)\n",
    "\n",
    "\n",
    "plot_ecg_waveform(short_lead_arr)\n",
    "print(short_lead_arr[0])\n",
    "\n",
    "compressed_arr = np.zeros((3, 5000))\n",
    "\n",
    "# Sum the specified channels for each new channel\n",
    "compressed_arr[0, :] = short_lead_arr[0, :] + short_lead_arr[3, :] + short_lead_arr[6, :] + short_lead_arr[9, :]\n",
    "compressed_arr[1, :] = short_lead_arr[1, :] + short_lead_arr[4, :] + short_lead_arr[7, :] + short_lead_arr[10, :]\n",
    "compressed_arr[2, :] = short_lead_arr[2, :] + short_lead_arr[5, :] + short_lead_arr[8, :] + short_lead_arr[11, :]\n",
    "\n",
    "compressed_arr = np.concatenate((compressed_arr, long_lead_arr), axis=0)\n",
    "\n",
    "plot_ecg_waveform(compressed_arr)\n",
    "print(compressed_arr[0])\n",
    "\n",
    "print(compressed_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3835361f-a9f5-40c1-a62c-b73f2307d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def process_file(filepath):\n",
    "    filename = os.path.basename(filepath).split('.')[0]\n",
    "    npz_file = np.load(filepath)\n",
    "    waveform_arr = npz_file['waveform']\n",
    "    \n",
    "    short_lead_arr = waveform_arr[:12]\n",
    "    long_lead_arr = waveform_arr[12:]\n",
    "    short_lead_arr = np.nan_to_num(short_lead_arr)\n",
    "\n",
    "    compressed_arr = np.zeros((3, 5000))\n",
    "\n",
    "    # Sum the specified channels for each new channel\n",
    "    compressed_arr[0, :] = short_lead_arr[0, :] + short_lead_arr[3, :] + short_lead_arr[6, :] + short_lead_arr[9, :]\n",
    "    compressed_arr[1, :] = short_lead_arr[1, :] + short_lead_arr[4, :] + short_lead_arr[7, :] + short_lead_arr[10, :]\n",
    "    compressed_arr[2, :] = short_lead_arr[2, :] + short_lead_arr[5, :] + short_lead_arr[8, :] + short_lead_arr[11, :]\n",
    "\n",
    "    compressed_arr = np.concatenate((compressed_arr, long_lead_arr), axis=0)\n",
    "    \n",
    "    savepath = os.path.join(waveform_path, f'{filename}.npy')\n",
    "    np.save(savepath, compressed_arr)\n",
    "\n",
    "\n",
    "os.chdir('/home/ngsci')\n",
    "\n",
    "waveform_path = '/home/ngsci/project/NEJM_benchmark/waveforms_all_channel'\n",
    "# npz_files = [os.path.join(waveform_path, f) for f in os.listdir(waveform_path) if f.endswith('.npz')]\n",
    "\n",
    "# Use multiprocessing to process files\n",
    "with Pool(processes=os.cpu_count()) as pool:\n",
    "    list(tqdm(pool.imap(process_file, npz_files), total=len(npz_files)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
