{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6765a8f0-fb11-4b72-a14b-013271277ea7",
   "metadata": {},
   "source": [
    "## Baseline training - Models only using metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a00f8f1-bf09-4523-b04f-eaa4d3730614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://devpi.svc.ngsci.local/root/pypi/+simple/\n",
      "Requirement already satisfied: confidenceinterval in /opt/venv/default/lib/python3.10/site-packages (1.0.5)\n",
      "Requirement already satisfied: setuptools~=68.2.0 in /opt/venv/default/lib/python3.10/site-packages (from confidenceinterval) (68.2.2)\n",
      "Requirement already satisfied: pandas in /opt/venv/default/lib/python3.10/site-packages (from confidenceinterval) (2.0.1)\n",
      "Requirement already satisfied: statsmodels in /opt/venv/default/lib/python3.10/site-packages (from confidenceinterval) (0.13.5)\n",
      "Requirement already satisfied: scikit-learn in /opt/venv/default/lib/python3.10/site-packages (from confidenceinterval) (1.2.2)\n",
      "Requirement already satisfied: scipy in /opt/venv/default/lib/python3.10/site-packages (from confidenceinterval) (1.10.1)\n",
      "Requirement already satisfied: numpy in /opt/venv/default/lib/python3.10/site-packages (from confidenceinterval) (1.23.5)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/venv/default/lib/python3.10/site-packages (from pandas->confidenceinterval) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/venv/default/lib/python3.10/site-packages (from pandas->confidenceinterval) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/venv/default/lib/python3.10/site-packages (from pandas->confidenceinterval) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/venv/default/lib/python3.10/site-packages (from scikit-learn->confidenceinterval) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/venv/default/lib/python3.10/site-packages (from scikit-learn->confidenceinterval) (3.1.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/venv/default/lib/python3.10/site-packages (from statsmodels->confidenceinterval) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/venv/default/lib/python3.10/site-packages (from statsmodels->confidenceinterval) (23.1)\n",
      "Requirement already satisfied: six in /opt/venv/default/lib/python3.10/site-packages (from patsy>=0.5.2->statsmodels->confidenceinterval) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install confidenceinterval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78587da1-c87f-4db0-b78e-d67b5281ff02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import mode\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from confidenceinterval import roc_auc_score, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12efbc58-f382-4d4d-ae70-3a2583d055c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############################\n",
    "## Load data\n",
    "############################\n",
    "\n",
    "df_train = pd.read_csv('train_ids_labels_with_covars_all_final_cath.csv')\n",
    "df_val = pd.read_csv('test_ids_labels_with_covars_all_final_cath.csv') #val_ids_labels_with_covars_all\n",
    "df_test = pd.read_csv('test_ids_labels_with_covars_all_final_cath.csv')\n",
    "df_all = pd.read_csv('all_ids_labels_tested_with_covars_all_final_cath.csv')\n",
    "\n",
    "df_train = df_all[df_all['split']=='train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3174158c-fc74-4959-ba91-8065b7f52895",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>patient_ngsci_id</th>\n",
       "      <th>ecg_id</th>\n",
       "      <th>date</th>\n",
       "      <th>p-r-t_axes</th>\n",
       "      <th>p_axes</th>\n",
       "      <th>r_axes</th>\n",
       "      <th>t_axes</th>\n",
       "      <th>pr_interval</th>\n",
       "      <th>pr_interval_units</th>\n",
       "      <th>...</th>\n",
       "      <th>race_other</th>\n",
       "      <th>agi_under_25k</th>\n",
       "      <th>agi_25k_to_50k</th>\n",
       "      <th>agi_50k_to_75k</th>\n",
       "      <th>agi_75k_to_100k</th>\n",
       "      <th>agi_100k_to_200k</th>\n",
       "      <th>agi_above_200k</th>\n",
       "      <th>ecg_cnt</th>\n",
       "      <th>female</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>pat001162d6</td>\n",
       "      <td>ecg162c83f05d</td>\n",
       "      <td>2114-06-21T21:04:34Z</td>\n",
       "      <td>45 59 0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>ms</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.274465</td>\n",
       "      <td>0.181957</td>\n",
       "      <td>0.137615</td>\n",
       "      <td>0.106269</td>\n",
       "      <td>0.212538</td>\n",
       "      <td>0.087156</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>pat001162d6</td>\n",
       "      <td>ecg86065367ee</td>\n",
       "      <td>2114-06-21T21:04:34Z</td>\n",
       "      <td>45 59 0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>ms</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.274465</td>\n",
       "      <td>0.181957</td>\n",
       "      <td>0.137615</td>\n",
       "      <td>0.106269</td>\n",
       "      <td>0.212538</td>\n",
       "      <td>0.087156</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>333</td>\n",
       "      <td>pat00bc255b</td>\n",
       "      <td>ecge81f90e55f</td>\n",
       "      <td>2110-03-16T00:48:37Z</td>\n",
       "      <td>21 63 82</td>\n",
       "      <td>21.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>ms</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.283726</td>\n",
       "      <td>0.230193</td>\n",
       "      <td>0.171306</td>\n",
       "      <td>0.110278</td>\n",
       "      <td>0.162741</td>\n",
       "      <td>0.041756</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>689</td>\n",
       "      <td>pat016dc0b1</td>\n",
       "      <td>ecg9f3122d3ff</td>\n",
       "      <td>2113-12-28T15:47:37Z</td>\n",
       "      <td>59 12 224</td>\n",
       "      <td>59.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>ms</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.048872</td>\n",
       "      <td>0.048872</td>\n",
       "      <td>0.150376</td>\n",
       "      <td>0.436090</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>795</td>\n",
       "      <td>pat01a2f886</td>\n",
       "      <td>ecg07fc5879be</td>\n",
       "      <td>2114-11-01T12:34:08Z</td>\n",
       "      <td>4 -35 23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>ms</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.523381</td>\n",
       "      <td>0.276978</td>\n",
       "      <td>0.104317</td>\n",
       "      <td>0.044964</td>\n",
       "      <td>0.041367</td>\n",
       "      <td>0.008993</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 patient_ngsci_id         ecg_id                  date   \n",
       "0          26      pat001162d6  ecg162c83f05d  2114-06-21T21:04:34Z  \\\n",
       "1          27      pat001162d6  ecg86065367ee  2114-06-21T21:04:34Z   \n",
       "2         333      pat00bc255b  ecge81f90e55f  2110-03-16T00:48:37Z   \n",
       "3         689      pat016dc0b1  ecg9f3122d3ff  2113-12-28T15:47:37Z   \n",
       "4         795      pat01a2f886  ecg07fc5879be  2114-11-01T12:34:08Z   \n",
       "\n",
       "  p-r-t_axes  p_axes  r_axes  t_axes  pr_interval pr_interval_units  ...   \n",
       "0    45 59 0    45.0    59.0     0.0        224.0                ms  ...  \\\n",
       "1    45 59 0    45.0    59.0     0.0        224.0                ms  ...   \n",
       "2   21 63 82    21.0    63.0    82.0        166.0                ms  ...   \n",
       "3  59 12 224    59.0    12.0   224.0        130.0                ms  ...   \n",
       "4   4 -35 23     4.0   -35.0    23.0        170.0                ms  ...   \n",
       "\n",
       "   race_other agi_under_25k agi_25k_to_50k  agi_50k_to_75k agi_75k_to_100k   \n",
       "0           0      0.274465       0.181957        0.137615        0.106269  \\\n",
       "1           0      0.274465       0.181957        0.137615        0.106269   \n",
       "2           0      0.283726       0.230193        0.171306        0.110278   \n",
       "3           0      0.236842       0.078947        0.048872        0.048872   \n",
       "4           1      0.523381       0.276978        0.104317        0.044964   \n",
       "\n",
       "   agi_100k_to_200k agi_above_200k  ecg_cnt female  split  \n",
       "0          0.212538       0.087156        1      1  train  \n",
       "1          0.212538       0.087156        1      1  train  \n",
       "2          0.162741       0.041756        1      0  train  \n",
       "3          0.150376       0.436090        1      0  train  \n",
       "4          0.041367       0.008993        1      1  train  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'patient_ngsci_id', 'ecg_id', 'date', 'p-r-t_axes',\n",
      "       'p_axes', 'r_axes', 't_axes', 'pr_interval', 'pr_interval_units',\n",
      "       'qrs_duration', 'qrs_duration_units', 'qtqtc', 'qt_interval',\n",
      "       'qt_interval_units', 'qtc_interval', 'qtc_interval_units', 'vent_rate',\n",
      "       'vent_rate_units', 'has_bbb', 'has_afib', 'has_st', 'has_pacemaker',\n",
      "       'has_lvh', 'has_normal', 'has_normal_ecg', 'has_normal_sinus',\n",
      "       'has_depress', 'has_st_eleva', 'has_twave', 'has_aberran_bbb',\n",
      "       'has_jpoint_repol', 'has_jpoint_eleva', 'has_twave_inver',\n",
      "       'has_twave_abnormal', 'has_nonspecific', 'has_rhythm_disturbance',\n",
      "       'has_prolonged_qt', 'has_lead_reversal', 'has_poor_or_quality',\n",
      "       'ecg_id_new', 'ed_enc_id', 'start_datetime', 'end_datetime',\n",
      "       'age_at_admit', 'macetrop_030_pos', 'death_030_day',\n",
      "       'macetrop_pos_or_death_030', 'stent_010_day', 'cabg_010_day',\n",
      "       'stent_or_cabg_010_day', 'ami_day_of', 'days_to_ami', 'maxtrop_sameday',\n",
      "       'tn_group_sameday', 'disch_disp', 'disch_obs', 'test_010_day',\n",
      "       'stress_010_day', 'cath_010_day', 'days_to_stress', 'days_to_cath',\n",
      "       'first_test', 'excl_flag_c_int', 'excl_flag_chronic', 'excl_flag_death',\n",
      "       'exclude_modeling', 'exclude', 'sex', 'race_black', 'race_hispanic',\n",
      "       'race_white', 'race_other', 'agi_under_25k', 'agi_25k_to_50k',\n",
      "       'agi_50k_to_75k', 'agi_75k_to_100k', 'agi_100k_to_200k',\n",
      "       'agi_above_200k', 'ecg_cnt', 'female', 'split'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "display(df_train.head())\n",
    "print(df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e268b13-5ffc-4956-a463-f1ddfd09648b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                     int64\n",
      "patient_ngsci_id              object\n",
      "ecg_id                        object\n",
      "date                          object\n",
      "p-r-t_axes                    object\n",
      "p_axes                       float64\n",
      "r_axes                       float64\n",
      "t_axes                       float64\n",
      "pr_interval                  float64\n",
      "pr_interval_units             object\n",
      "qrs_duration                   int64\n",
      "qrs_duration_units            object\n",
      "qtqtc                         object\n",
      "qt_interval                    int64\n",
      "qt_interval_units             object\n",
      "qtc_interval                   int64\n",
      "qtc_interval_units            object\n",
      "vent_rate                      int64\n",
      "vent_rate_units               object\n",
      "has_bbb                        int64\n",
      "has_afib                       int64\n",
      "has_st                         int64\n",
      "has_pacemaker                  int64\n",
      "has_lvh                        int64\n",
      "has_normal                     int64\n",
      "has_normal_ecg                 int64\n",
      "has_normal_sinus               int64\n",
      "has_depress                    int64\n",
      "has_st_eleva                   int64\n",
      "has_twave                      int64\n",
      "has_aberran_bbb                int64\n",
      "has_jpoint_repol               int64\n",
      "has_jpoint_eleva               int64\n",
      "has_twave_inver                int64\n",
      "has_twave_abnormal             int64\n",
      "has_nonspecific                int64\n",
      "has_rhythm_disturbance         int64\n",
      "has_prolonged_qt               int64\n",
      "has_lead_reversal              int64\n",
      "has_poor_or_quality            int64\n",
      "ecg_id_new                    object\n",
      "ed_enc_id                     object\n",
      "start_datetime                object\n",
      "end_datetime                  object\n",
      "age_at_admit                 float64\n",
      "macetrop_030_pos                bool\n",
      "death_030_day                   bool\n",
      "macetrop_pos_or_death_030       bool\n",
      "stent_010_day                   bool\n",
      "cabg_010_day                    bool\n",
      "stent_or_cabg_010_day           bool\n",
      "ami_day_of                      bool\n",
      "days_to_ami                  float64\n",
      "maxtrop_sameday              float64\n",
      "tn_group_sameday              object\n",
      "disch_disp                    object\n",
      "disch_obs                       bool\n",
      "test_010_day                    bool\n",
      "stress_010_day                  bool\n",
      "cath_010_day                    bool\n",
      "days_to_stress               float64\n",
      "days_to_cath                 float64\n",
      "first_test                    object\n",
      "excl_flag_c_int                 bool\n",
      "excl_flag_chronic               bool\n",
      "excl_flag_death                 bool\n",
      "exclude_modeling                bool\n",
      "exclude                         bool\n",
      "sex                           object\n",
      "race_black                     int64\n",
      "race_hispanic                  int64\n",
      "race_white                     int64\n",
      "race_other                     int64\n",
      "agi_under_25k                float64\n",
      "agi_25k_to_50k               float64\n",
      "agi_50k_to_75k               float64\n",
      "agi_75k_to_100k              float64\n",
      "agi_100k_to_200k             float64\n",
      "agi_above_200k               float64\n",
      "ecg_cnt                        int64\n",
      "female                         int64\n",
      "split                         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Set the display option to show all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "#print(df_all.isna().sum())\n",
    "print(df_all.dtypes)\n",
    "\n",
    "#Define X and y variables\n",
    "human_waveform_vars = [ 'r_axes',\n",
    "       'qrs_duration',  'qt_interval', #'p-r-t_axes', 'qtqtc',\n",
    "        'qtc_interval',  'vent_rate',\n",
    "        'has_bbb', 'has_afib', 'has_st', 'has_pacemaker',\n",
    "       'has_lvh', 'has_normal', 'has_normal_ecg', 'has_normal_sinus',\n",
    "       'has_depress', 'has_st_eleva', 'has_twave', 'has_aberran_bbb',\n",
    "       'has_jpoint_repol', 'has_jpoint_eleva', 'has_twave_inver',\n",
    "       'has_twave_abnormal', 'has_nonspecific', 'has_rhythm_disturbance',\n",
    "       'has_prolonged_qt', 'has_lead_reversal', 'has_poor_or_quality', 'ste_std_twi'] #'p_axes', 'maxtrop_sameday','vent_rate_units','pr_interval','t_axes',\n",
    "\n",
    "human_waveform_age_sex_vars = [ 'r_axes',\n",
    "       'qrs_duration',  'qt_interval', #'p-r-t_axes', 'qtqtc',\n",
    "        'qtc_interval',  'vent_rate',\n",
    "        'has_bbb', 'has_afib', 'has_st', 'has_pacemaker',\n",
    "       'has_lvh', 'has_normal', 'has_normal_ecg', 'has_normal_sinus',\n",
    "       'has_depress', 'has_st_eleva', 'has_twave', 'has_aberran_bbb',\n",
    "       'has_jpoint_repol', 'has_jpoint_eleva', 'has_twave_inver',\n",
    "       'has_twave_abnormal', 'has_nonspecific', 'has_rhythm_disturbance',\n",
    "       'has_prolonged_qt', 'has_lead_reversal', 'has_poor_or_quality',\n",
    "        'age_at_admit', 'female','ste_std_twi'] #'p_axes', 'maxtrop_sameday','vent_rate_units','pr_interval','t_axes',\n",
    "\n",
    "human_waveform_age_sex_race_vars = [ 'r_axes',\n",
    "       'qrs_duration',  'qt_interval', #'p-r-t_axes', 'qtqtc',\n",
    "        'qtc_interval',  'vent_rate',\n",
    "        'has_bbb', 'has_afib', 'has_st', 'has_pacemaker',\n",
    "       'has_lvh', 'has_normal', 'has_normal_ecg', 'has_normal_sinus',\n",
    "       'has_depress', 'has_st_eleva', 'has_twave', 'has_aberran_bbb',\n",
    "       'has_jpoint_repol', 'has_jpoint_eleva', 'has_twave_inver',\n",
    "       'has_twave_abnormal', 'has_nonspecific', 'has_rhythm_disturbance',\n",
    "       'has_prolonged_qt', 'has_lead_reversal', 'has_poor_or_quality',\n",
    "        'age_at_admit', 'female', 'race_black', 'race_hispanic', 'race_white', 'race_other',\n",
    "        'ste_std_twi'] #'p_axes', 'maxtrop_sameday','vent_rate_units','pr_interval','t_axes',\n",
    "\n",
    "human_waveform_age_sex_race_agi_vars = [ 'r_axes',\n",
    "       'qrs_duration',  'qt_interval', #'p-r-t_axes', 'qtqtc',\n",
    "        'qtc_interval',  'vent_rate',\n",
    "        'has_bbb', 'has_afib', 'has_st', 'has_pacemaker',\n",
    "       'has_lvh', 'has_normal', 'has_normal_ecg', 'has_normal_sinus',\n",
    "       'has_depress', 'has_st_eleva', 'has_twave', 'has_aberran_bbb',\n",
    "       'has_jpoint_repol', 'has_jpoint_eleva', 'has_twave_inver',\n",
    "       'has_twave_abnormal', 'has_nonspecific', 'has_rhythm_disturbance',\n",
    "       'has_prolonged_qt', 'has_lead_reversal', 'has_poor_or_quality',\n",
    "        'age_at_admit', 'female', 'race_black', 'race_hispanic', 'race_white', 'race_other',\n",
    "       'agi_under_25k', 'agi_25k_to_50k', 'agi_50k_to_75k', 'agi_75k_to_100k',\n",
    "       'agi_100k_to_200k', 'agi_above_200k', 'ste_std_twi'] #'p_axes', 'maxtrop_sameday','vent_rate_units','pr_interval','t_axes',\n",
    "\n",
    "human_waveform_age_sex_race_agi_tropt_vars = [ 'r_axes',\n",
    "       'qrs_duration',  'qt_interval', #'p-r-t_axes', 'qtqtc',\n",
    "        'qtc_interval',  'vent_rate',\n",
    "        'has_bbb', 'has_afib', 'has_st', 'has_pacemaker',\n",
    "       'has_lvh', 'has_normal', 'has_normal_ecg', 'has_normal_sinus',\n",
    "       'has_depress', 'has_st_eleva', 'has_twave', 'has_aberran_bbb',\n",
    "       'has_jpoint_repol', 'has_jpoint_eleva', 'has_twave_inver',\n",
    "       'has_twave_abnormal', 'has_nonspecific', 'has_rhythm_disturbance',\n",
    "       'has_prolonged_qt', 'has_lead_reversal', 'has_poor_or_quality',\n",
    "        'age_at_admit', 'female', 'race_black', 'race_hispanic', 'race_white', 'race_other',\n",
    "       'agi_under_25k', 'agi_25k_to_50k', 'agi_50k_to_75k', 'agi_75k_to_100k',\n",
    "       'agi_100k_to_200k', 'agi_above_200k', 'ste_std_twi', 'maxtrop_sameday'] #'p_axes','vent_rate_units','pr_interval','t_axes',\n",
    "\n",
    "human_waveform_age_sex_tropt_vars = [ 'r_axes',\n",
    "       'qrs_duration',  'qt_interval', #'p-r-t_axes', 'qtqtc',\n",
    "        'qtc_interval',  'vent_rate',\n",
    "        'has_bbb', 'has_afib', 'has_st', 'has_pacemaker',\n",
    "       'has_lvh', 'has_normal', 'has_normal_ecg', 'has_normal_sinus',\n",
    "       'has_depress', 'has_st_eleva', 'has_twave', 'has_aberran_bbb',\n",
    "       'has_jpoint_repol', 'has_jpoint_eleva', 'has_twave_inver',\n",
    "       'has_twave_abnormal', 'has_nonspecific', 'has_rhythm_disturbance',\n",
    "       'has_prolonged_qt', 'has_lead_reversal', 'has_poor_or_quality',\n",
    "        'age_at_admit', 'female', 'ste_std_twi', 'maxtrop_sameday'] #'p_axes','vent_rate_units','pr_interval','t_axes',\n",
    "\n",
    "human_waveform_age_sex_race_tropt_vars = [ 'r_axes',\n",
    "       'qrs_duration',  'qt_interval', #'p-r-t_axes', 'qtqtc',\n",
    "        'qtc_interval',  'vent_rate',\n",
    "        'has_bbb', 'has_afib', 'has_st', 'has_pacemaker',\n",
    "       'has_lvh', 'has_normal', 'has_normal_ecg', 'has_normal_sinus',\n",
    "       'has_depress', 'has_st_eleva', 'has_twave', 'has_aberran_bbb',\n",
    "       'has_jpoint_repol', 'has_jpoint_eleva', 'has_twave_inver',\n",
    "       'has_twave_abnormal', 'has_nonspecific', 'has_rhythm_disturbance',\n",
    "       'has_prolonged_qt', 'has_lead_reversal', 'has_poor_or_quality',\n",
    "        'race_black', 'race_hispanic', 'race_white', 'race_other',\n",
    "        'age_at_admit', 'female', 'ste_std_twi', 'maxtrop_sameday'] #'p_axes','vent_rate_units','pr_interval','t_axes',\n",
    "\n",
    "ste = ['has_depress', 'has_st_eleva', 'has_twave_inver'] #'p_axes','vent_rate_units','pr_interval','t_axes',\n",
    "\n",
    "ste_plus = ['has_depress', 'has_st_eleva', 'has_twave_inver', 'has_twave_abnormal'] \n",
    "#[[ 0.18956526  0.30042848 -0.01083876  0.01352145]]\n",
    "\n",
    "groundtruth_ami = 'stent_or_cabg_010_day'\n",
    "adverse_event = 'macetrop_pos_or_death_030'\n",
    "\n",
    "# input_spec_list = [human_waveform_vars, human_waveform_age_sex_vars, human_waveform_age_sex_race_vars, \n",
    "#                    human_waveform_age_sex_race_agi_vars, human_waveform_age_sex_race_agi_tropt_vars, human_waveform_age_sex_tropt_vars, human_waveform_age_sex_race_tropt_vars]\n",
    "\n",
    "# input_spec_name = ['human ECG labels', 'human ECG labels + age + sex', 'human ECG labels + age + sex + race', \n",
    "#                    'human ECG labels + age + sex + agi', 'human ECG labels + age + sex + agi + tropt (KNN imputed)', 'human ECG labels + age + sex + tropt (KNN imputed)', \n",
    "#                    'human ECG labels + age + sex + race + tropt (KNN imputed)']\n",
    "\n",
    "# input_spec_list = [human_waveform_vars, human_waveform_age_sex_vars, human_waveform_age_sex_race_vars, \n",
    "#                    human_waveform_age_sex_race_agi_vars, human_waveform_age_sex_race_agi_tropt_vars, human_waveform_age_sex_race_tropt_vars, human_waveform_age_sex_tropt_vars,]\n",
    "\n",
    "# input_spec_name = ['human ECG labels', 'human ECG labels + age + sex', 'human ECG labels + age + sex + race', \n",
    "#                    'human ECG labels + age + sex + agi', 'human ECG labels + age + sex + agi + tropt (KNN imputed)', \n",
    "#                    'human ECG labels + age + sex + race + tropt (KNN imputed)', 'human ECG labels + age + sex + tropt (KNN imputed)']\n",
    "\n",
    "# input_spec_list = [human_waveform_age_sex_vars, human_waveform_age_sex_race_vars, \n",
    "#                    human_waveform_age_sex_race_agi_vars, human_waveform_age_sex_race_agi_tropt_vars, human_waveform_age_sex_tropt_vars, human_waveform_age_sex_race_tropt_vars,\n",
    "#                   human_waveform_vars, ste]\n",
    "\n",
    "input_spec_list = [ste_plus] #,ste\n",
    "\n",
    "input_spec_name = ['St elevation, T-wave inversion, ST depression, T-wave abnormal'] #, 'St elevation, T-wave inversion, ST depression'\n",
    "\n",
    "# relevant_vars = [ 'r_axes',\n",
    "#        'qrs_duration',  'qt_interval',\n",
    "#         'qtc_interval',  'vent_rate',\n",
    "#         'has_bbb', 'has_afib', 'has_st', 'has_pacemaker',\n",
    "#        'has_lvh', 'has_normal', 'has_normal_ecg', 'has_normal_sinus',\n",
    "#        'has_depress', 'has_st_eleva', 'has_twave', 'has_aberran_bbb',\n",
    "#        'has_jpoint_repol', 'has_jpoint_eleva', 'has_twave_inver',\n",
    "#        'has_twave_abnormal', 'has_nonspecific', 'has_rhythm_disturbance',\n",
    "#        'has_prolonged_qt', 'has_lead_reversal', 'has_poor_or_quality',\n",
    "#         'age_at_admit', 'female', 'race_black', 'race_hispanic', 'race_white', 'race_other',\n",
    "#        'agi_under_25k', 'agi_25k_to_50k', 'agi_50k_to_75k', 'agi_75k_to_100k',\n",
    "#        'agi_100k_to_200k', 'agi_above_200k', 'ste_std_twi', 'stent_or_cabg_010_day', 'maxtrop_sameday', 'p_axes'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4a49a5-5173-443e-b1cb-86cb2ba7ce92",
   "metadata": {},
   "source": [
    "## Analysis in tested set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef761e18-883d-415c-b807-7950db287238",
   "metadata": {},
   "source": [
    "### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8208a19b-34da-4154-8d17-0769de1b861d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO: St elevation, T-wave inversion, ST depression, T-wave abnormal\n",
      "Test AUC Score: 0.5282750129699707 (0.4965039726284047, 0.5600460533115368)\n",
      "Test Accuracy Score: 0.6295971978984238 (0.6011982387694503, 0.657127202085731)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_524/2088081622.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['maxtrop_sameday'] = imputer.fit_transform(df_train[['maxtrop_sameday']])\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Assuming df_train and df_val are your training and validation DataFrames\n",
    "# input_vars and output are defined as provided\n",
    "\n",
    "for variables, name in zip(input_spec_list, input_spec_name):\n",
    "    \n",
    "    print(f\"LASSO: {name}\")\n",
    "    \n",
    "    if name == 'human ECG labels + age + sex + agi + tropt (KNN imputed)' or 'human ECG labels + age + sex + tropt (KNN imputed)' or 'human ECG labels + age + sex + race + tropt (KNN imputed)':\n",
    "        # Compute the median of the 'maxtrop_sameday' column\n",
    "        median_maxtrop = df_train['maxtrop_sameday'].median()\n",
    "\n",
    "        # Replace missing values with the median\n",
    "        #imputer = SimpleImputer(strategy='median')\n",
    "        imputer = KNNImputer(n_neighbors=5) \n",
    "        df_train['maxtrop_sameday'] = imputer.fit_transform(df_train[['maxtrop_sameday']])\n",
    "        df_val['maxtrop_sameday'] = imputer.transform(df_val[['maxtrop_sameday']])\n",
    "    \n",
    "    variables_incl_y = variables + [groundtruth_ami]\n",
    "    \n",
    "    df_train_rel = df_train[variables_incl_y].dropna()\n",
    "    df_val_rel = df_test[variables_incl_y].dropna() \n",
    "\n",
    "    # Prepare the training data\n",
    "    X_train = df_train_rel[variables]\n",
    "    y_train = df_train_rel[groundtruth_ami]\n",
    "\n",
    "    # Prepare the validation data\n",
    "    X_val = df_val_rel[variables]\n",
    "    y_val = df_val_rel[groundtruth_ami]\n",
    "    \n",
    "    # Scale the data using StandardScaler\n",
    "    # scaler = StandardScaler()\n",
    "    # X_train_scaled = scaler.fit_transform(X_train)\n",
    "    # X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Initialize the LASSO Logistic Regression classifier\n",
    "    #lasso_classifier = LogisticRegression(penalty='l1', solver='liblinear', random_state=42) #C=0.07,\n",
    "    logistic_classifier = LogisticRegression(penalty='none', solver='lbfgs', random_state=42)\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    #lasso_classifier.fit(X_train_scaled, y_train)\n",
    "    logistic_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    joblib.dump(logistic_classifier, \"structured_feature_logreg_acs.pkl\")\n",
    "\n",
    "    # Predict on validation set\n",
    "    y_val_pred = logistic_classifier.predict_proba(X_val)[:, 1]  # get probabilities for the positive class\n",
    "\n",
    "    # Calculate AUC\n",
    "#     auc_score = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "#     print(f\"AUC Score on Validation Set: {auc_score}\")\n",
    "    \n",
    "    auc, ci = roc_auc_score(y_val, y_val_pred,\n",
    "                        confidence_level=0.95)\n",
    "                        #     ,\n",
    "                        # method='bootstrap_bca',\n",
    "                        # n_resamples=1000)\n",
    "    \n",
    "    print(f'Test AUC Score: {auc} ({ci[0]}, {ci[1]})')\n",
    "    \n",
    "    # Step 2: Calculate the optimal threshold using Youden's J statistic\n",
    "    fpr, tpr, thresholds = roc_curve(y_val, y_val_pred)\n",
    "    youden_j = tpr - fpr\n",
    "    optimal_idx = np.argmax(youden_j)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "    # Step 3: Binarize the predictions based on the optimal threshold\n",
    "    y_val_class = (y_val_pred >= optimal_threshold).astype(int)\n",
    "    \n",
    "    acc, ci_acc = accuracy_score(y_val, y_val_class,\n",
    "                        confidence_level=0.95)\n",
    "                        #          ,\n",
    "                        # method='bootstrap_bca',\n",
    "                        # n_resamples=1000)\n",
    "    \n",
    "    print(f'Test Accuracy Score: {acc} ({ci_acc[0]}, {ci_acc[1]})')\n",
    "\n",
    "df_test['preds_ste_sti_twi_logist'] = y_val_pred\n",
    "df_test['binary_preds_ste_sti_twi_logist'] = y_val_class\n",
    "\n",
    "#df_test.to_csv('test_ids_labels_with_covars_all_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ea5261-dd1d-4298-8dc4-3c3616e090d0",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "871b26d7-d821-4397-8af9-3782e1833e5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: St elevation, T-wave inversion, ST depression, T-wave abnormal\n",
      "Test AUC Score: 0.5282591581344604 (0.4964886825073616, 0.5600296337615593)\n",
      "Test Accuracy Score: 0.6295971978984238 (0.6011982387694503, 0.657127202085731)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "warnings.filterwarnings(\"ignore\")#category=ConvergenceWarning\n",
    "\n",
    "for variables, name in zip(input_spec_list, input_spec_name):\n",
    "    \n",
    "    print(f\"SVM: {name}\")\n",
    "    \n",
    "    if name == 'human ECG labels + age + sex + agi + tropt (KNN imputed)' or 'human ECG labels + age + sex + tropt (KNN imputed)' or 'human ECG labels + age + sex + race + tropt (KNN imputed)':\n",
    "        # Compute the median of the 'maxtrop_sameday' column\n",
    "        median_maxtrop = df_train['maxtrop_sameday'].median()\n",
    "\n",
    "        # Replace missing values with the median\n",
    "        #imputer = SimpleImputer(strategy='median')\n",
    "        imputer = KNNImputer(n_neighbors=5) \n",
    "        df_train['maxtrop_sameday'] = imputer.fit_transform(df_train[['maxtrop_sameday']])\n",
    "        df_val['maxtrop_sameday'] = imputer.transform(df_val[['maxtrop_sameday']])\n",
    "    \n",
    "    variables_incl_y = variables + [groundtruth_ami]\n",
    "    \n",
    "    df_train_rel = df_train[variables_incl_y].dropna()\n",
    "    df_val_rel = df_val[variables_incl_y].dropna() \n",
    "\n",
    "    # Prepare the training data\n",
    "    X_train = df_train_rel[variables]\n",
    "    y_train = df_train_rel[groundtruth_ami]\n",
    "\n",
    "    # Prepare the validation data\n",
    "    X_val = df_val_rel[variables]\n",
    "    y_val = df_val_rel[groundtruth_ami]\n",
    "    \n",
    "    # Scale the data using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Initialize the Non-Linear Support Vector Machine (SVM) classifier with a kernel (e.g., 'rbf')\n",
    "    svm_classifier = LinearSVC(random_state=42, C=0.05)\n",
    "\n",
    "    # Train the model\n",
    "    svm_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict on validation set\n",
    "    y_val_pred = svm_classifier.decision_function(X_val_scaled)  # get probabilities for non-linear SVM\n",
    "\n",
    "#     # Calculate AUC\n",
    "#     auc_score = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "#     print(f\"AUC Score on Validation Set: {auc_score}\")\n",
    "    \n",
    "    auc, ci = roc_auc_score(y_val, y_val_pred,\n",
    "                        confidence_level=0.95)\n",
    "                        #     ,\n",
    "                        # method='bootstrap_bca',\n",
    "                        # n_resamples=1000)\n",
    "    \n",
    "    print(f'Test AUC Score: {auc} ({ci[0]}, {ci[1]})')\n",
    "    \n",
    "    # Step 2: Calculate the optimal threshold using Youden's J statistic\n",
    "    fpr, tpr, thresholds = roc_curve(y_val, y_val_pred)\n",
    "    youden_j = tpr - fpr\n",
    "    optimal_idx = np.argmax(youden_j)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "    # Step 3: Binarize the predictions based on the optimal threshold\n",
    "    y_val_class = (y_val_pred >= optimal_threshold).astype(int)\n",
    "    \n",
    "    acc, ci_acc = accuracy_score(y_val, y_val_class,\n",
    "                        confidence_level=0.95)\n",
    "                        #          ,\n",
    "                        # method='bootstrap_bca',\n",
    "                        # n_resamples=1000)\n",
    "    \n",
    "    print(f'Test Accuracy Score: {acc} ({ci_acc[0]}, {ci_acc[1]})')\n",
    "\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f610fe0-ce03-401c-bc6c-0f4d199413f6",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7785c15f-31b6-4156-83c4-d581128d1f85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: St elevation, T-wave inversion, ST depression, T-wave abnormal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_524/1448035896.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['maxtrop_sameday'] = imputer.fit_transform(df_train[['maxtrop_sameday']])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC Score: 0.5458941459655762 (0.5141686942717028, 0.5776195976594496)\n",
      "Test Accuracy Score: 0.617338003502627 (0.5887998734427482, 0.6450893770612676)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for variables, name in zip(input_spec_list, input_spec_name):\n",
    "    \n",
    "    print(f\"Random Forest: {name}\")\n",
    "    \n",
    "    if name == 'human ECG labels + age + sex + agi + tropt (KNN imputed)' or 'human ECG labels + age + sex + tropt (KNN imputed)' or 'human ECG labels + age + sex + race + tropt (KNN imputed)':\n",
    "        # Compute the median of the 'maxtrop_sameday' column\n",
    "        median_maxtrop = df_train['maxtrop_sameday'].median()\n",
    "\n",
    "        # Replace missing values with the median\n",
    "        #imputer = SimpleImputer(strategy='median')\n",
    "        imputer = KNNImputer(n_neighbors=5) \n",
    "        df_train['maxtrop_sameday'] = imputer.fit_transform(df_train[['maxtrop_sameday']])\n",
    "        df_val['maxtrop_sameday'] = imputer.transform(df_val[['maxtrop_sameday']])\n",
    "    \n",
    "    variables_incl_y = variables + [groundtruth_ami]\n",
    "    \n",
    "    df_train_rel = df_train[variables_incl_y].dropna()\n",
    "    df_val_rel = df_val[variables_incl_y].dropna() \n",
    "\n",
    "    # Prepare the training data\n",
    "    X_train = df_train_rel[variables]\n",
    "    y_train = df_train_rel[groundtruth_ami]\n",
    "\n",
    "    # Prepare the validation data\n",
    "    X_val = df_val_rel[variables]\n",
    "    y_val = df_val_rel[groundtruth_ami]\n",
    "    \n",
    "    # Scale the data using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Initialize the Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=200, min_samples_leaf=75,max_depth=5, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    rf_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict on validation set\n",
    "    y_val_pred = rf_classifier.predict_proba(X_val_scaled)[:, 1]  # get probabilities for the positive class\n",
    "\n",
    "    # Calculate AUC\n",
    "#     auc_score = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "#     print(f\"AUC Score on Validation Set: {auc_score}\")\n",
    "    \n",
    "    auc, ci = roc_auc_score(y_val, y_val_pred,\n",
    "                        confidence_level=0.95)\n",
    "                        #     ,\n",
    "                        # method='bootstrap_bca',\n",
    "                        # n_resamples=1000)\n",
    "    \n",
    "    print(f'Test AUC Score: {auc} ({ci[0]}, {ci[1]})')\n",
    "    \n",
    "    # Step 2: Calculate the optimal threshold using Youden's J statistic\n",
    "    fpr, tpr, thresholds = roc_curve(y_val, y_val_pred)\n",
    "    youden_j = tpr - fpr\n",
    "    optimal_idx = np.argmax(youden_j)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    \n",
    "    # fpr, tpr, thresholds = roc_curve(y_val, y_val_pred)\n",
    "    # distances = np.sqrt((1 - tpr)**2 + fpr**2)  # Calculate the distance to the point (0, 1)\n",
    "    # optimal_idx = np.argmin(distances)  # Find the index of the smallest distance\n",
    "    # optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "    # Step 3: Binarize the predictions based on the optimal threshold\n",
    "    y_val_class = (y_val_pred >= optimal_threshold).astype(int)\n",
    "    \n",
    "    acc, ci_acc = accuracy_score(y_val, y_val_class,\n",
    "                        confidence_level=0.95)\n",
    "                        #          ,\n",
    "                        # method='bootstrap_bca',\n",
    "                        # n_resamples=1000)\n",
    "    \n",
    "    print(f'Test Accuracy Score: {acc} ({ci_acc[0]}, {ci_acc[1]})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44610b26-d996-483c-9cc2-039bd653abaa",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "babb9f71-91e7-41f6-ad2b-623f24cc6042",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosted Trees: St elevation, T-wave inversion, ST depression, T-wave abnormal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_524/4122885672.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['maxtrop_sameday'] = imputer.fit_transform(df_train[['maxtrop_sameday']])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC Score: 0.5283607244491577 (0.4965856883838661, 0.5601357605144494)\n",
      "Test Accuracy Score: 0.6330998248686515 (0.6047441472080887, 0.6605630623188544)\n"
     ]
    }
   ],
   "source": [
    "for variables, name in zip(input_spec_list, input_spec_name):\n",
    "    \n",
    "    print(f\"Gradient Boosted Trees: {name}\")\n",
    "    \n",
    "    if name == 'human ECG labels + age + sex + agi + tropt (KNN imputed)' or 'human ECG labels + age + sex + tropt (KNN imputed)' or 'human ECG labels + age + sex + race + tropt (KNN imputed)':\n",
    "        # Compute the median of the 'maxtrop_sameday' column\n",
    "        median_maxtrop = df_train['maxtrop_sameday'].median()\n",
    "\n",
    "        # Replace missing values with the median\n",
    "        #imputer = SimpleImputer(strategy='median')\n",
    "        imputer = KNNImputer(n_neighbors=5) \n",
    "        df_train['maxtrop_sameday'] = imputer.fit_transform(df_train[['maxtrop_sameday']])\n",
    "        df_val['maxtrop_sameday'] = imputer.transform(df_val[['maxtrop_sameday']])\n",
    "    \n",
    "    variables_incl_y = variables + [groundtruth_ami]\n",
    "    \n",
    "    df_train_rel = df_train[variables_incl_y].dropna()\n",
    "    df_val_rel = df_val[variables_incl_y].dropna() \n",
    "\n",
    "    # Prepare the training data\n",
    "    X_train = df_train_rel[variables]\n",
    "    y_train = df_train_rel[groundtruth_ami]\n",
    "\n",
    "    # Prepare the validation data\n",
    "    X_val = df_val_rel[variables]\n",
    "    y_val = df_val_rel[groundtruth_ami]\n",
    "    \n",
    "    # Scale the data using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Initialize the Gradient Boosting classifier\n",
    "    gb_classifier = GradientBoostingClassifier( learning_rate=0.02, n_estimators=200, min_samples_leaf=50, max_depth=7, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    gb_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict on validation set\n",
    "    y_val_pred = gb_classifier.predict_proba(X_val_scaled)[:, 1]  # get probabilities for the positive class\n",
    "\n",
    "#     # Calculate AUC\n",
    "#     auc_score = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "#     print(f\"AUC Score on Validation Set: {auc_score}\")\n",
    "    \n",
    "    auc, ci = roc_auc_score(y_val, y_val_pred,\n",
    "                        confidence_level=0.95)\n",
    "    # ,\n",
    "    #                     method='bootstrap_bca',\n",
    "    #                     n_resamples=1000)\n",
    "    \n",
    "    print(f'Test AUC Score: {auc} ({ci[0]}, {ci[1]})')\n",
    "    \n",
    "    # Step 2: Calculate the optimal threshold using Youden's J statistic\n",
    "    fpr, tpr, thresholds = roc_curve(y_val, y_val_pred)\n",
    "    youden_j = tpr - fpr\n",
    "    optimal_idx = np.argmax(youden_j)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "    # Step 3: Binarize the predictions based on the optimal threshold\n",
    "    y_val_class = (y_val_pred >= optimal_threshold).astype(int)\n",
    "    \n",
    "    acc, ci_acc = accuracy_score(y_val, y_val_class,\n",
    "                        confidence_level=0.95)\n",
    "    # ,\n",
    "    #                     method='bootstrap_bca',\n",
    "    #                     n_resamples=1000)\n",
    "    \n",
    "    print(f'Test Accuracy Score: {acc} ({ci_acc[0]}, {ci_acc[1]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164caba2-1514-425a-bcfc-da96d571959b",
   "metadata": {},
   "source": [
    "### Summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb5f37a7-7d3c-42d1-81d3-55e63ef6a193",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Define the data with updated AUC scores\n",
    "# data = {\n",
    "#     'Model Class': ['LASSO', 'LASSO', 'LASSO', 'LASSO', 'LASSO', 'SVM', 'SVM', 'SVM', 'SVM', 'SVM',\n",
    "#                     'Random Forest', 'Random Forest', 'Random Forest', 'Random Forest', 'Random Forest',\n",
    "#                     'Gradient Boosted Trees', 'Gradient Boosted Trees', 'Gradient Boosted Trees', 'Gradient Boosted Trees', 'Gradient Boosted Trees'],\n",
    "#     'Input Specification': ['human ECG labels', 'human ECG labels + age + sex', 'human ECG labels + age + sex + race', 'human ECG labels + age + sex + agi', 'human ECG labels + age + sex + agi + tropt (KNN imputed)',\n",
    "#                             'human ECG labels', 'human ECG labels + age + sex', 'human ECG labels + age + sex + race', 'human ECG labels + age + sex + agi', 'human ECG labels + age + sex + agi + tropt (KNN imputed)',\n",
    "#                             'human ECG labels', 'human ECG labels + age + sex', 'human ECG labels + age + sex + race', 'human ECG labels + age + sex + agi', 'human ECG labels + age + sex + agi + tropt (KNN imputed)',\n",
    "#                             'human ECG labels', 'human ECG labels + age + sex', 'human ECG labels + age + sex + race', 'human ECG labels + age + sex + agi', 'human ECG labels + age + sex + agi + tropt (KNN imputed)'],\n",
    "#     'AUC Score on Validation Set': [0.7066463395854508, 0.7297206566263205, 0.7400597492993317, 0.7411108050693185, 0.8028468218615151,\n",
    "#                                     0.6963565246850842, 0.7202808833040747, 0.728156087344852, 0.7185059250746372, 0.7870613972601872,\n",
    "#                                     0.6974929933167022, 0.7192244910530043, 0.7408173950537436, 0.7488705474876607, 0.8137788457581024,\n",
    "#                                     0.6548307616495734, 0.6753395546521298, 0.7007299270072993, 0.7125096165718464, 0.8048698636425518]\n",
    "# }\n",
    "\n",
    "# # Create a DataFrame\n",
    "# summary_df = pd.DataFrame(data)\n",
    "\n",
    "# # Specify the desired order of rows and columns\n",
    "# desired_row_order = ['LASSO', 'SVM', 'Random Forest', 'Gradient Boosted Trees']\n",
    "# desired_column_order = ['human ECG labels', 'human ECG labels + age + sex', 'human ECG labels + age + sex + race', 'human ECG labels + age + sex + agi', 'human ECG labels + age + sex + agi + tropt (KNN imputed)']\n",
    "\n",
    "# # Filter the DataFrame to match the desired row order\n",
    "# summary_df_filtered = summary_df[summary_df['Model Class'].isin(desired_row_order)]\n",
    "\n",
    "# # Pivot the DataFrame\n",
    "# summary_df_pivot = summary_df_filtered.pivot(index='Model Class', columns='Input Specification', values='AUC Score on Validation Set')\n",
    "\n",
    "# # Reorder the rows and columns in the DataFrame\n",
    "# summary_df_pivot = summary_df_pivot.reindex(desired_row_order)[desired_column_order]\n",
    "\n",
    "# # Print the summary table with the desired ordering\n",
    "# display(summary_df_pivot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad9f21d1-cff4-4cae-add2-9aa08e82ad30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Input Specification</th>\n",
       "      <th>human ECG labels</th>\n",
       "      <th>human ECG labels + age + sex</th>\n",
       "      <th>human ECG labels + age + sex + race</th>\n",
       "      <th>human ECG labels + age + sex + agi</th>\n",
       "      <th>human ECG labels + age + sex + agi + tropt (KNN imputed)</th>\n",
       "      <th>human ECG labels + age + sex + tropt (KNN imputed)</th>\n",
       "      <th>human ECG labels + age + sex + race + tropt (KNN imputed)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LASSO</th>\n",
       "      <td>0.727098</td>\n",
       "      <td>0.766590</td>\n",
       "      <td>0.768723</td>\n",
       "      <td>0.772262</td>\n",
       "      <td>0.813529</td>\n",
       "      <td>0.811678</td>\n",
       "      <td>0.812194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.720315</td>\n",
       "      <td>0.762524</td>\n",
       "      <td>0.765333</td>\n",
       "      <td>0.770483</td>\n",
       "      <td>0.817160</td>\n",
       "      <td>0.813802</td>\n",
       "      <td>0.812893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.733381</td>\n",
       "      <td>0.758559</td>\n",
       "      <td>0.755965</td>\n",
       "      <td>0.734943</td>\n",
       "      <td>0.823556</td>\n",
       "      <td>0.851330</td>\n",
       "      <td>0.847376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosted Trees</th>\n",
       "      <td>0.678167</td>\n",
       "      <td>0.716124</td>\n",
       "      <td>0.722875</td>\n",
       "      <td>0.711432</td>\n",
       "      <td>0.821884</td>\n",
       "      <td>0.838190</td>\n",
       "      <td>0.827392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Input Specification     human ECG labels  human ECG labels + age + sex   \n",
       "Model Class                                                              \n",
       "LASSO                           0.727098                      0.766590  \\\n",
       "SVM                             0.720315                      0.762524   \n",
       "Random Forest                   0.733381                      0.758559   \n",
       "Gradient Boosted Trees          0.678167                      0.716124   \n",
       "\n",
       "Input Specification     human ECG labels + age + sex + race   \n",
       "Model Class                                                   \n",
       "LASSO                                              0.768723  \\\n",
       "SVM                                                0.765333   \n",
       "Random Forest                                      0.755965   \n",
       "Gradient Boosted Trees                             0.722875   \n",
       "\n",
       "Input Specification     human ECG labels + age + sex + agi   \n",
       "Model Class                                                  \n",
       "LASSO                                             0.772262  \\\n",
       "SVM                                               0.770483   \n",
       "Random Forest                                     0.734943   \n",
       "Gradient Boosted Trees                            0.711432   \n",
       "\n",
       "Input Specification     human ECG labels + age + sex + agi + tropt (KNN imputed)   \n",
       "Model Class                                                                        \n",
       "LASSO                                                            0.813529         \\\n",
       "SVM                                                              0.817160          \n",
       "Random Forest                                                    0.823556          \n",
       "Gradient Boosted Trees                                           0.821884          \n",
       "\n",
       "Input Specification     human ECG labels + age + sex + tropt (KNN imputed)   \n",
       "Model Class                                                                  \n",
       "LASSO                                                            0.811678   \\\n",
       "SVM                                                              0.813802    \n",
       "Random Forest                                                    0.851330    \n",
       "Gradient Boosted Trees                                           0.838190    \n",
       "\n",
       "Input Specification     human ECG labels + age + sex + race + tropt (KNN imputed)  \n",
       "Model Class                                                                        \n",
       "LASSO                                                            0.812194          \n",
       "SVM                                                              0.812893          \n",
       "Random Forest                                                    0.847376          \n",
       "Gradient Boosted Trees                                           0.827392          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the data with updated AUC scores\n",
    "data = {\n",
    "    'Model Class': ['LASSO', 'LASSO', 'LASSO', 'LASSO', 'LASSO', 'LASSO', 'LASSO',\n",
    "                    'SVM', 'SVM', 'SVM', 'SVM', 'SVM', 'SVM', 'SVM',\n",
    "                    'Random Forest', 'Random Forest', 'Random Forest', 'Random Forest', 'Random Forest', 'Random Forest', 'Random Forest',\n",
    "                    'Gradient Boosted Trees', 'Gradient Boosted Trees', 'Gradient Boosted Trees', 'Gradient Boosted Trees', 'Gradient Boosted Trees', 'Gradient Boosted Trees', 'Gradient Boosted Trees'],\n",
    "    'Input Specification': ['human ECG labels', 'human ECG labels + age + sex', 'human ECG labels + age + sex + race', 'human ECG labels + age + sex + agi', 'human ECG labels + age + sex + agi + tropt (KNN imputed)',\n",
    "                            'human ECG labels + age + sex + tropt (KNN imputed)', 'human ECG labels + age + sex + race + tropt (KNN imputed)',\n",
    "                            'human ECG labels', 'human ECG labels + age + sex', 'human ECG labels + age + sex + race', 'human ECG labels + age + sex + agi', 'human ECG labels + age + sex + agi + tropt (KNN imputed)',\n",
    "                            'human ECG labels + age + sex + tropt (KNN imputed)', 'human ECG labels + age + sex + race + tropt (KNN imputed)',\n",
    "                            'human ECG labels', 'human ECG labels + age + sex', 'human ECG labels + age + sex + race', 'human ECG labels + age + sex + agi', 'human ECG labels + age + sex + agi + tropt (KNN imputed)',\n",
    "                            'human ECG labels + age + sex + tropt (KNN imputed)', 'human ECG labels + age + sex + race + tropt (KNN imputed)',\n",
    "                            'human ECG labels', 'human ECG labels + age + sex', 'human ECG labels + age + sex + race', 'human ECG labels + age + sex + agi', 'human ECG labels + age + sex + agi + tropt (KNN imputed)',\n",
    "                            'human ECG labels + age + sex + tropt (KNN imputed)', 'human ECG labels + age + sex + race + tropt (KNN imputed)'],\n",
    "    'AUC Score on Validation Set': [0.7270976694135304, 0.7665902075722821, 0.7687225667601167, 0.7722616001201459, 0.8135293753883394, 0.8116784187126553, 0.8121938096451732,\n",
    "                                    0.7203154645597938, 0.7625237164783507, 0.7653328802424036, 0.7704829690182486, 0.8171602564291329, 0.8138022824455582, 0.8128932687678758,\n",
    "                                    0.7333814742446124, 0.7585591708435986, 0.7559652252711466, 0.7349427392685821, 0.8235562609876115, 0.8513295386967972, 0.8473763203352873,\n",
    "                                    0.6781666808257583, 0.7161243734601987, 0.7228754283125195, 0.7114318274845621, 0.8218836410109928, 0.8381899017359047, 0.8273921785178262]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "summary_df = pd.DataFrame(data)\n",
    "\n",
    "# Specify the desired order of rows and columns\n",
    "desired_row_order = ['LASSO', 'SVM', 'Random Forest', 'Gradient Boosted Trees']\n",
    "desired_column_order = ['human ECG labels', 'human ECG labels + age + sex', 'human ECG labels + age + sex + race', 'human ECG labels + age + sex + agi', 'human ECG labels + age + sex + agi + tropt (KNN imputed)', \n",
    "                        'human ECG labels + age + sex + tropt (KNN imputed)', 'human ECG labels + age + sex + race + tropt (KNN imputed)']\n",
    "\n",
    "# Filter the DataFrame to match the desired row order\n",
    "summary_df_filtered = summary_df[summary_df['Model Class'].isin(desired_row_order)]\n",
    "\n",
    "# Pivot the DataFrame\n",
    "summary_df_pivot = summary_df_filtered.pivot(index='Model Class', columns='Input Specification', values='AUC Score on Validation Set')\n",
    "\n",
    "# Reorder the rows and columns in the DataFrame\n",
    "summary_df_pivot = summary_df_pivot.reindex(desired_row_order)[desired_column_order]\n",
    "\n",
    "# Print the summary table with the desired ordering\n",
    "display(summary_df_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64d174bd-5329-45a1-a327-85c3cbdc1638",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Input Specification</th>\n",
       "      <th>human ECG labels</th>\n",
       "      <th>human ECG labels + age + sex + tropt (KNN imputed)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LASSO</th>\n",
       "      <td>0.727098</td>\n",
       "      <td>0.811678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.720315</td>\n",
       "      <td>0.813802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.733381</td>\n",
       "      <td>0.851330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosted Trees</th>\n",
       "      <td>0.678167</td>\n",
       "      <td>0.838190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Input Specification     human ECG labels   \n",
       "Model Class                                \n",
       "LASSO                           0.727098  \\\n",
       "SVM                             0.720315   \n",
       "Random Forest                   0.733381   \n",
       "Gradient Boosted Trees          0.678167   \n",
       "\n",
       "Input Specification     human ECG labels + age + sex + tropt (KNN imputed)  \n",
       "Model Class                                                                 \n",
       "LASSO                                                            0.811678   \n",
       "SVM                                                              0.813802   \n",
       "Random Forest                                                    0.851330   \n",
       "Gradient Boosted Trees                                           0.838190   "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df_pivot[['human ECG labels','human ECG labels + age + sex + tropt (KNN imputed)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907ebe62-4298-4ecf-a80d-8dde602fa583",
   "metadata": {},
   "source": [
    "## Analysis in untested population\n",
    "\n",
    "Evaluate how well AMI models trained above do in predicting Mace_death_30 in the untested population. Only done for Tropt_imputed model for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c1a3922-c887-4fbc-83ed-52767c1df6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "## Load data tested\n",
    "############################\n",
    "\n",
    "df_train_t = pd.read_csv('train_ids_labels_untested_with_covars_all_final.csv')\n",
    "df_val_t = pd.read_csv('test_ids_labels_untested_with_covars_all_final.csv') #val_ids_labels_untested_with_covars_all_final\n",
    "df_test_t = pd.read_csv('test_ids_labels_untested_with_covars_all_final.csv')\n",
    "df_all_t = pd.read_csv('all_ids_labels_untested_with_covars_all_final.csv')\n",
    "\n",
    "df_train = df_all[df_all['split']=='train']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75111eca-a890-4b47-b196-c6f77f688042",
   "metadata": {},
   "source": [
    "### Lasso test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1080853-f445-494b-9b4f-7743f0928e49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO: St elevation, T-wave inversion, ST depression, T-wave abnormal\n",
      "Test AUC Score: 0.6064528226852417 (0.5942850627151164, 0.618620582655367)\n",
      "Test Accuracy Score: 0.7178377864410003 (0.7117163884529317, 0.7238796311262415)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "variables, name = input_spec_list[-1], input_spec_name[-1]\n",
    "\n",
    "print(f\"LASSO: {name}\")\n",
    "\n",
    "if name == 'human ECG labels + age + sex + agi + tropt (KNN imputed)' or 'human ECG labels + age + sex + tropt (KNN imputed)' or 'human ECG labels + age + sex + race + tropt (KNN imputed)':\n",
    "    # Compute the median of the 'maxtrop_sameday' column\n",
    "    median_maxtrop = df_train['maxtrop_sameday'].median()\n",
    "\n",
    "    # Replace missing values with the median\n",
    "    #imputer = SimpleImputer(strategy='median')\n",
    "    imputer = KNNImputer(n_neighbors=5) \n",
    "    df_train_t['maxtrop_sameday'] = imputer.fit_transform(df_train_t[['maxtrop_sameday']])\n",
    "    df_val_t['maxtrop_sameday'] = imputer.transform(df_val_t[['maxtrop_sameday']])\n",
    "\n",
    "variables_incl_y = variables + [adverse_event]\n",
    "\n",
    "df_train_rel = df_train_t[variables_incl_y].dropna()\n",
    "df_val_rel = df_test_t[variables_incl_y].dropna() \n",
    "\n",
    "# Prepare the training data\n",
    "X_train = df_train_rel[variables]\n",
    "y_train = df_train_rel[adverse_event]\n",
    "\n",
    "# Prepare the validation data\n",
    "X_val = df_val_rel[variables]\n",
    "y_val = df_val_rel[adverse_event]\n",
    "\n",
    "# Scale the data using StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Initialize the LASSO Logistic Regression classifier\n",
    "#lasso_classifier = LogisticRegression(penalty='l1', solver='liblinear', random_state=42) #C=0.07,\n",
    "logistic_classifier = LogisticRegression(penalty='none', solver='lbfgs', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "#lasso_classifier.fit(X_train_scaled, y_train)\n",
    "logistic_classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "joblib.dump(logistic_classifier, \"structured_feature_logreg_mace.pkl\")\n",
    "\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred = logistic_classifier.predict_proba(X_val)[:, 1]  # get probabilities for the positive class\n",
    "\n",
    "# # Calculate AUC\n",
    "# auc_score = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "# print(f\"AUC Score on Validation Set: {auc_score}\")\n",
    "\n",
    "auc, ci = roc_auc_score(y_val, y_val_pred,\n",
    "                        confidence_level=0.95)\n",
    "# ,\n",
    "#                         method='bootstrap_bca',\n",
    "#                         n_resamples=1000)\n",
    "    \n",
    "print(f'Test AUC Score: {auc} ({ci[0]}, {ci[1]})')\n",
    "\n",
    "# Step 2: Calculate the optimal threshold using Youden's J statistic\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_val_pred)\n",
    "youden_j = tpr - fpr\n",
    "optimal_idx = np.argmax(youden_j)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# Step 3: Binarize the predictions based on the optimal threshold\n",
    "y_val_class = (y_val_pred >= optimal_threshold).astype(int)\n",
    "\n",
    "acc, ci_acc = accuracy_score(y_val, y_val_class,\n",
    "                    confidence_level=0.95)\n",
    "# ,\n",
    "#                     method='bootstrap_bca',\n",
    "#                     n_resamples=1000)\n",
    "\n",
    "print(f'Test Accuracy Score: {acc} ({ci_acc[0]}, {ci_acc[1]})')\n",
    "\n",
    "df_test_t['preds_ste_sti_twi_logist'] = y_val_pred\n",
    "df_test_t['binary_preds_ste_sti_twi_logist'] = y_val_class\n",
    "#df_test_t.to_csv('test_ids_labels_untested_with_covars_all_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb9fe6c-3c56-4979-bae3-dbac96f95f8b",
   "metadata": {},
   "source": [
    "### SVM Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ba9e069-152a-4e2f-b9a6-ce67083f88ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: St elevation, T-wave inversion, ST depression, T-wave abnormal\n",
      "Test AUC Score: 0.5469594597816467 (0.5370017398785283, 0.5569171796847652)\n",
      "Test Accuracy Score: 0.756659050814125 (0.7521078512074738, 0.7611532277959313)\n"
     ]
    }
   ],
   "source": [
    "variables, name = input_spec_list[-1], input_spec_name[-1]\n",
    "\n",
    "print(f\"SVM: {name}\")\n",
    "\n",
    "if name == 'human ECG labels + age + sex + agi + tropt (KNN imputed)' or 'human ECG labels + age + sex + tropt (KNN imputed)' or 'human ECG labels + age + sex + race + tropt (KNN imputed)':\n",
    "    # Compute the median of the 'maxtrop_sameday' column\n",
    "    median_maxtrop = df_train['maxtrop_sameday'].median()\n",
    "\n",
    "    # Replace missing values with the median\n",
    "    #imputer = SimpleImputer(strategy='median')\n",
    "    imputer = KNNImputer(n_neighbors=5) \n",
    "    df_train_t['maxtrop_sameday'] = imputer.fit_transform(df_train_t[['maxtrop_sameday']])\n",
    "    df_val_t['maxtrop_sameday'] = imputer.transform(df_val_t[['maxtrop_sameday']])\n",
    "\n",
    "variables_incl_y = variables + [adverse_event]\n",
    "\n",
    "df_train_rel = df_train_t[variables_incl_y].dropna()\n",
    "df_val_rel = df_train_t[variables_incl_y].dropna() \n",
    "\n",
    "# Prepare the training data\n",
    "X_train = df_train_rel[variables]\n",
    "y_train = df_train_rel[adverse_event]\n",
    "\n",
    "# Prepare the validation data\n",
    "X_val = df_val_rel[variables]\n",
    "y_val = df_val_rel[adverse_event]\n",
    "\n",
    "# Scale the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "#     # Initialize the LASSO Logistic Regression classifier\n",
    "#     lasso_classifier = LogisticRegression(penalty='l1', solver='liblinear', C=1, random_state=42)\n",
    "\n",
    "#     # Train the model\n",
    "#     lasso_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred = svm_classifier.decision_function(X_val_scaled)  # get probabilities for non-linear SVM\n",
    "\n",
    "# Calculate AUC\n",
    "# auc_score = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "# print(f\"AUC Score on Validation Set: {auc_score}\")\n",
    "\n",
    "auc, ci = roc_auc_score(y_val, y_val_pred,\n",
    "                        confidence_level=0.95)\n",
    "# ,\n",
    "#                         method='bootstrap_bca',\n",
    "#                         n_resamples=1000)\n",
    "    \n",
    "print(f'Test AUC Score: {auc} ({ci[0]}, {ci[1]})')\n",
    "\n",
    "# Step 2: Calculate the optimal threshold using Youden's J statistic\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_val_pred)\n",
    "youden_j = tpr - fpr\n",
    "optimal_idx = np.argmax(youden_j)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# Step 3: Binarize the predictions based on the optimal threshold\n",
    "y_val_class = (y_val_pred >= optimal_threshold).astype(int)\n",
    "\n",
    "acc, ci_acc = accuracy_score(y_val, y_val_class,\n",
    "                    confidence_level=0.95)\n",
    "# ,\n",
    "#                     method='bootstrap_bca',\n",
    "#                     n_resamples=1000)\n",
    "\n",
    "print(f'Test Accuracy Score: {acc} ({ci_acc[0]}, {ci_acc[1]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494cf8e5-158e-4634-89f2-ad5b6f231656",
   "metadata": {},
   "source": [
    "### Random Forest Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36e256cb-8cf8-4905-9633-7c16390affff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: St elevation, T-wave inversion, ST depression, T-wave abnormal\n",
      "Test AUC Score: 0.5742689967155457 (0.5648869204531369, 0.5836510729779544)\n",
      "Test Accuracy Score: 0.7137692685889464 (0.7089815106864863, 0.7185095328037012)\n"
     ]
    }
   ],
   "source": [
    "variables, name = input_spec_list[-1], input_spec_name[-1]\n",
    "\n",
    "print(f\"Random Forest: {name}\")\n",
    "\n",
    "if name == 'human ECG labels + age + sex + agi + tropt (KNN imputed)' or 'human ECG labels + age + sex + tropt (KNN imputed)' or 'human ECG labels + age + sex + race + tropt (KNN imputed)':\n",
    "    # Compute the median of the 'maxtrop_sameday' column\n",
    "    median_maxtrop = df_train['maxtrop_sameday'].median()\n",
    "\n",
    "    # Replace missing values with the median\n",
    "    #imputer = SimpleImputer(strategy='median')\n",
    "    imputer = KNNImputer(n_neighbors=5) \n",
    "    df_train_t['maxtrop_sameday'] = imputer.fit_transform(df_train_t[['maxtrop_sameday']])\n",
    "    df_val_t['maxtrop_sameday'] = imputer.transform(df_val_t[['maxtrop_sameday']])\n",
    "\n",
    "variables_incl_y = variables + [adverse_event]\n",
    "\n",
    "df_train_rel = df_train_t[variables_incl_y].dropna()\n",
    "df_val_rel = df_train_t[variables_incl_y].dropna() \n",
    "\n",
    "# Prepare the training data\n",
    "X_train = df_train_rel[variables]\n",
    "y_train = df_train_rel[adverse_event]\n",
    "\n",
    "# Prepare the validation data\n",
    "X_val = df_val_rel[variables]\n",
    "y_val = df_val_rel[adverse_event]\n",
    "\n",
    "# Scale the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "#     # Initialize the LASSO Logistic Regression classifier\n",
    "#     lasso_classifier = LogisticRegression(penalty='l1', solver='liblinear', C=1, random_state=42)\n",
    "\n",
    "#     # Train the model\n",
    "#     lasso_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred = rf_classifier.predict_proba(X_val_scaled)[:, 1]  # get probabilities for the positive class\n",
    "\n",
    "# Calculate AUC\n",
    "# auc_score = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "# print(f\"AUC Score on Validation Set: {auc_score}\")\n",
    "\n",
    "auc, ci = roc_auc_score(y_val, y_val_pred,\n",
    "                        confidence_level=0.95)\n",
    "# ,\n",
    "#                         method='bootstrap_bca',\n",
    "#                         n_resamples=1000)\n",
    "    \n",
    "print(f'Test AUC Score: {auc} ({ci[0]}, {ci[1]})')\n",
    "\n",
    "# Step 2: Calculate the optimal threshold using Youden's J statistic\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_val_pred)\n",
    "youden_j = tpr - fpr\n",
    "optimal_idx = np.argmax(youden_j)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# fpr, tpr, thresholds = roc_curve(y_val, y_val_pred)\n",
    "# distances = np.sqrt((1 - tpr)**2 + fpr**2)  # Calculate the distance to the point (0, 1)\n",
    "# optimal_idx = np.argmin(distances)  # Find the index of the smallest distance\n",
    "# optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# Step 3: Binarize the predictions based on the optimal threshold\n",
    "y_val_class = (y_val_pred >= optimal_threshold).astype(int)\n",
    "\n",
    "acc, ci_acc = accuracy_score(y_val, y_val_class,\n",
    "                    confidence_level=0.95)\n",
    "# ,\n",
    "#                     method='bootstrap_bca',\n",
    "#                     n_resamples=1000)\n",
    "\n",
    "print(f'Test Accuracy Score: {acc} ({ci_acc[0]}, {ci_acc[1]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867acf79-7430-4466-a0d3-f60f7bc32007",
   "metadata": {},
   "source": [
    "### Gradient Boosted Tree Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56a00551-5c6b-4239-b66a-591f4e810aad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosted Trees: St elevation, T-wave inversion, ST depression, T-wave abnormal\n",
      "Test AUC Score: 0.0 (6.776263578034403e-21, 0.00011108633158243367)\n",
      "Test Accuracy Score: 0.756659050814125 (0.7521078512074738, 0.7611532277959313)\n"
     ]
    }
   ],
   "source": [
    "variables, name = input_spec_list[-1], input_spec_name[-1]\n",
    "\n",
    "print(f\"Gradient Boosted Trees: {name}\")\n",
    "\n",
    "if name == 'human ECG labels + age + sex + agi + tropt (KNN imputed)' or 'human ECG labels + age + sex + tropt (KNN imputed)' or 'human ECG labels + age + sex + race + tropt (KNN imputed)':\n",
    "    # Compute the median of the 'maxtrop_sameday' column\n",
    "    median_maxtrop = df_train['maxtrop_sameday'].median()\n",
    "\n",
    "    # Replace missing values with the median\n",
    "    #imputer = SimpleImputer(strategy='median')\n",
    "    imputer = KNNImputer(n_neighbors=5) \n",
    "    df_train_t['maxtrop_sameday'] = imputer.fit_transform(df_train_t[['maxtrop_sameday']])\n",
    "    df_val_t['maxtrop_sameday'] = imputer.transform(df_val_t[['maxtrop_sameday']])\n",
    "\n",
    "variables_incl_y = variables + [adverse_event]\n",
    "\n",
    "df_train_rel = df_train_t[variables_incl_y].dropna()\n",
    "df_val_rel = df_train_t[variables_incl_y].dropna() \n",
    "\n",
    "# Prepare the training data\n",
    "X_train = df_train_rel[variables]\n",
    "y_train = df_train_rel[adverse_event]\n",
    "\n",
    "# Prepare the validation data\n",
    "X_val = df_val_rel[variables]\n",
    "y_val = df_val_rel[adverse_event]\n",
    "\n",
    "# Scale the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "#     # Initialize the LASSO Logistic Regression classifier\n",
    "#     lasso_classifier = LogisticRegression(penalty='l1', solver='liblinear', C=1, random_state=42)\n",
    "\n",
    "#     # Train the model\n",
    "#     lasso_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred = gb_classifier.predict_proba(X_val_scaled)[:, 1]  # get probabilities for the positive class\n",
    "\n",
    "# Calculate AUC\n",
    "# auc_score = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "# print(f\"AUC Score on Validation Set: {auc_score}\")\n",
    "\n",
    "auc, ci = accuracy_score(y_val, y_val_pred,\n",
    "                        confidence_level=0.95)\n",
    "# ,\n",
    "#                         method='bootstrap_bca',\n",
    "#                         n_resamples=1000)\n",
    "    \n",
    "print(f'Test AUC Score: {auc} ({ci[0]}, {ci[1]})')\n",
    "\n",
    "# Step 2: Calculate the optimal threshold using Youden's J statistic\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_val_pred)\n",
    "youden_j = tpr - fpr\n",
    "optimal_idx = np.argmax(youden_j)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# Step 3: Binarize the predictions based on the optimal threshold\n",
    "y_val_class = (y_val_pred >= optimal_threshold).astype(int)\n",
    "\n",
    "acc, ci_acc = accuracy_score(y_val, y_val_class,\n",
    "                    confidence_level=0.95)\n",
    "# ,\n",
    "#                     method='bootstrap_bca',\n",
    "#                     n_resamples=1000)\n",
    "\n",
    "print(f'Test Accuracy Score: {acc} ({ci_acc[0]}, {ci_acc[1]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c1fa021-e25a-4f05-8136-a72bd68218ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Input Specification</th>\n",
       "      <th>human ECG labels + age + sex + tropt (KNN imputed)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model Class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gradient Boosted Trees</th>\n",
       "      <td>0.497394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO</th>\n",
       "      <td>0.603370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.608423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.585305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Input Specification     human ECG labels + age + sex + tropt (KNN imputed)\n",
       "Model Class                                                               \n",
       "Gradient Boosted Trees                                           0.497394 \n",
       "LASSO                                                            0.603370 \n",
       "Random Forest                                                    0.608423 \n",
       "SVM                                                              0.585305 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Define the data for the new table\n",
    "# adverse_event_data = {\n",
    "#     'Model Class': ['LASSO', 'SVM', 'Random Forest', 'Gradient Boosted Trees'],\n",
    "#     'Input Specification': ['human ECG labels + age + sex + race + tropt (KNN imputed)'] * 4,\n",
    "#     'AUC Score on Validation Set': [\n",
    "#         0.6205558850177413,\n",
    "#         0.6051718104474512,\n",
    "#         0.6307197244884056,\n",
    "#         0.5623672827896413\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# # Create a DataFrame for the untested patient population model performance\n",
    "# adverse_event_df = pd.DataFrame(adverse_event_data)\n",
    "\n",
    "# # Pivot the DataFrame for better readability\n",
    "# adverse_event_df_pivot = adverse_event_df.pivot(index='Model Class', columns='Input Specification', values='AUC Score on Validation Set')\n",
    "\n",
    "# # Display the summary table\n",
    "# display(adverse_event_df_pivot)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Define the updated data for the new table\n",
    "adverse_event_data = {\n",
    "    'Model Class': ['LASSO', 'SVM', 'Random Forest', 'Gradient Boosted Trees'],\n",
    "    'Input Specification': ['human ECG labels + age + sex + tropt (KNN imputed)', \n",
    "                            'human ECG labels + age + sex + tropt (KNN imputed)', \n",
    "                            'human ECG labels + age + sex + tropt (KNN imputed)', \n",
    "                            'human ECG labels + age + sex + tropt (KNN imputed)'],\n",
    "    'AUC Score on Validation Set': [\n",
    "        0.6033697663004493,  # Updated AUC for LASSO\n",
    "        0.585304960924227,   # Updated AUC for SVM\n",
    "        0.6084229055763204,  # Updated AUC for Random Forest\n",
    "        0.4973938866236267   # Updated AUC for Gradient Boosted Trees\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a DataFrame for the updated model performance\n",
    "adverse_event_df = pd.DataFrame(adverse_event_data)\n",
    "\n",
    "# Pivot the DataFrame for better readability\n",
    "adverse_event_df_pivot = adverse_event_df.pivot(index='Model Class', columns='Input Specification', values='AUC Score on Validation Set')\n",
    "\n",
    "# Display the updated summary table\n",
    "display(adverse_event_df_pivot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f6b97ca-200c-464e-a399-ba7a5fe4ad59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Input Specification</th>\n",
       "      <th>human ECG labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model Class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gradient Boosted Trees</th>\n",
       "      <td>0.476140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO</th>\n",
       "      <td>0.508170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.569293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.501262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Input Specification     human ECG labels\n",
       "Model Class                             \n",
       "Gradient Boosted Trees          0.476140\n",
       "LASSO                           0.508170\n",
       "Random Forest                   0.569293\n",
       "SVM                             0.501262"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the updated data for the table\n",
    "data_untested = {\n",
    "    'Model Class': ['LASSO', 'SVM', 'Random Forest', 'Gradient Boosted Trees'],\n",
    "    'Input Specification': ['human ECG labels'] * 4,  # Same input specification for all models\n",
    "    'AUC Score on Validation Set': [\n",
    "        0.508169668139087,   # Updated AUC for LASSO\n",
    "        0.5012620342054592,  # Updated AUC for SVM\n",
    "        0.5692929078415827,  # Updated AUC for Random Forest\n",
    "        0.47613980443236303  # Updated AUC for Gradient Boosted Trees\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the updated data\n",
    "untested_df = pd.DataFrame(data_untested)\n",
    "\n",
    "# Pivot the DataFrame to align models and their scores\n",
    "untested_df_pivot = untested_df.pivot(index='Model Class', columns='Input Specification', values='AUC Score on Validation Set')\n",
    "\n",
    "# Display the updated table\n",
    "display(untested_df_pivot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd236e24-146a-4834-8558-b7c2cfee05ee",
   "metadata": {},
   "source": [
    "### Off-topic waveform processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2bdf36f-5ec8-46e1-8c7b-2bc2b3444eb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'waveform_arr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming 'arr' is your original numpy array with shape [leads, time]\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m short_lead_arr \u001b[38;5;241m=\u001b[39m \u001b[43mwaveform_arr\u001b[49m[:\u001b[38;5;241m12\u001b[39m]\n\u001b[1;32m      3\u001b[0m long_lead_arr \u001b[38;5;241m=\u001b[39m waveform_arr[\u001b[38;5;241m12\u001b[39m:]\n\u001b[1;32m      4\u001b[0m short_lead_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan_to_num(short_lead_arr)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'waveform_arr' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming 'arr' is your original numpy array with shape [leads, time]\n",
    "short_lead_arr = waveform_arr[:12]\n",
    "long_lead_arr = waveform_arr[12:]\n",
    "short_lead_arr = np.nan_to_num(short_lead_arr)\n",
    "\n",
    "\n",
    "plot_ecg_waveform(short_lead_arr)\n",
    "print(short_lead_arr[0])\n",
    "\n",
    "compressed_arr = np.zeros((3, 5000))\n",
    "\n",
    "# Sum the specified channels for each new channel\n",
    "compressed_arr[0, :] = short_lead_arr[0, :] + short_lead_arr[3, :] + short_lead_arr[6, :] + short_lead_arr[9, :]\n",
    "compressed_arr[1, :] = short_lead_arr[1, :] + short_lead_arr[4, :] + short_lead_arr[7, :] + short_lead_arr[10, :]\n",
    "compressed_arr[2, :] = short_lead_arr[2, :] + short_lead_arr[5, :] + short_lead_arr[8, :] + short_lead_arr[11, :]\n",
    "\n",
    "compressed_arr = np.concatenate((compressed_arr, long_lead_arr), axis=0)\n",
    "\n",
    "plot_ecg_waveform(compressed_arr)\n",
    "print(compressed_arr[0])\n",
    "\n",
    "print(compressed_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3835361f-a9f5-40c1-a62c-b73f2307d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def process_file(filepath):\n",
    "    filename = os.path.basename(filepath).split('.')[0]\n",
    "    npz_file = np.load(filepath)\n",
    "    waveform_arr = npz_file['waveform']\n",
    "    \n",
    "    short_lead_arr = waveform_arr[:12]\n",
    "    long_lead_arr = waveform_arr[12:]\n",
    "    short_lead_arr = np.nan_to_num(short_lead_arr)\n",
    "\n",
    "    compressed_arr = np.zeros((3, 5000))\n",
    "\n",
    "    # Sum the specified channels for each new channel\n",
    "    compressed_arr[0, :] = short_lead_arr[0, :] + short_lead_arr[3, :] + short_lead_arr[6, :] + short_lead_arr[9, :]\n",
    "    compressed_arr[1, :] = short_lead_arr[1, :] + short_lead_arr[4, :] + short_lead_arr[7, :] + short_lead_arr[10, :]\n",
    "    compressed_arr[2, :] = short_lead_arr[2, :] + short_lead_arr[5, :] + short_lead_arr[8, :] + short_lead_arr[11, :]\n",
    "\n",
    "    compressed_arr = np.concatenate((compressed_arr, long_lead_arr), axis=0)\n",
    "    \n",
    "    savepath = os.path.join(waveform_path, f'{filename}.npy')\n",
    "    np.save(savepath, compressed_arr)\n",
    "\n",
    "\n",
    "os.chdir('/home/ngsci')\n",
    "\n",
    "waveform_path = '/home/ngsci/project/NEJM_benchmark/waveforms_all_channel'\n",
    "# npz_files = [os.path.join(waveform_path, f) for f in os.listdir(waveform_path) if f.endswith('.npz')]\n",
    "\n",
    "# Use multiprocessing to process files\n",
    "with Pool(processes=os.cpu_count()) as pool:\n",
    "    list(tqdm(pool.imap(process_file, npz_files), total=len(npz_files)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
