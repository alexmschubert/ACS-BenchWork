{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68ca3cda-2103-4e01-a3ac-1f9ab08a9eb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://devpi.svc.ngsci.local/root/pypi/+simple/\n",
      "Collecting confidenceinterval\n",
      "  Using cached confidenceinterval-1.0.5-py3-none-any.whl\n",
      "Collecting setuptools~=68.2.0\n",
      "  Using cached https://devpi.svc.ngsci.local/root/pypi/%2Bf/b45/4a35605876da6/setuptools-68.2.2-py3-none-any.whl (807 kB)\n",
      "Requirement already satisfied: scikit-learn in /opt/venv/default/lib/python3.10/site-packages (from confidenceinterval) (1.2.2)\n",
      "Requirement already satisfied: pandas in /opt/venv/default/lib/python3.10/site-packages (from confidenceinterval) (2.0.1)\n",
      "Requirement already satisfied: numpy in /opt/venv/default/lib/python3.10/site-packages (from confidenceinterval) (1.23.5)\n",
      "Requirement already satisfied: statsmodels in /opt/venv/default/lib/python3.10/site-packages (from confidenceinterval) (0.13.5)\n",
      "Requirement already satisfied: scipy in /opt/venv/default/lib/python3.10/site-packages (from confidenceinterval) (1.10.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/venv/default/lib/python3.10/site-packages (from pandas->confidenceinterval) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/venv/default/lib/python3.10/site-packages (from pandas->confidenceinterval) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/venv/default/lib/python3.10/site-packages (from pandas->confidenceinterval) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/venv/default/lib/python3.10/site-packages (from scikit-learn->confidenceinterval) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/venv/default/lib/python3.10/site-packages (from scikit-learn->confidenceinterval) (1.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/venv/default/lib/python3.10/site-packages (from statsmodels->confidenceinterval) (23.1)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/venv/default/lib/python3.10/site-packages (from statsmodels->confidenceinterval) (0.5.3)\n",
      "Requirement already satisfied: six in /opt/venv/default/lib/python3.10/site-packages (from patsy>=0.5.2->statsmodels->confidenceinterval) (1.16.0)\n",
      "Installing collected packages: setuptools, confidenceinterval\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 65.5.0\n",
      "    Uninstalling setuptools-65.5.0:\n",
      "      Successfully uninstalled setuptools-65.5.0\n",
      "Successfully installed confidenceinterval-1.0.5 setuptools-68.2.2\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install confidenceinterval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67f70865-e7b9-44ac-aecb-249f4fc51979",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import mode\n",
    "from scipy import stats\n",
    "from multiprocessing import Pool\n",
    "import neurokit2 as nk\n",
    "from biosppy.signals import ecg\n",
    "import biosppy\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from confidenceinterval import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92595517-1bd2-44c1-8b5a-1e898b616518",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecg_id</th>\n",
       "      <th>ecg_id_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ecg162c83f05d</td>\n",
       "      <td>162c83f05d.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ecg86065367ee</td>\n",
       "      <td>86065367ee.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ecgdd0d198786</td>\n",
       "      <td>dd0d198786.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ecge81f90e55f</td>\n",
       "      <td>e81f90e55f.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ecg7bad30ef89</td>\n",
       "      <td>7bad30ef89.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ecg_id      ecg_id_new\n",
       "0  ecg162c83f05d  162c83f05d.npy\n",
       "1  ecg86065367ee  86065367ee.npy\n",
       "2  ecgdd0d198786  dd0d198786.npy\n",
       "3  ecge81f90e55f  e81f90e55f.npy\n",
       "4  ecg7bad30ef89  7bad30ef89.npy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"/home/ngsci/project/NEJM_benchmark/all_ids_labels_tested_with_covars_all.csv\")\n",
    "display(test_df[['ecg_id','ecg_id_new']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbb512bc-f589-4373-9e5a-776411079cb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Define input and output directories\n",
    "#input_dir = \"/home/ngsci/project/NEJM_benchmark/waveforms/\"\n",
    "#input_dir = \"/home/ngsci/project/NEJM_benchmark/waveforms_3by4/\"\n",
    "#input_dir = \"/home/ngsci/project/NEJM_benchmark/waveforms_3by4/\"\n",
    "input_dir = \"/home/ngsci/project/NEJM_benchmark/waveforms_all_channel/\"\n",
    "output_dir = \"/home/ngsci/project/NEJM_benchmark/waveforms_med_beat/\"\n",
    "\n",
    "# List all files in the input directory\n",
    "ecg_files = os.listdir(input_dir)\n",
    "\n",
    "ecg_file = ecg_files[0]\n",
    "file_path = os.path.join(input_dir, ecg_file)\n",
    "ecg_data = np.load(file_path)\n",
    "\n",
    "print(ecg_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff07861e-1189-4020-9bd8-6935c764c4f8",
   "metadata": {},
   "source": [
    "### Some playing around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "964ed0fd-048b-456a-91ae-20164d98177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform_array = np.load('/home/ngsci/datasets/ed-bwh-ecg/v1/ecg-waveform.npy')\n",
    "ed_encounter = pd.read_csv('/home/ngsci/datasets/ed-bwh-ecg/v1/ed-encounter.csv')\n",
    "ecg_metadata = pd.read_csv('/home/ngsci/datasets/ed-bwh-ecg/v1/ecg-metadata.csv')\n",
    "ecg_npy = pd.read_csv('/home/ngsci/datasets/ed-bwh-ecg/v1/ecg-npy-index.csv')\n",
    "patient = pd.read_csv('/home/ngsci/datasets/ed-bwh-ecg/v1/patient.csv')\n",
    "ecg_to_ed_enc = pd.read_csv('/home/ngsci/datasets/ed-bwh-ecg/v1/ecg-ed-enc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40fcbb83-aa5b-444f-a8aa-9f28d389ed82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove ecg string from ID\n",
    "ecg_metadata['ecg_id_new'] = ecg_metadata['ecg_id'].str[3:]\n",
    "ecg_npy['ecg_id_new'] = ecg_npy['ecg_id'].str[3:]\n",
    "ecg_to_ed_enc['ecg_id_new'] = ecg_to_ed_enc['ecg_id'].str[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab4e351a-ea1f-4151-9e22-9cbf3cf97903",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112900, 40)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform_array.shape\n",
    "ecg_npy.shape\n",
    "ecg_metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f13c8ed3-800e-4a9d-a7c0-8fad2002e970",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71460, 28)\n",
      "28009\n"
     ]
    }
   ],
   "source": [
    "print(ed_encounter.shape)\n",
    "print(ed_encounter.exclude.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422fe3a5-7015-44d3-b9b6-b19a13c72446",
   "metadata": {},
   "source": [
    "### Assess quality of guideline-based AMI labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62edd9e2-5e9d-456d-8a8e-c4269f6fa4fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Create dataset that has ECG metadata and testing information\n",
    "###########################################\n",
    "## Get encounter ID into the dataframe \n",
    "###########################################\n",
    "\n",
    "# Check if the columns in ecg_to_ed_enc (except 'ecg_id') are not in ecg_metadata\n",
    "ecg_to_ed_enc_new = ecg_to_ed_enc.drop('ecg_id', axis=1)\n",
    "columns_to_check = [col for col in ecg_to_ed_enc.columns if col != 'ecg_id' and col != 'ecg_id_new']\n",
    "if not any(col in ecg_metadata.columns for col in columns_to_check):\n",
    "    # Merge the DataFrames\n",
    "    merged_df = pd.merge(ecg_metadata, ecg_to_ed_enc_new, on='ecg_id_new', how='left')\n",
    "    print('done')\n",
    "else:\n",
    "    print(\"Merge not performed: Columns from ecg_to_ed_enc already exist in ecg_metadata.\")\n",
    "\n",
    "###########################################\n",
    "## Get encounter information into dataframe \n",
    "###########################################\n",
    "\n",
    "# Check if the columns in ecg_to_ed_enc (except 'ecg_id') are not in ecg_metadata\n",
    "ed_encounter_new = ed_encounter.drop('patient_ngsci_id', axis=1)\n",
    "columns_to_check = [col for col in ed_encounter.columns if col not in ['ed_enc_id','patient_ngsci_id']]\n",
    "if not any(col in merged_df.columns for col in columns_to_check):\n",
    "    # Merge the DataFrames\n",
    "    ecg_analysis_df = pd.merge(merged_df, ed_encounter_new, on='ed_enc_id', how='left')\n",
    "    print('done')\n",
    "else:\n",
    "    print(\"Merge not performed: Columns from merged_df already exist in ed_encounter.\")\n",
    "    \n",
    "###########################################\n",
    "## Get patient info into dataframe \n",
    "###########################################\n",
    "\n",
    "# Check if the columns in ecg_to_ed_enc (except 'ecg_id') are not in ecg_metadata\n",
    "columns_to_check = [col for col in patient.columns if col not in ['ed_enc_id','patient_ngsci_id']]\n",
    "if not any(col in merged_df.columns for col in columns_to_check):\n",
    "    # Merge the DataFrames\n",
    "    ecg_analysis_df = pd.merge(ecg_analysis_df, patient, on='patient_ngsci_id', how='left')\n",
    "    print('done')\n",
    "else:\n",
    "    print(\"Merge not performed: Columns from merged_df already exist in ed_encounter.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d35485b1-0b81-4da9-a1be-f3a886810a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ecg_analysis_df.columns)\n",
    "# ecg_analysis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf0a2bba-5d7a-4bc3-98b0-dcca7ed94a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112900, 78)\n",
      "(61680, 78)\n",
      "\n",
      "(112900, 78)\n",
      "(73392, 78)\n",
      "(8198, 78)\n"
     ]
    }
   ],
   "source": [
    "###############################################################\n",
    "## Restrict sample to patients included in QJE paper \n",
    "###############################################################\n",
    "\n",
    "## CHECK THIS FILTER MAY BE A BIG PROBLEM AND SHOULD BE RECONSIDERED\n",
    "ecg_analysis_df_included = ecg_analysis_df[ecg_analysis_df['exclude']==False]\n",
    "ecg_analysis_df_tested = ecg_analysis_df[ecg_analysis_df['test_010_day']==True]\n",
    "print(ecg_analysis_df.shape)\n",
    "print(ecg_analysis_df_included.shape)\n",
    "\n",
    "ecg_analysis_df_included_all = ecg_analysis_df[ecg_analysis_df['exclude_modeling']==False]\n",
    "ecg_analysis_df_tested_all = ecg_analysis_df_included_all[ecg_analysis_df_included_all['test_010_day']==True]\n",
    "print()\n",
    "print(ecg_analysis_df.shape)\n",
    "print(ecg_analysis_df_included_all.shape)\n",
    "print(ecg_analysis_df_tested_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "942c8af1-d3bd-4a6a-955d-956f3ec2f1ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112900, 78)\n",
      "(73392, 78)\n",
      "(8198, 78)\n",
      "(65194, 78)\n"
     ]
    }
   ],
   "source": [
    "###############################################################\n",
    "## Restrict sample to patients that were tested\n",
    "###############################################################\n",
    "print(ecg_analysis_df.shape)\n",
    "print(ecg_analysis_df_included_all.shape)\n",
    "ecg_analysis_df_included_tested_all = ecg_analysis_df_included_all[ecg_analysis_df_included_all['test_010_day']==True]\n",
    "ecg_analysis_df_included_untested_all = ecg_analysis_df_included_all[ecg_analysis_df_included_all['test_010_day']==False]\n",
    "print(ecg_analysis_df_included_tested_all.shape)\n",
    "print(ecg_analysis_df_included_untested_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3835b8-482b-492e-af52-4ee073fe869f",
   "metadata": {},
   "source": [
    "## Construct Table 1 (encounter level, as dataset overview)\n",
    "\n",
    "Rationale demographics e.g. age may change between different patient encounters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "948da201-f368-45c1-aeef-684deb18d344",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ecg_ed_enc_meta = ecg_to_ed_enc.merge(ecg_metadata, on='ecg_id', how='left')\n",
    "ecg_ed_enc_meta_merge = ecg_ed_enc_meta[['ed_enc_id','has_twave_inver', 'has_depress', 'has_st_eleva','has_afib']] #'ecg_id', \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d833a86a-420c-49f4-a6c5-a4325f66b4c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encounter_w_demographic_df = (\n",
    "    ed_encounter\n",
    "    .merge(    \n",
    "        patient, \n",
    "        on='patient_ngsci_id', \n",
    "        how='left'\n",
    "    )\n",
    "    # .merge(ecg_metadata,\n",
    "    #        on='ed_enc_id',\n",
    "    #        how='left')\n",
    "    .merge(\n",
    "        ( # merge in ECG counts for each encounter\n",
    "            ecg_to_ed_enc\n",
    "            .groupby('ed_enc_id')\n",
    "            .agg(ecg_cnt=pd.NamedAgg(column=\"ecg_id\", aggfunc=\"count\"))\n",
    "            .reset_index()\n",
    "        ),\n",
    "        on='ed_enc_id',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    ")\n",
    "\n",
    "encounter_w_demographic_df = encounter_w_demographic_df.merge(\n",
    "        ( # merge in ECG characteristics\n",
    "            ecg_ed_enc_meta_merge\n",
    "            .groupby('ed_enc_id')\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        ),\n",
    "        on='ed_enc_id',\n",
    "        how='left'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7a9fae7-75a3-4ecb-8a94-16754dc9e720",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['patient_ngsci_id', 'ed_enc_id', 'start_datetime', 'end_datetime',\n",
       "       'age_at_admit', 'macetrop_030_pos', 'death_030_day',\n",
       "       'macetrop_pos_or_death_030', 'stent_010_day', 'cabg_010_day',\n",
       "       'stent_or_cabg_010_day', 'ami_day_of', 'days_to_ami', 'maxtrop_sameday',\n",
       "       'tn_group_sameday', 'disch_disp', 'disch_obs', 'test_010_day',\n",
       "       'stress_010_day', 'cath_010_day', 'days_to_stress', 'days_to_cath',\n",
       "       'first_test', 'excl_flag_c_int', 'excl_flag_chronic', 'excl_flag_death',\n",
       "       'exclude_modeling', 'exclude', 'sex', 'race_black', 'race_hispanic',\n",
       "       'race_white', 'race_other', 'agi_under_25k', 'agi_25k_to_50k',\n",
       "       'agi_50k_to_75k', 'agi_75k_to_100k', 'agi_100k_to_200k',\n",
       "       'agi_above_200k', 'ecg_cnt', 'has_twave_inver', 'has_depress',\n",
       "       'has_st_eleva', 'has_afib'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encounter_w_demographic_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "137cdf43-5206-418a-aa36-34e78ca4f7cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_stats_for_ed_encounters(df):\n",
    "    '''Get statistics for demographics and key variables.'''\n",
    "    output = pd.Series()\n",
    "    # counts\n",
    "    enc_counts = pd.Series()\n",
    "    enc_counts.loc['Visits'] = df['ed_enc_id'].nunique()\n",
    "    enc_counts.loc['Patients'] = df['patient_ngsci_id'].nunique()\n",
    "    enc_counts.loc['ECGs'] = df['ecg_cnt'].sum().astype(int)\n",
    "    enc_counts = enc_counts.apply('{:,d}'.format)\n",
    "    output = pd.concat([output,enc_counts])\n",
    "    \n",
    "    # demographics - age\n",
    "    demographics = pd.Series()\n",
    "    age_mean = df['age_at_admit'].mean()\n",
    "    age_sem = df['age_at_admit'].sem()\n",
    "    demographics.loc['Age Mean (years)'] = f\"{age_mean:.2f} ({age_sem:.3f})\"\n",
    "    \n",
    "    # demographics - sex\n",
    "    sex_stats = df['sex'].value_counts(normalize=True, dropna=False)\n",
    "    female_pct = sex_stats.get('Female', 0)  # Use .get to avoid KeyError if 'Female' is not a category\n",
    "    female_sem = np.sqrt(female_pct * (1 - female_pct) / len(df))\n",
    "    demographics.loc['Female'] = f\"{female_pct:.3g} ({female_sem:.3f})\"\n",
    "    \n",
    "    # demographics - race\n",
    "    for race in ['black', 'hispanic', 'white', 'other']:\n",
    "        mean = df[f'race_{race}'].mean()\n",
    "        sem = df[f'race_{race}'].sem()\n",
    "        demographics.loc[race.capitalize()] = f\"{mean:.3g} ({sem:.3f})\"\n",
    "    \n",
    "    output.loc['Demographics'] = ''\n",
    "    output = pd.concat([output, demographics])\n",
    "    \n",
    "#     # key variables\n",
    "#     key_variables = pd.Series()\n",
    "#     for var, label in [('has_afib', 'Atrial fibrillation'), \n",
    "#                        ('has_st_eleva', 'ST elevation'),\n",
    "#                       ('has_depress', 'ST depression'),\n",
    "#                       ('has_twave_inver', 'T-wave inversion'),]:\n",
    "#         mean = df[var].replace({True: 1, False: 0}).mean()\n",
    "#         sem = df[var].replace({True: 1, False: 0}).sem()\n",
    "#         key_variables.loc[label] = f\"{mean:.3g} ({sem:.3f})\"\n",
    "    \n",
    "#     output.loc['Rhythm abnormalities'] = ''\n",
    "#     output = pd.concat([output, key_variables])\n",
    "    \n",
    "    # key variables\n",
    "    key_variables = pd.Series()\n",
    "    for var, label in [('stent_or_cabg_010_day', 'Positive Test'), \n",
    "                       ('macetrop_pos_or_death_030', 'Adverse Event')]:\n",
    "        mean = round(df[var].replace({True: 1, False: 0}).mean(),4)\n",
    "        sem = df[var].replace({True: 1, False: 0}).sem()\n",
    "        key_variables.loc[label] = f\"{mean:.3g} ({sem:.3f})\"\n",
    "    \n",
    "    output.loc['Outcomes'] = ''\n",
    "    output = pd.concat([output, key_variables])\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64289270-786c-460b-a68b-cadf63859c72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encounter_w_demographic_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "541de1e2-1209-420c-9c79-c3ab15ccadee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_458/205766762.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ecg_analysis_df_included_all['ecg_cnt'] = 1\n",
      "/tmp/ipykernel_458/205766762.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ecg_analysis_df_tested_all['ecg_cnt'] = 1\n",
      "/tmp/ipykernel_458/205766762.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ecg_analysis_df_included_untested_all['ecg_cnt'] = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All</th>\n",
       "      <th>Included</th>\n",
       "      <th>Tested</th>\n",
       "      <th>Untested</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Visits</th>\n",
       "      <td>71,460</td>\n",
       "      <td>51,158</td>\n",
       "      <td>4,609</td>\n",
       "      <td>46,549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patients</th>\n",
       "      <td>44,713</td>\n",
       "      <td>35,595</td>\n",
       "      <td>3,982</td>\n",
       "      <td>33,025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECGs</th>\n",
       "      <td>112,900</td>\n",
       "      <td>73,392</td>\n",
       "      <td>8,198</td>\n",
       "      <td>65,194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demographics</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age Mean (years)</th>\n",
       "      <td>58.28 (0.058)</td>\n",
       "      <td>54.91 (0.070)</td>\n",
       "      <td>61.59 (0.159)</td>\n",
       "      <td>54.07 (0.076)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>0.548 (0.001)</td>\n",
       "      <td>0.561 (0.002)</td>\n",
       "      <td>0.443 (0.005)</td>\n",
       "      <td>0.576 (0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black</th>\n",
       "      <td>0.211 (0.001)</td>\n",
       "      <td>0.233 (0.002)</td>\n",
       "      <td>0.193 (0.004)</td>\n",
       "      <td>0.239 (0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic</th>\n",
       "      <td>0.142 (0.001)</td>\n",
       "      <td>0.165 (0.001)</td>\n",
       "      <td>0.127 (0.004)</td>\n",
       "      <td>0.17 (0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.572 (0.001)</td>\n",
       "      <td>0.522 (0.002)</td>\n",
       "      <td>0.608 (0.005)</td>\n",
       "      <td>0.512 (0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.0749 (0.001)</td>\n",
       "      <td>0.0791 (0.001)</td>\n",
       "      <td>0.0725 (0.003)</td>\n",
       "      <td>0.0799 (0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outcomes</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Test</th>\n",
       "      <td>0.0164 (0.000)</td>\n",
       "      <td>0.0207 (0.001)</td>\n",
       "      <td>0.185 (0.004)</td>\n",
       "      <td>0 (0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adverse Event</th>\n",
       "      <td>0.161 (0.001)</td>\n",
       "      <td>0.108 (0.001)</td>\n",
       "      <td>0.338 (0.005)</td>\n",
       "      <td>0.0793 (0.001)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             All        Included          Tested   \n",
       "Visits                    71,460          51,158           4,609  \\\n",
       "Patients                  44,713          35,595           3,982   \n",
       "ECGs                     112,900          73,392           8,198   \n",
       "Demographics                                                       \n",
       "Age Mean (years)   58.28 (0.058)   54.91 (0.070)   61.59 (0.159)   \n",
       "Female             0.548 (0.001)   0.561 (0.002)   0.443 (0.005)   \n",
       "Black              0.211 (0.001)   0.233 (0.002)   0.193 (0.004)   \n",
       "Hispanic           0.142 (0.001)   0.165 (0.001)   0.127 (0.004)   \n",
       "White              0.572 (0.001)   0.522 (0.002)   0.608 (0.005)   \n",
       "Other             0.0749 (0.001)  0.0791 (0.001)  0.0725 (0.003)   \n",
       "Outcomes                                                           \n",
       "Positive Test     0.0164 (0.000)  0.0207 (0.001)   0.185 (0.004)   \n",
       "Adverse Event      0.161 (0.001)   0.108 (0.001)   0.338 (0.005)   \n",
       "\n",
       "                        Untested  \n",
       "Visits                    46,549  \n",
       "Patients                  33,025  \n",
       "ECGs                      65,194  \n",
       "Demographics                      \n",
       "Age Mean (years)   54.07 (0.076)  \n",
       "Female             0.576 (0.002)  \n",
       "Black              0.239 (0.002)  \n",
       "Hispanic            0.17 (0.001)  \n",
       "White              0.512 (0.002)  \n",
       "Other             0.0799 (0.001)  \n",
       "Outcomes                          \n",
       "Positive Test          0 (0.000)  \n",
       "Adverse Event     0.0793 (0.001)  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "included_df = encounter_w_demographic_df.query('exclude_modeling == False') \n",
    "#included_df = encounter_w_demographic_df.query('exclude == False')\n",
    "tested_df = included_df.query('test_010_day == True')\n",
    "untested_df = included_df.query('test_010_day == False')\n",
    "\n",
    "ecg_analysis_df['ecg_cnt'] = 1\n",
    "ecg_analysis_df_included_all['ecg_cnt'] = 1\n",
    "ecg_analysis_df_tested_all['ecg_cnt'] = 1\n",
    "ecg_analysis_df_included_untested_all['ecg_cnt'] = 1\n",
    "\n",
    "column_subsets = {\n",
    "    'All': ecg_analysis_df, #encounter_w_demographic_df,\n",
    "    'Included': ecg_analysis_df_included_all, #included_df,\n",
    "    'Tested': ecg_analysis_df_tested_all, #tested_df,\n",
    "    'Untested': ecg_analysis_df_included_untested_all #untested_df,\n",
    "}\n",
    "\n",
    "table1 = pd.DataFrame()\n",
    "for col_name, col_subset in column_subsets.items():\n",
    "    table1[col_name] = get_stats_for_ed_encounters(col_subset)\n",
    "\n",
    "table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3103a3c4-a06c-419f-8507-e165db983d3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_stats_for_ed_encounters(df):\n",
    "    '''Get statistics for demographics and key variables.'''\n",
    "    output = pd.Series()\n",
    "    # counts\n",
    "    enc_counts = pd.Series()\n",
    "    enc_counts.loc['Visits'] = df['ed_enc_id'].nunique()\n",
    "    enc_counts.loc['Patients'] = df['patient_ngsci_id'].nunique()\n",
    "    enc_counts.loc['ECGs'] = df['ecg_cnt'].sum()\n",
    "    enc_counts = enc_counts.apply('{:,d}'.format)\n",
    "    output = pd.concat([output, enc_counts])\n",
    "    \n",
    "    # Cardiac Rhythm diagnosis\n",
    "    rhythm = pd.Series()\n",
    "    for condition in ['has_rhythm_disturbance', 'has_afib', 'has_st_eleva', 'has_depress', 'has_twave_inver']:\n",
    "        mean_value = df[condition].mean()\n",
    "        sem_value = df[condition].sem()\n",
    "        label = ' '.join([word.capitalize() for word in condition.split('_')])\n",
    "        rhythm.loc[label] = f\"{mean_value:.3g} ({sem_value:.3f})\"\n",
    "    \n",
    "    output.loc['Rhythm abnormalities'] = ''\n",
    "    output = pd.concat([output, rhythm])\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06c6a777-fb7b-4724-a6d6-5e1e8b884be8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_458/1948896224.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ecg_analysis_df_included_tested_all['ecg_cnt'] = 1\n",
      "/tmp/ipykernel_458/1948896224.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ecg_analysis_df_included_untested_all['ecg_cnt'] = 1\n",
      "/tmp/ipykernel_458/1948896224.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ecg_analysis_df_included['female'] = (ecg_analysis_df_included['sex'] == \"Female\").astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All</th>\n",
       "      <th>Included</th>\n",
       "      <th>Tested</th>\n",
       "      <th>Untested</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Visits</th>\n",
       "      <td>71,460</td>\n",
       "      <td>51,158</td>\n",
       "      <td>4,609</td>\n",
       "      <td>46,549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patients</th>\n",
       "      <td>44,713</td>\n",
       "      <td>35,595</td>\n",
       "      <td>3,982</td>\n",
       "      <td>33,025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECGs</th>\n",
       "      <td>112,900</td>\n",
       "      <td>73,392</td>\n",
       "      <td>8,198</td>\n",
       "      <td>65,194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rhythm abnormalities</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Has Rhythm Disturbance</th>\n",
       "      <td>0.228 (0.001)</td>\n",
       "      <td>0.201 (0.001)</td>\n",
       "      <td>0.285 (0.005)</td>\n",
       "      <td>0.191 (0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Has Afib</th>\n",
       "      <td>0.0827 (0.001)</td>\n",
       "      <td>0.0684 (0.001)</td>\n",
       "      <td>0.0853 (0.003)</td>\n",
       "      <td>0.0663 (0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Has St Eleva</th>\n",
       "      <td>0.0155 (0.000)</td>\n",
       "      <td>0.0158 (0.000)</td>\n",
       "      <td>0.0429 (0.002)</td>\n",
       "      <td>0.0123 (0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Has Depress</th>\n",
       "      <td>0.0173 (0.000)</td>\n",
       "      <td>0.0144 (0.000)</td>\n",
       "      <td>0.0307 (0.002)</td>\n",
       "      <td>0.0124 (0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Has Twave Inver</th>\n",
       "      <td>0.0759 (0.001)</td>\n",
       "      <td>0.0663 (0.001)</td>\n",
       "      <td>0.106 (0.003)</td>\n",
       "      <td>0.0614 (0.001)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   All        Included          Tested   \n",
       "Visits                          71,460          51,158           4,609  \\\n",
       "Patients                        44,713          35,595           3,982   \n",
       "ECGs                           112,900          73,392           8,198   \n",
       "Rhythm abnormalities                                                     \n",
       "Has Rhythm Disturbance   0.228 (0.001)   0.201 (0.001)   0.285 (0.005)   \n",
       "Has Afib                0.0827 (0.001)  0.0684 (0.001)  0.0853 (0.003)   \n",
       "Has St Eleva            0.0155 (0.000)  0.0158 (0.000)  0.0429 (0.002)   \n",
       "Has Depress             0.0173 (0.000)  0.0144 (0.000)  0.0307 (0.002)   \n",
       "Has Twave Inver         0.0759 (0.001)  0.0663 (0.001)   0.106 (0.003)   \n",
       "\n",
       "                              Untested  \n",
       "Visits                          46,549  \n",
       "Patients                        33,025  \n",
       "ECGs                            65,194  \n",
       "Rhythm abnormalities                    \n",
       "Has Rhythm Disturbance   0.191 (0.002)  \n",
       "Has Afib                0.0663 (0.001)  \n",
       "Has St Eleva            0.0123 (0.000)  \n",
       "Has Depress             0.0124 (0.000)  \n",
       "Has Twave Inver         0.0614 (0.001)  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecg_analysis_df['ecg_cnt'] = 1\n",
    "ecg_analysis_df_included_tested_all['ecg_cnt'] = 1\n",
    "ecg_analysis_df_included_untested_all['ecg_cnt'] = 1\n",
    "ecg_analysis_df['female'] = (ecg_analysis_df['sex'] == \"Female\").astype(int)\n",
    "ecg_analysis_df_included_modelling = ecg_analysis_df[ecg_analysis_df['exclude_modeling']==False]\n",
    "ecg_analysis_df_included = ecg_analysis_df[ecg_analysis_df['exclude']==False]\n",
    "ecg_analysis_df_included['female'] = (ecg_analysis_df_included['sex'] == \"Female\").astype(int)\n",
    "ecg_analysis_df_included_tested = ecg_analysis_df_included[ecg_analysis_df_included['test_010_day']==True]\n",
    "ecg_analysis_df_included_untested = ecg_analysis_df_included[ecg_analysis_df_included['test_010_day']==False]\n",
    "\n",
    "column_subsets = {\n",
    "    'All': ecg_analysis_df,\n",
    "    'Included': ecg_analysis_df_included_modelling,\n",
    "#    'Included': ecg_analysis_df_included,\n",
    "    'Tested': ecg_analysis_df_included_tested_all,\n",
    "    'Untested': ecg_analysis_df_included_untested_all,\n",
    "}\n",
    "\n",
    "table1 = pd.DataFrame()\n",
    "for col_name, col_subset in column_subsets.items():\n",
    "    table1[col_name] = get_stats_for_ed_encounters(col_subset)\n",
    "\n",
    "table1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df33c2b8-21a5-4412-8fa1-f38e60dac206",
   "metadata": {},
   "source": [
    "### Testing yield analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e68b05-5f23-4249-94cb-d2a4b4460d0a",
   "metadata": {},
   "source": [
    "Notes \n",
    "\n",
    "Human judgement challenges\n",
    "Fact about %STE/STD/TWI with +test (st elevation, t wave inversion, st depression)\n",
    "Define 3 Human labels that imply cardiologist was worried about MI\n",
    "st elevation, st depression; lesser - t wave abnormality\n",
    "Any of these 3\n",
    "For each label (for suspicious ECG) calculate\n",
    "%tested\n",
    "%yield if tested (TPR)\n",
    "%yields that occur in those without label (1-sens???)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31e8093a-20b2-41d8-a841-985da4723d13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation for label: has_st_eleva\n",
      "\n",
      "Prevalence of has_st_eleva among all included ECGs is 1.58%\n",
      "The testing rate among those with has_st_eleva is 30.45%\n",
      "Prevalence of has_st_eleva among all ECGs corresponding to visits with subsequent definitive AMI testing is 4.29%\n",
      "The testing yield among those with has_st_eleva is 53.41%\n",
      "Of all identified ACS among those with testing 12.38% presented with has_st_eleva in their ECG\n",
      "The testing yield among those without has_st_eleva is 16.95%\n",
      "\n",
      "\n",
      "The testing yield among all tested patients 18.52%\n",
      "\n",
      "AUC for has_st_eleva: 0.5496 (0.541154748773732, 0.5581414634226181)\n",
      "\n",
      "\n",
      "Evaluation for label: has_twave_inver\n",
      "\n",
      "Prevalence of has_twave_inver among all included ECGs is 6.63%\n",
      "The testing rate among those with has_twave_inver is 17.79%\n",
      "Prevalence of has_twave_inver among all ECGs corresponding to visits with subsequent definitive AMI testing is 10.56%\n",
      "The testing yield among those with has_twave_inver is 23.9%\n",
      "Of all identified ACS among those with testing 13.64% presented with has_twave_inver in their ECG\n",
      "The testing yield among those without has_twave_inver is 17.88%\n",
      "\n",
      "\n",
      "The testing yield among all tested patients 18.52%\n",
      "\n",
      "AUC for has_twave_inver: 0.5189 (0.5095098547858137, 0.5282011694985491)\n",
      "\n",
      "\n",
      "Evaluation for label: has_depress\n",
      "\n",
      "Prevalence of has_depress among all included ECGs is 1.44%\n",
      "The testing rate among those with has_depress is 23.77%\n",
      "Prevalence of has_depress among all ECGs corresponding to visits with subsequent definitive AMI testing is 3.0700000000000003%\n",
      "The testing yield among those with has_depress is 42.86%\n",
      "Of all identified ACS among those with testing 7.11% presented with has_depress in their ECG\n",
      "The testing yield among those without has_depress is 17.74%\n",
      "\n",
      "\n",
      "The testing yield among all tested patients 18.52%\n",
      "\n",
      "AUC for has_depress: 0.5248 (0.5180962798948459, 0.5314931156282254)\n",
      "\n",
      "\n",
      "Evaluation for label: ste_std_twi\n",
      "\n",
      "Prevalence of ste_std_twi among all included ECGs is 8.83%\n",
      "The testing rate among those with ste_std_twi is 19.56%\n",
      "Prevalence of ste_std_twi among all ECGs corresponding to visits with subsequent definitive AMI testing is 15.45%\n",
      "The testing yield among those with ste_std_twi is 31.81%\n",
      "Of all identified ACS among those with testing 26.55% presented with ste_std_twi in their ECG\n",
      "The testing yield among those without ste_std_twi is 16.09%\n",
      "\n",
      "\n",
      "The testing yield among all tested patients 18.52%\n",
      "\n",
      "AUC for ste_std_twi: 0.5681 (0.5562527695763715, 0.5798867424857013)\n",
      "\n",
      "(8198, 80)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_458/1709387696.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ecg_analysis_df_included_modelling['ste_std_twi'] = ecg_analysis_df_included_modelling[['has_st_eleva', 'has_twave_inver', 'has_depress']].any(axis=1)\n",
      "/tmp/ipykernel_458/1709387696.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ecg_analysis_df_tested['ste_std_twi'] = ecg_analysis_df_tested[['has_st_eleva', 'has_twave_inver', 'has_depress']].any(axis=1)\n",
      "/tmp/ipykernel_458/1709387696.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ecg_analysis_df_included_tested_all['ste_std_twi'] = ecg_analysis_df_included_tested_all[['has_st_eleva', 'has_twave_inver', 'has_depress']].any(axis=1)\n"
     ]
    }
   ],
   "source": [
    "###############################################################\n",
    "## Evaluate performance of STE based AMI detection\n",
    "###############################################################\n",
    "\n",
    "def evaluate_testing_performance(testing_label='has_st_eleva'):\n",
    "    print()\n",
    "    print(f'Evaluation for label: {testing_label}')\n",
    "    print()\n",
    "#     ## Depict prevalence of label among included ECGs\n",
    "#     prevalence = round((ecg_analysis_df[ecg_analysis_df[testing_label]==True].shape[0]) / (ecg_analysis_df.shape[0]),4)*100\n",
    "#     print(f'Prevalence of {testing_label} among all ECGs is {prevalence}%')\n",
    "\n",
    "#     ## Testing among those with label\n",
    "#     label_population = ecg_analysis_df[ecg_analysis_df[testing_label]==True]\n",
    "#     testing_rate = round(label_population['test_010_day'].sum()/(label_population.shape[0]),4)*100\n",
    "#     print(f'The testing rate among those with {testing_label} is {testing_rate}%')\n",
    "    \n",
    "    ## Depict prevalence of label among included ECGs\n",
    "    prevalence = round((ecg_analysis_df_included_modelling[ecg_analysis_df_included_modelling[testing_label]==True].shape[0]) / (ecg_analysis_df_included_modelling.shape[0]),4)*100\n",
    "    print(f'Prevalence of {testing_label} among all included ECGs is {prevalence}%')\n",
    "\n",
    "    ## Testing among those with label\n",
    "    label_population = ecg_analysis_df_included_modelling[ecg_analysis_df_included_modelling[testing_label]==True]\n",
    "    testing_rate = round(label_population['test_010_day'].sum()/(label_population.shape[0]),4)*100\n",
    "    print(f'The testing rate among those with {testing_label} is {testing_rate}%')\n",
    "    \n",
    "    ## Depict prevalence of label among tested ECGs\n",
    "    prevalence = round((ecg_analysis_df_included_tested_all[ecg_analysis_df_included_tested_all[testing_label]==True].shape[0]) / (ecg_analysis_df_included_tested_all.shape[0]),4)*100\n",
    "    print(f'Prevalence of {testing_label} among all ECGs corresponding to visits with subsequent definitive AMI testing is {prevalence}%')\n",
    "\n",
    "    # Testing yield if patient with ECG with label got tested\n",
    "    label_population_tpr = ecg_analysis_df_included_tested_all[ecg_analysis_df_included_tested_all[testing_label]==True]\n",
    "    testing_tpr = round((label_population_tpr['stent_or_cabg_010_day'].sum())/(label_population_tpr.shape[0])*100,2)\n",
    "    print(f'The testing yield among those with {testing_label} is {testing_tpr}%')\n",
    "    \n",
    "    # Share of blockages detected\n",
    "    label_population_tpr = ecg_analysis_df_included_tested_all[ecg_analysis_df_included_tested_all[testing_label]==True]\n",
    "    testing_tpr = round((label_population_tpr['stent_or_cabg_010_day'].sum())/(ecg_analysis_df_included_tested_all['stent_or_cabg_010_day'].sum())*100,2)\n",
    "    print(f'Of all identified ACS among those with testing {testing_tpr}% presented with {testing_label} in their ECG')\n",
    "\n",
    "    # Testing yield if patient with ECG without label got tested\n",
    "    no_label_population_tpr = ecg_analysis_df_included_tested_all[ecg_analysis_df_included_tested_all[testing_label]==False]\n",
    "    testing_tpr = round((no_label_population_tpr['stent_or_cabg_010_day'].sum())/(no_label_population_tpr.shape[0])*100,2)\n",
    "    print(f'The testing yield among those without {testing_label} is {testing_tpr}%')\n",
    "    print()\n",
    "    \n",
    "    print()\n",
    "    label_population_tpr = ecg_analysis_df_included_tested_all\n",
    "    testing_tpr = round((label_population_tpr['stent_or_cabg_010_day'].sum())/(label_population_tpr.shape[0])*100,2)\n",
    "    print(f'The testing yield among all tested patients {testing_tpr}%')\n",
    "    print()\n",
    "    \n",
    "    # Calculate AUC\n",
    "    try:\n",
    "        true_labels =  ecg_analysis_df_included_tested_all['stent_or_cabg_010_day'].astype(int)\n",
    "        predicted_scores = ecg_analysis_df_included_tested_all[testing_label].astype(int)\n",
    "        auc, ci = roc_auc_score(true_labels, predicted_scores,confidence_level=0.95)\n",
    "        # ,\n",
    "        #                     method='bootstrap_bca',\n",
    "        #                     n_resamples=1000\n",
    "\n",
    "        # print(f'Test AUC Score: {auc} ({ci[0]}, {ci[1]})')\n",
    "        # auc = roc_auc_score(true_labels, predicted_scores)\n",
    "        print(f'AUC for {testing_label}: {auc:.4f} ({ci[0]}, {ci[1]})')\n",
    "    except ValueError:\n",
    "        print(f\"Cannot calculate AUC for {testing_label} (possible lack of positive/negative cases).\")\n",
    "    print()\n",
    "\n",
    "ecg_analysis_df['ste_std_twi'] = ecg_analysis_df[['has_st_eleva', 'has_twave_inver', 'has_depress']].any(axis=1)\n",
    "ecg_analysis_df_included_modelling['ste_std_twi'] = ecg_analysis_df_included_modelling[['has_st_eleva', 'has_twave_inver', 'has_depress']].any(axis=1)\n",
    "ecg_analysis_df_tested['ste_std_twi'] = ecg_analysis_df_tested[['has_st_eleva', 'has_twave_inver', 'has_depress']].any(axis=1)\n",
    "ecg_analysis_df_included_tested_all['ste_std_twi'] = ecg_analysis_df_included_tested_all[['has_st_eleva', 'has_twave_inver', 'has_depress']].any(axis=1)\n",
    "    \n",
    "labels = ['has_st_eleva', 'has_twave_inver', 'has_depress', 'ste_std_twi']\n",
    "\n",
    "for label in labels:\n",
    "    evaluate_testing_performance(label)    \n",
    "\n",
    "print(ecg_analysis_df_included_tested_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b9f9096-a470-40c2-b142-d093381ab72c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_3bf7f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3bf7f_level0_col0\" class=\"col_heading level0 col0\" >Label</th>\n",
       "      <th id=\"T_3bf7f_level0_col1\" class=\"col_heading level0 col1\" >Prevalence (%)</th>\n",
       "      <th id=\"T_3bf7f_level0_col2\" class=\"col_heading level0 col2\" >Testing Rate (%)</th>\n",
       "      <th id=\"T_3bf7f_level0_col3\" class=\"col_heading level0 col3\" >Prevalence among ECGs with ACS testing (%)</th>\n",
       "      <th id=\"T_3bf7f_level0_col4\" class=\"col_heading level0 col4\" >Testing Yield (%)</th>\n",
       "      <th id=\"T_3bf7f_level0_col5\" class=\"col_heading level0 col5\" >Share of indentified ACS Cases (%)</th>\n",
       "      <th id=\"T_3bf7f_level0_col6\" class=\"col_heading level0 col6\" >Testing Yield among Negative Cases (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3bf7f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3bf7f_row0_col0\" class=\"data row0 col0\" >ST elevation</td>\n",
       "      <td id=\"T_3bf7f_row0_col1\" class=\"data row0 col1\" >1.58</td>\n",
       "      <td id=\"T_3bf7f_row0_col2\" class=\"data row0 col2\" >30.45</td>\n",
       "      <td id=\"T_3bf7f_row0_col3\" class=\"data row0 col3\" >4.290000</td>\n",
       "      <td id=\"T_3bf7f_row0_col4\" class=\"data row0 col4\" >53.410000</td>\n",
       "      <td id=\"T_3bf7f_row0_col5\" class=\"data row0 col5\" >12.380000</td>\n",
       "      <td id=\"T_3bf7f_row0_col6\" class=\"data row0 col6\" >16.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3bf7f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3bf7f_row1_col0\" class=\"data row1 col0\" >T-wave inversion</td>\n",
       "      <td id=\"T_3bf7f_row1_col1\" class=\"data row1 col1\" >6.63</td>\n",
       "      <td id=\"T_3bf7f_row1_col2\" class=\"data row1 col2\" >17.79</td>\n",
       "      <td id=\"T_3bf7f_row1_col3\" class=\"data row1 col3\" >10.560000</td>\n",
       "      <td id=\"T_3bf7f_row1_col4\" class=\"data row1 col4\" >23.900000</td>\n",
       "      <td id=\"T_3bf7f_row1_col5\" class=\"data row1 col5\" >13.640000</td>\n",
       "      <td id=\"T_3bf7f_row1_col6\" class=\"data row1 col6\" >17.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3bf7f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_3bf7f_row2_col0\" class=\"data row2 col0\" >ST depression</td>\n",
       "      <td id=\"T_3bf7f_row2_col1\" class=\"data row2 col1\" >1.44</td>\n",
       "      <td id=\"T_3bf7f_row2_col2\" class=\"data row2 col2\" >23.77</td>\n",
       "      <td id=\"T_3bf7f_row2_col3\" class=\"data row2 col3\" >3.070000</td>\n",
       "      <td id=\"T_3bf7f_row2_col4\" class=\"data row2 col4\" >42.860000</td>\n",
       "      <td id=\"T_3bf7f_row2_col5\" class=\"data row2 col5\" >7.110000</td>\n",
       "      <td id=\"T_3bf7f_row2_col6\" class=\"data row2 col6\" >17.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3bf7f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_3bf7f_row3_col0\" class=\"data row3 col0\" >Any of 3 features</td>\n",
       "      <td id=\"T_3bf7f_row3_col1\" class=\"data row3 col1\" >8.83</td>\n",
       "      <td id=\"T_3bf7f_row3_col2\" class=\"data row3 col2\" >19.56</td>\n",
       "      <td id=\"T_3bf7f_row3_col3\" class=\"data row3 col3\" >15.450000</td>\n",
       "      <td id=\"T_3bf7f_row3_col4\" class=\"data row3 col4\" >31.810000</td>\n",
       "      <td id=\"T_3bf7f_row3_col5\" class=\"data row3 col5\" >26.550000</td>\n",
       "      <td id=\"T_3bf7f_row3_col6\" class=\"data row3 col6\" >16.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f103e8391e0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# # Updated data for each label\n",
    "# data = {\n",
    "#     \"Label\": [\"has_st_eleva\", \"has_twave_inver\", \"has_depress\", \"ste_std_twi\"],\n",
    "#     \"Prevalence among all ECGs\": [\"1.55%\", \"7.59%\", \"1.73%\", \"9.90%\"],\n",
    "#     \"Testing rate\": [\"23.79%\", \"12.63%\", \"14.98%\", \"13.94%\"],\n",
    "#     \"Prevalence among ECGs with ACS testing\": [\"4.29%\", \"10.56%\", \"3.07%\", \"15.45%\"],\n",
    "#     \"Testing yield with label\": [\"53.41%\", \"23.90%\", \"42.86%\", \"31.81%\"],\n",
    "#     \"Share of ACS with label\": [\"12.38%\", \"13.64%\", \"7.11%\", \"26.55%\"],\n",
    "#     \"Testing yield without label\": [\"16.95%\", \"17.88%\", \"17.74%\", \"16.09%\"]\n",
    "# }\n",
    "\n",
    "# # Create DataFrame\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # Display the updated table\n",
    "# display(df)\n",
    "\n",
    "\n",
    "# Create a DataFrame with the provided data\n",
    "data = {\n",
    "    'Label': ['ST elevation', 'T-wave inversion', 'ST depression', 'Any of 3 features'],\n",
    "    'Prevalence (%)': [1.58, 6.63, 1.44, 8.83],\n",
    "    'Testing Rate (%)': [30.45, 17.79, 23.77, 19.56],\n",
    "    'Prevalence among ECGs with ACS testing (%)': [4.29, 10.56, 3.07, 15.45],\n",
    "    'Testing Yield (%)': [53.41, 23.9, 42.86, 31.81],\n",
    "    'Share of indentified ACS Cases (%)': [12.38, 13.64, 7.11, 26.55],\n",
    "    'Testing Yield among Negative Cases (%)': [16.95, 17.88, 17.74, 16.09] \n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)  \n",
    "\n",
    "# Format the DataFrame for better presentation\n",
    "formatted_table = df.style.format({'Prevalence (%)': '{:.2f}',\n",
    "                                     'Testing Rate (%)': '{:.2f}',\n",
    "                                     'Prevalence among AMI testing (%)': '{:.2f}',\n",
    "                                     'Testing Yield among Positive Cases (%)': '{:.2f}',\n",
    "                                     'ACS Presentation Rate (%)': '{:.2f}',\n",
    "                                     'Testing Yield among Negative Cases (%)': '{:.2f}'})\n",
    "\n",
    "# Display the formatted table\n",
    "formatted_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd597eb4-c9b7-4723-9f60-db080fc2122f",
   "metadata": {},
   "source": [
    "### Create the filelists for the Stanford dataloader  \n",
    "\n",
    "What we need for this:\n",
    "1. Save each waveform as a single npy file\n",
    "2. Create train test eval split and save filename files for each "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da3be8c0-8b1b-441a-87ec-83b106e3dbf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ecg_id  npy_index  ecg_id_new\n",
      "0  ecg00000b759a          0  00000b759a\n",
      "1  ecg000097099c          1  000097099c\n",
      "2  ecg0000ca5d8e          2  0000ca5d8e\n",
      "3  ecg00010d846a          3  00010d846a\n",
      "4  ecg00019b8ba0          4  00019b8ba0\n"
     ]
    }
   ],
   "source": [
    "### Saving single waveforms in a directory\n",
    "print(ecg_npy.head())\n",
    "\n",
    "#Mode of ECG is not informative and may lead to overfitting of models\n",
    "#So I am implementing zero-mode for saved waveforms\n",
    "# for i in tqdm(range(waveform_array.shape[0])):\n",
    "#     ecg = waveform_array[i]\n",
    "#     for i in range(ecg.shape[0]):\n",
    "#         sequence = ecg[i]\n",
    "#         sequence_mode = mode(sequence)[0][0]\n",
    "#         ecg[i] -= sequence_mode\n",
    "#     info = ecg_npy[ecg_npy['npy_index']==i]\n",
    "#     ecg_id = info['ecg_id'].item()\n",
    "#     np.save(f\"/home/ngsci/project/NEJM_benchmark/waveforms/{ecg_id}.npy\",ecg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53767da1-0acc-4c1f-95b9-00c7762e44af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_458/773829370.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ecg_analysis_df_tested_all['female'] = (ecg_analysis_df_tested_all['sex'] == \"Female\").astype(int)\n",
      "/tmp/ipykernel_458/773829370.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_f['split'] = 'train'\n",
      "/tmp/ipykernel_458/773829370.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_f['ecg_id_new'] = df_train_f['ecg_id_new'].astype(str).apply(lambda x: x + '.npy')\n",
      "/tmp/ipykernel_458/773829370.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val_f['split'] = 'train'\n",
      "/tmp/ipykernel_458/773829370.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val_f['ecg_id_new'] = df_val_f['ecg_id_new'].astype(str).apply(lambda x: x + '.npy')\n",
      "/tmp/ipykernel_458/773829370.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_f['split'] = 'valid'\n",
      "/tmp/ipykernel_458/773829370.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_f['ecg_id_new'] = df_test_f['ecg_id_new'].astype(str).apply(lambda x: x + '.npy')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3982\n",
      "['pat001162d6' 'pat002e1ab9' 'pat003cc38d' ... 'patfff96ba2' 'patfffb7549'\n",
      " 'patfffd14bc']\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_458/773829370.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_f['split'] = 'train'\n",
      "/tmp/ipykernel_458/773829370.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_f['ecg_id_new'] = df_train_f['ecg_id_new'].astype(str).apply(lambda x: x + '.npy')\n",
      "/tmp/ipykernel_458/773829370.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val_f['split'] = 'valid'\n",
      "/tmp/ipykernel_458/773829370.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val_f['ecg_id_new'] = df_val_f['ecg_id_new'].astype(str).apply(lambda x: x + '.npy')\n",
      "/tmp/ipykernel_458/773829370.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_f['split'] = 'test'\n",
      "/tmp/ipykernel_458/773829370.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_f['ecg_id_new'] = df_test_f['ecg_id_new'].astype(str).apply(lambda x: x + '.npy')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8198, 81)\n"
     ]
    }
   ],
   "source": [
    "# REPEAT FOR ALL IDS WITH ANGIOGRAPHY\n",
    "ecg_analysis_df_tested_all['female'] = (ecg_analysis_df_tested_all['sex'] == \"Female\").astype(int)\n",
    "patient_ids = ecg_analysis_df_tested_all.patient_ngsci_id.unique() \n",
    "print(len(patient_ids))\n",
    "print(patient_ids)\n",
    "\n",
    "# Splitting the ids into train (50%) and temp (50%)\n",
    "train_ids, temp_ids = train_test_split(patient_ids, test_size=0.5, random_state=0)\n",
    "\n",
    "# Splitting the temp into val (20% of total) and test (30% of total)\n",
    "val_ids, test_ids = train_test_split(temp_ids, test_size=0.6, random_state=0)\n",
    "\n",
    "print(len(train_ids) + len(val_ids) + len(test_ids) - len(patient_ids))\n",
    "\n",
    "#final version\n",
    "df_train_f = ecg_analysis_df_tested_all[ecg_analysis_df_tested_all['patient_ngsci_id'].isin(train_ids)]#[['ecg_id','stent_or_cabg_010_day', 'macetrop_pos_or_death_030','has_st_eleva', 'has_twave_inver', 'has_depress', 'ste_std_twi']]\n",
    "df_train_f['split'] = 'train'\n",
    "df_train_f['ecg_id_new'] = df_train_f['ecg_id_new'].astype(str).apply(lambda x: x + '.npy')\n",
    "df_val_f = ecg_analysis_df_tested_all[ecg_analysis_df_tested_all['patient_ngsci_id'].isin(val_ids)]#[['ecg_id','stent_or_cabg_010_day', 'macetrop_pos_or_death_030', 'has_st_eleva', 'has_twave_inver', 'has_depress', 'ste_std_twi']]\n",
    "df_val_f['split'] = 'train'\n",
    "df_val_f['ecg_id_new'] = df_val_f['ecg_id_new'].astype(str).apply(lambda x: x + '.npy')\n",
    "df_test_f = ecg_analysis_df_tested_all[ecg_analysis_df_tested_all['patient_ngsci_id'].isin(test_ids)]#[['ecg_id','stent_or_cabg_010_day', 'macetrop_pos_or_death_030', 'has_st_eleva', 'has_twave_inver', 'has_depress', 'ste_std_twi']]\n",
    "df_test_f['split'] = 'valid'\n",
    "df_test_f['ecg_id_new'] = df_test_f['ecg_id_new'].astype(str).apply(lambda x: x + '.npy')\n",
    "df_all_f = pd.concat([df_train_f, df_val_f, df_test_f])\n",
    "df_train_f.to_csv('train_ids_labels_with_covars_all_final.csv')\n",
    "df_val_f.to_csv('val_ids_labels_with_covars_all_final.csv')\n",
    "df_test_f.to_csv('test_ids_labels_with_covars_all_final.csv')\n",
    "df_all_f.to_csv('all_ids_labels_tested_with_covars_all_final.csv')\n",
    "\n",
    "# Creating 3 versions of the dataframe\n",
    "df_train_f = ecg_analysis_df_tested_all[ecg_analysis_df_tested_all['patient_ngsci_id'].isin(train_ids)]#[['ecg_id','stent_or_cabg_010_day', 'macetrop_pos_or_death_030','has_st_eleva', 'has_twave_inver', 'has_depress', 'ste_std_twi']]\n",
    "df_train_f['split'] = 'train'\n",
    "df_train_f['ecg_id_new'] = df_train_f['ecg_id_new'].astype(str).apply(lambda x: x + '.npy')\n",
    "df_val_f = ecg_analysis_df_tested_all[ecg_analysis_df_tested_all['patient_ngsci_id'].isin(val_ids)]#[['ecg_id','stent_or_cabg_010_day', 'macetrop_pos_or_death_030', 'has_st_eleva', 'has_twave_inver', 'has_depress', 'ste_std_twi']]\n",
    "df_val_f['split'] = 'valid'\n",
    "df_val_f['ecg_id_new'] = df_val_f['ecg_id_new'].astype(str).apply(lambda x: x + '.npy')\n",
    "df_test_f = ecg_analysis_df_tested_all[ecg_analysis_df_tested_all['patient_ngsci_id'].isin(test_ids)]#[['ecg_id','stent_or_cabg_010_day', 'macetrop_pos_or_death_030', 'has_st_eleva', 'has_twave_inver', 'has_depress', 'ste_std_twi']]\n",
    "df_test_f['split'] = 'test'\n",
    "df_test_f['ecg_id_new'] = df_test_f['ecg_id_new'].astype(str).apply(lambda x: x + '.npy')\n",
    "df_all_f = pd.concat([df_train_f, df_val_f, df_test_f])\n",
    "df_train_f.to_csv('train_ids_labels_with_covars_all.csv')\n",
    "df_val_f.to_csv('val_ids_labels_with_covars_all.csv')\n",
    "df_test_f.to_csv('test_ids_labels_with_covars_all.csv')\n",
    "df_all_f.to_csv('all_ids_labels_tested_with_covars_all.csv')\n",
    "print(df_all_f.shape)\n",
    "\n",
    "# Extract respective ecg ids\n",
    "train_ids = df_train_f['ecg_id_new'].tolist()\n",
    "val_ids = df_val_f['ecg_id_new'].tolist()\n",
    "test_ids = df_test_f['ecg_id_new'].tolist()\n",
    "\n",
    "# ### Create train / val / test split for tested population, split by patient \n",
    "# ecg_analysis_df_included_tested['female'] = (ecg_analysis_df_included_tested['sex'] == \"Female\").astype(int)\n",
    "# patient_ids = ecg_analysis_df_included_tested.patient_ngsci_id.unique() \n",
    "# print(len(patient_ids))\n",
    "# print(patient_ids)\n",
    "\n",
    "# # Splitting the ids into train (50%) and temp (50%)\n",
    "# train_ids, temp_ids = train_test_split(patient_ids, test_size=0.5, random_state=0)\n",
    "\n",
    "# # Splitting the temp into val (20% of total) and test (30% of total)\n",
    "# val_ids, test_ids = train_test_split(temp_ids, test_size=0.6, random_state=0)\n",
    "\n",
    "# # Creating 3 versions of the dataframe\n",
    "# df_train = ecg_analysis_df_included_tested[ecg_analysis_df_included_tested['patient_ngsci_id'].isin(train_ids)]#[['ecg_id','stent_or_cabg_010_day', 'macetrop_pos_or_death_030','has_st_eleva', 'has_twave_inver', 'has_depress', 'ste_std_twi']]\n",
    "# df_train['split'] = 'train'\n",
    "# df_train['ecg_id_new'] = df_train['ecg_id_new'].astype(str).apply(lambda x: x + '.npy')\n",
    "# df_val = ecg_analysis_df_included_tested[ecg_analysis_df_included_tested['patient_ngsci_id'].isin(val_ids)]#[['ecg_id','stent_or_cabg_010_day', 'macetrop_pos_or_death_030', 'has_st_eleva', 'has_twave_inver', 'has_depress', 'ste_std_twi']]\n",
    "# df_val['split'] = 'valid'\n",
    "# df_val['ecg_id_new'] = df_val['ecg_id_new'].astype(str).apply(lambda x: x + '.npy')\n",
    "# df_test = ecg_analysis_df_included_tested[ecg_analysis_df_included_tested['patient_ngsci_id'].isin(test_ids)]#[['ecg_id','stent_or_cabg_010_day', 'macetrop_pos_or_death_030', 'has_st_eleva', 'has_twave_inver', 'has_depress', 'ste_std_twi']]\n",
    "# df_test['split'] = 'test'\n",
    "# df_test['ecg_id_new'] = df_test['ecg_id_new'].astype(str).apply(lambda x: x + '.npy')\n",
    "# print(df_test.head())\n",
    "# df_all = pd.concat([df_train, df_val, df_test])\n",
    "# df_train.to_csv('train_ids_labels_with_covars.csv')\n",
    "# df_val.to_csv('val_ids_labels_with_covars.csv')\n",
    "# df_test.to_csv('test_ids_labels_with_covars.csv')\n",
    "# df_all.to_csv('all_ids_labels_tested_with_covars.csv')\n",
    "\n",
    "# print(df_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "243cee55-07c7-4a05-a801-de7c3c58739e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n",
      "Index(['patient_ngsci_id', 'ecg_id', 'date', 'p-r-t_axes', 'p_axes', 'r_axes',\n",
      "       't_axes', 'pr_interval', 'pr_interval_units', 'qrs_duration',\n",
      "       'qrs_duration_units', 'qtqtc', 'qt_interval', 'qt_interval_units',\n",
      "       'qtc_interval', 'qtc_interval_units', 'vent_rate', 'vent_rate_units',\n",
      "       'has_bbb', 'has_afib', 'has_st', 'has_pacemaker', 'has_lvh',\n",
      "       'has_normal', 'has_normal_ecg', 'has_normal_sinus', 'has_depress',\n",
      "       'has_st_eleva', 'has_twave', 'has_aberran_bbb', 'has_jpoint_repol',\n",
      "       'has_jpoint_eleva', 'has_twave_inver', 'has_twave_abnormal',\n",
      "       'has_nonspecific', 'has_rhythm_disturbance', 'has_prolonged_qt',\n",
      "       'has_lead_reversal', 'has_poor_or_quality', 'ecg_id_new', 'ed_enc_id',\n",
      "       'start_datetime', 'end_datetime', 'age_at_admit', 'macetrop_030_pos',\n",
      "       'death_030_day', 'macetrop_pos_or_death_030', 'stent_010_day',\n",
      "       'cabg_010_day', 'stent_or_cabg_010_day', 'ami_day_of', 'days_to_ami',\n",
      "       'maxtrop_sameday', 'tn_group_sameday', 'disch_disp', 'disch_obs',\n",
      "       'test_010_day', 'stress_010_day', 'cath_010_day', 'days_to_stress',\n",
      "       'days_to_cath', 'first_test', 'excl_flag_c_int', 'excl_flag_chronic',\n",
      "       'excl_flag_death', 'exclude_modeling', 'exclude', 'sex', 'race_black',\n",
      "       'race_hispanic', 'race_white', 'race_other', 'agi_under_25k',\n",
      "       'agi_25k_to_50k', 'agi_50k_to_75k', 'agi_75k_to_100k',\n",
      "       'agi_100k_to_200k', 'agi_above_200k', 'ecg_cnt', 'female', 'split'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "pt_version_test = df_test_f.groupby('patient_ngsci_id').first()\n",
    "print(pt_version_test['race_black'].sum())\n",
    "print(df_test_f.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a926aef-5e08-454e-badb-5e17fd6e5f85",
   "metadata": {},
   "source": [
    "## Table 1 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf212b36-5ddf-4b54-a31e-9f4c273c6c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def generate_summary_table(df_train,df_val,df_test):\n",
    "#     summary = pd.DataFrame(columns=[\"All\",\"Train\", \"Val\", \"Test\"]) #\"Untested\"\n",
    "    \n",
    "#     # Count of all emergency visits and patients\n",
    "#     all_visits_train = len(df_train['ed_enc_id'].unique())\n",
    "#     all_patients_train = len(df_train['patient_ngsci_id'].unique())\n",
    "#     all_visits_test = len(df_test['ed_enc_id'].unique())\n",
    "#     all_patients_test = len(df_test['patient_ngsci_id'].unique())\n",
    "    \n",
    "#     # summary.loc[\"All Emergency Visits 2010-2015\", \"All\"] = \"\"\n",
    "#     # summary.loc[\"Visits\", \"All\"] = f\"{all_visits_train + all_visits_test:,}\"\n",
    "#     # summary.loc[\"Patients\", \"All\"] = f\"{all_patients_train + all_patients_test:,}\"\n",
    "    \n",
    "#     # Count of visits, patients, and ECGs available on the platform\n",
    "#     available_visits_train = len(df_train['ed_enc_id'].unique())\n",
    "#     available_patients_train = len(df_train['patient_ngsci_id'].unique())\n",
    "#     available_ecgs_train = len(df_train['ecg_id'].unique())\n",
    "    \n",
    "#     available_visits_test = len(df_test['ed_enc_id'].unique())\n",
    "#     available_patients_test = len(df_test['patient_ngsci_id'].unique())\n",
    "#     available_ecgs_test = len(df_test['ecg_id'].unique())\n",
    "    \n",
    "#     # summary.loc[\"Available on Platform\", \"All\"] = \"\"\n",
    "#     summary.loc[\"Visits\", \"All\"] = f\"{available_visits_train + available_visits_test:,}\"\n",
    "#     summary.loc[\"Patients\", \"All\"] = f\"{available_patients_train + available_patients_test:,}\"\n",
    "#     summary.loc[\"ECGs\", \"All\"] = f\"{available_ecgs_train + available_ecgs_test:,}\"\n",
    "    \n",
    "#     summary.loc[\"Visits\", \"Train\"] = f\"{available_visits_train:,}\"\n",
    "#     summary.loc[\"Patients\", \"Train\"] = f\"{available_patients_train:,}\"\n",
    "#     summary.loc[\"ECGs\", \"Train\"] = f\"{available_ecgs_train:,}\"\n",
    "    \n",
    "#     summary.loc[\"Visits\", \"Test\"] = f\"{available_visits_test:,}\"\n",
    "#     summary.loc[\"Patients\", \"Test\"] = f\"{available_patients_test:,}\"\n",
    "#     summary.loc[\"ECGs\", \"Test\"] = f\"{available_ecgs_test:,}\"\n",
    "    \n",
    "#     # summary.loc[\"Visits\", \"Untested\"] = f\"{all_visits_train - available_visits_train:,}\"\n",
    "#     # summary.loc[\"Patients\", \"Untested\"] = f\"{all_patients_train - available_patients_train:,}\"\n",
    "#     # summary.loc[\"ECGs\", \"Untested\"] = f\"{all_visits_train - available_ecgs_train:,}\"\n",
    "    \n",
    "#     # Demographics\n",
    "#     # Calculate demographics on patient level \n",
    "    \n",
    "#     pt_df_full = df_full.groupby('patient_ngsci_id').first()\n",
    "#     pt_df_train = df_train.groupby('patient_ngsci_id').first()\n",
    "#     pt_df_test = df_test.groupby('patient_ngsci_id').first()\n",
    "    \n",
    "#     age_mean_all = pt_df_full['age_at_admit'].mean()\n",
    "#     age_std_all = pt_df_full['age_at_admit'].std()\n",
    "\n",
    "#     age_mean_train = pt_df_train['age_at_admit'].mean()\n",
    "#     age_std_train = pt_df_train['age_at_admit'].std()\n",
    "    \n",
    "#     age_mean_test = pt_df_test['age_at_admit'].mean()\n",
    "#     age_std_test = pt_df_test['age_at_admit'].std()\n",
    "    \n",
    "#     summary.loc[\"Demographics\", \"All\"] = \"\"#\n",
    "#     summary.loc[\"Demographics\", \"Train\"] = \"\"#\n",
    "#     summary.loc[\"Demographics\", \"Test\"] = \"\"#\n",
    "    \n",
    "#     summary.loc[\"Age Mean (years)\", \"All\"] = f\"{age_mean_all:.2f}\"\n",
    "#     summary.loc[\"Age Std (years)\", \"All\"] = f\"{age_std_all:.2f}\"\n",
    "    \n",
    "#     summary.loc[\"Age Mean (years)\", \"Train\"] = f\"{age_mean_train:.2f}\"\n",
    "#     summary.loc[\"Age Std (years)\", \"Train\"] = f\"{age_std_train:.2f}\"\n",
    "    \n",
    "#     summary.loc[\"Age Mean (years)\", \"Test\"] = f\"{age_mean_test:.2f}\"\n",
    "#     summary.loc[\"Age Std (years)\", \"Test\"] = f\"{age_std_test:.2f}\"\n",
    "    \n",
    "#     # Gender and Race\n",
    "#     female_full = pt_df_full['female'].mean()\n",
    "#     female_train = pt_df_train['female'].mean()\n",
    "#     female_test = pt_df_test['female'].mean()\n",
    "    \n",
    "#     black_full = pt_df_full['race_black'].mean()\n",
    "#     black_train = pt_df_train['race_black'].mean()\n",
    "#     black_test = pt_df_test['race_black'].mean()\n",
    "    \n",
    "#     hispanic_full = pt_df_full['race_hispanic'].mean()\n",
    "#     hispanic_train = pt_df_train['race_hispanic'].mean()\n",
    "#     hispanic_test = pt_df_test['race_hispanic'].mean()\n",
    "    \n",
    "#     white_full = pt_df_full['race_white'].mean()\n",
    "#     white_train = pt_df_train['race_white'].mean()\n",
    "#     white_test = pt_df_test['race_white'].mean()\n",
    "    \n",
    "#     other_full = pt_df_full['race_other'].mean()\n",
    "#     other_train = pt_df_train['race_other'].mean()\n",
    "#     other_test = pt_df_test['race_other'].mean()\n",
    "    \n",
    "#     summary.loc[\"Female\", \"All\"] = f\"{female_full:.3f}\"\n",
    "#     summary.loc[\"Black\", \"All\"] = f\"{black_full:.3f}\"\n",
    "#     summary.loc[\"Hispanic\", \"All\"] = f\"{hispanic_full:.3f}\"\n",
    "#     summary.loc[\"White\", \"All\"] = f\"{white_full:.3f}\"\n",
    "#     summary.loc[\"Other\", \"All\"] = f\"{other_full:.3f}\"\n",
    "    \n",
    "#     summary.loc[\"Female\", \"Train\"] = f\"{female_train:.3f}\"\n",
    "#     summary.loc[\"Black\", \"Train\"] = f\"{black_train:.3f}\"\n",
    "#     summary.loc[\"Hispanic\", \"Train\"] = f\"{hispanic_train:.3f}\"\n",
    "#     summary.loc[\"White\", \"Train\"] = f\"{white_train:.3f}\"\n",
    "#     summary.loc[\"Other\", \"Train\"] = f\"{other_train:.3f}\"\n",
    "    \n",
    "#     summary.loc[\"Female\", \"Test\"] = f\"{female_test:.3f}\"\n",
    "#     summary.loc[\"Black\", \"Test\"] = f\"{black_test:.3f}\"\n",
    "#     summary.loc[\"Hispanic\", \"Test\"] = f\"{hispanic_test:.3f}\"\n",
    "#     summary.loc[\"White\", \"Test\"] = f\"{white_test:.3f}\"\n",
    "#     summary.loc[\"Other\", \"Test\"] = f\"{other_test:.3f}\"\n",
    "    \n",
    "#     # Key Variables (Positive Test and Adverse Event)\n",
    "    \n",
    "#     # adverse_event_full = sum(pt_df_full[pt_df_full['macetrop_030_pos'] == 1]['macetrop_030_pos']) / len(pt_df_full)\n",
    "#     # positive_test_full = sum(pt_df_full[pt_df_full['stent_or_cabg_010_day'] == 1]['stent_or_cabg_010_day']) / len(pt_df_full)\n",
    "    \n",
    "#     adverse_event_full = sum(pt_df_full['macetrop_pos_or_death_030']) / len(pt_df_full)\n",
    "#     positive_test_full = sum(pt_df_full['stent_or_cabg_010_day']) / len(pt_df_full)\n",
    "    \n",
    "#     adverse_event_train = sum(pt_df_train[pt_df_train['macetrop_pos_or_death_030'] == 1]['macetrop_pos_or_death_030']) / len(pt_df_train)\n",
    "#     positive_test_train = sum(pt_df_train[pt_df_train['stent_or_cabg_010_day'] == 1]['stent_or_cabg_010_day']) / len(pt_df_train)\n",
    "    \n",
    "#     adverse_event_test = sum(pt_df_test[pt_df_test['macetrop_pos_or_death_030'] == 1]['macetrop_pos_or_death_030']) / len(pt_df_test)\n",
    "#     positive_test_test = sum(pt_df_test[pt_df_test['stent_or_cabg_010_day'] == 1]['stent_or_cabg_010_day']) / len(pt_df_test)\n",
    "    \n",
    "#     summary.loc[\"Key Variables\", \"All\"] = \"\"\n",
    "#     summary.loc[\"Key Variables\", \"Train\"] = \"\"\n",
    "#     summary.loc[\"Key Variables\", \"Test\"] = \"\"\n",
    "    \n",
    "    \n",
    "#     summary.loc[\"Positive Test\", \"All\"] = f\"{positive_test_full:.4f}\"\n",
    "#     summary.loc[\"Adverse Event\", \"All\"] = f\"{adverse_event_full:.3f}\"\n",
    "    \n",
    "#     summary.loc[\"Positive Test\", \"Train\"] = f\"{positive_test_train:.4f}\"\n",
    "#     summary.loc[\"Adverse Event\", \"Train\"] = f\"{adverse_event_train:.3f}\"\n",
    "    \n",
    "#     summary.loc[\"Positive Test\", \"Test\"] = f\"{positive_test_test:.4f}\"\n",
    "#     summary.loc[\"Adverse Event\", \"Test\"] = f\"{adverse_event_test:.3f}\"\n",
    "    \n",
    "#     return summary\n",
    "\n",
    "# # df_train_full = pd.concat([df_train, df_val], axis=0)\n",
    "# # df_full = pd.concat([df_train, df_val, df_test], axis=0)\n",
    "\n",
    "# # #summary_table = generate_summary_table(df_full,df_train_full,df_test)\n",
    "# # summary_table = generate_summary_table(df_train,df_val,df_test)\n",
    "# # print(summary_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7817546-7a6d-42b7-84d6-62276f11accb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_table(df_train, df_val, df_test):\n",
    "    import pandas as pd\n",
    "\n",
    "    # Combine all datasets\n",
    "    df_full = pd.concat([df_train, df_val, df_test], axis=0)\n",
    "    \n",
    "    # Initialize summary DataFrame\n",
    "    summary = pd.DataFrame(columns=[\"All\", \"Train\", \"Validation\", \"Test\"])\n",
    "    \n",
    "    # Counts of unique visits and patients\n",
    "    visits_train = df_train['ed_enc_id'].nunique()\n",
    "    patients_train = df_train['patient_ngsci_id'].nunique()\n",
    "    ecgs_train = df_train['ecg_id'].nunique()\n",
    "    \n",
    "    visits_val = df_val['ed_enc_id'].nunique()\n",
    "    patients_val = df_val['patient_ngsci_id'].nunique()\n",
    "    ecgs_val = df_val['ecg_id'].nunique()\n",
    "    \n",
    "    visits_test = df_test['ed_enc_id'].nunique()\n",
    "    patients_test = df_test['patient_ngsci_id'].nunique()\n",
    "    ecgs_test = df_test['ecg_id'].nunique()\n",
    "    \n",
    "    # Total counts\n",
    "    total_visits = visits_train + visits_val + visits_test\n",
    "    total_patients = patients_train + patients_val + patients_test\n",
    "    total_ecgs = ecgs_train + ecgs_val + ecgs_test\n",
    "    \n",
    "    # Populate summary table\n",
    "    summary.loc[\"Visits\", \"All\"] = f\"{total_visits:,}\"\n",
    "    summary.loc[\"Patients\", \"All\"] = f\"{total_patients:,}\"\n",
    "    summary.loc[\"ECGs\", \"All\"] = f\"{total_ecgs:,}\"\n",
    "    \n",
    "    summary.loc[\"Visits\", \"Train\"] = f\"{visits_train:,}\"\n",
    "    summary.loc[\"Patients\", \"Train\"] = f\"{patients_train:,}\"\n",
    "    summary.loc[\"ECGs\", \"Train\"] = f\"{ecgs_train:,}\"\n",
    "    \n",
    "    summary.loc[\"Visits\", \"Validation\"] = f\"{visits_val:,}\"\n",
    "    summary.loc[\"Patients\", \"Validation\"] = f\"{patients_val:,}\"\n",
    "    summary.loc[\"ECGs\", \"Validation\"] = f\"{ecgs_val:,}\"\n",
    "    \n",
    "    summary.loc[\"Visits\", \"Test\"] = f\"{visits_test:,}\"\n",
    "    summary.loc[\"Patients\", \"Test\"] = f\"{patients_test:,}\"\n",
    "    summary.loc[\"ECGs\", \"Test\"] = f\"{ecgs_test:,}\"\n",
    "    \n",
    "    # Demographics on patient level\n",
    "    pt_df_full = df_full.groupby('patient_ngsci_id').first()\n",
    "    pt_df_train = df_train.groupby('patient_ngsci_id').first()\n",
    "    pt_df_val = df_val.groupby('patient_ngsci_id').first()\n",
    "    pt_df_test = df_test.groupby('patient_ngsci_id').first()\n",
    "    \n",
    "    # Age statistics\n",
    "    age_mean_all = pt_df_full['age_at_admit'].mean()\n",
    "    age_std_all = pt_df_full['age_at_admit'].std()\n",
    "    \n",
    "    age_mean_train = pt_df_train['age_at_admit'].mean()\n",
    "    age_std_train = pt_df_train['age_at_admit'].std()\n",
    "    \n",
    "    age_mean_val = pt_df_val['age_at_admit'].mean()\n",
    "    age_std_val = pt_df_val['age_at_admit'].std()\n",
    "    \n",
    "    age_mean_test = pt_df_test['age_at_admit'].mean()\n",
    "    age_std_test = pt_df_test['age_at_admit'].std()\n",
    "    \n",
    "    # Add age statistics to summary\n",
    "    summary.loc[\"Demographics\", :] = \"\"\n",
    "    summary.loc[\"Age Mean (years)\", \"All\"] = f\"{age_mean_all:.2f}\"\n",
    "    summary.loc[\"Age Std (years)\", \"All\"] = f\"{age_std_all:.2f}\"\n",
    "    summary.loc[\"Age Mean (years)\", \"Train\"] = f\"{age_mean_train:.2f}\"\n",
    "    summary.loc[\"Age Std (years)\", \"Train\"] = f\"{age_std_train:.2f}\"\n",
    "    summary.loc[\"Age Mean (years)\", \"Validation\"] = f\"{age_mean_val:.2f}\"\n",
    "    summary.loc[\"Age Std (years)\", \"Validation\"] = f\"{age_std_val:.2f}\"\n",
    "    summary.loc[\"Age Mean (years)\", \"Test\"] = f\"{age_mean_test:.2f}\"\n",
    "    summary.loc[\"Age Std (years)\", \"Test\"] = f\"{age_std_test:.2f}\"\n",
    "    \n",
    "    # Gender and Race\n",
    "    def compute_means(df):\n",
    "        return {\n",
    "            'Female': df['female'].mean(),\n",
    "            'Black': df['race_black'].mean(),\n",
    "            'Hispanic': df['race_hispanic'].mean(),\n",
    "            'White': df['race_white'].mean(),\n",
    "            'Other': df['race_other'].mean()\n",
    "        }\n",
    "    \n",
    "    means_all = compute_means(pt_df_full)\n",
    "    means_train = compute_means(pt_df_train)\n",
    "    means_val = compute_means(pt_df_val)\n",
    "    means_test = compute_means(pt_df_test)\n",
    "    \n",
    "    # Add gender and race to summary\n",
    "    for key in means_all.keys():\n",
    "        summary.loc[key, \"All\"] = f\"{means_all[key]:.3f}\"\n",
    "        summary.loc[key, \"Train\"] = f\"{means_train[key]:.3f}\"\n",
    "        summary.loc[key, \"Validation\"] = f\"{means_val[key]:.3f}\"\n",
    "        summary.loc[key, \"Test\"] = f\"{means_test[key]:.3f}\"\n",
    "    \n",
    "    # Key Variables (Positive Test and Adverse Event)\n",
    "    def compute_key_vars(df):\n",
    "        return {\n",
    "            'Positive Test': df['stent_or_cabg_010_day'].mean(),\n",
    "            'Adverse Event': df['macetrop_pos_or_death_030'].mean()\n",
    "        }\n",
    "    \n",
    "    key_vars_all = compute_key_vars(pt_df_full)\n",
    "    key_vars_train = compute_key_vars(pt_df_train)\n",
    "    key_vars_val = compute_key_vars(pt_df_val)\n",
    "    key_vars_test = compute_key_vars(pt_df_test)\n",
    "    \n",
    "    # Add key variables to summary\n",
    "    summary.loc[\"Key Variables\", :] = \"\"\n",
    "    for key in key_vars_all.keys():\n",
    "        summary.loc[key, \"All\"] = f\"{key_vars_all[key]:.4f}\"\n",
    "        summary.loc[key, \"Train\"] = f\"{key_vars_train[key]:.4f}\"\n",
    "        summary.loc[key, \"Validation\"] = f\"{key_vars_val[key]:.4f}\"\n",
    "        summary.loc[key, \"Test\"] = f\"{key_vars_test[key]:.4f}\"\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Usage example\n",
    "# df_full = pd.concat([df_train, df_val, df_test], axis=0)\n",
    "# summary_table = generate_summary_table(df_train, df_val, df_test)\n",
    "# print(summary_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3fea2d2-1032-4654-b1f7-c06c5d00fece",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All</th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Visits</th>\n",
       "      <td>4,609</td>\n",
       "      <td>2,299</td>\n",
       "      <td>924</td>\n",
       "      <td>1,386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patients</th>\n",
       "      <td>3,982</td>\n",
       "      <td>1,991</td>\n",
       "      <td>796</td>\n",
       "      <td>1,195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECGs</th>\n",
       "      <td>8,198</td>\n",
       "      <td>4,081</td>\n",
       "      <td>1,656</td>\n",
       "      <td>2,461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demographics</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age Mean (years)</th>\n",
       "      <td>61.18</td>\n",
       "      <td>60.96</td>\n",
       "      <td>60.85</td>\n",
       "      <td>61.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age Std (years)</th>\n",
       "      <td>14.26</td>\n",
       "      <td>14.41</td>\n",
       "      <td>14.32</td>\n",
       "      <td>13.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>0.466</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black</th>\n",
       "      <td>0.185</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic</th>\n",
       "      <td>0.134</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.609</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.072</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Key Variables</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Test</th>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.1532</td>\n",
       "      <td>0.1721</td>\n",
       "      <td>0.1573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adverse Event</th>\n",
       "      <td>0.2888</td>\n",
       "      <td>0.2868</td>\n",
       "      <td>0.2764</td>\n",
       "      <td>0.3004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     All   Train Validation    Test\n",
       "Visits             4,609   2,299        924   1,386\n",
       "Patients           3,982   1,991        796   1,195\n",
       "ECGs               8,198   4,081      1,656   2,461\n",
       "Demographics                                       \n",
       "Age Mean (years)   61.18   60.96      60.85   61.76\n",
       "Age Std (years)    14.26   14.41      14.32   13.97\n",
       "Female             0.466   0.452      0.465   0.491\n",
       "Black              0.185   0.187      0.196   0.172\n",
       "Hispanic           0.134   0.137      0.127   0.133\n",
       "White              0.609   0.600      0.598   0.633\n",
       "Other              0.072   0.076      0.079   0.062\n",
       "Key Variables                                      \n",
       "Positive Test     0.1582  0.1532     0.1721  0.1573\n",
       "Adverse Event     0.2888  0.2868     0.2764  0.3004"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All</th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Visits</th>\n",
       "      <td>5,533</td>\n",
       "      <td>3,223</td>\n",
       "      <td>924</td>\n",
       "      <td>1,386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patients</th>\n",
       "      <td>4,778</td>\n",
       "      <td>2,787</td>\n",
       "      <td>796</td>\n",
       "      <td>1,195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECGs</th>\n",
       "      <td>9,854</td>\n",
       "      <td>5,737</td>\n",
       "      <td>1,656</td>\n",
       "      <td>2,461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demographics</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age Mean (years)</th>\n",
       "      <td>61.18</td>\n",
       "      <td>60.93</td>\n",
       "      <td>60.85</td>\n",
       "      <td>61.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age Std (years)</th>\n",
       "      <td>14.26</td>\n",
       "      <td>14.38</td>\n",
       "      <td>14.32</td>\n",
       "      <td>13.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>0.466</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black</th>\n",
       "      <td>0.185</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic</th>\n",
       "      <td>0.134</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.609</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.072</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Key Variables</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Test</th>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>0.1721</td>\n",
       "      <td>0.1573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adverse Event</th>\n",
       "      <td>0.2888</td>\n",
       "      <td>0.2838</td>\n",
       "      <td>0.2764</td>\n",
       "      <td>0.3004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     All   Train Validation    Test\n",
       "Visits             5,533   3,223        924   1,386\n",
       "Patients           4,778   2,787        796   1,195\n",
       "ECGs               9,854   5,737      1,656   2,461\n",
       "Demographics                                       \n",
       "Age Mean (years)   61.18   60.93      60.85   61.76\n",
       "Age Std (years)    14.26   14.38      14.32   13.97\n",
       "Female             0.466   0.455      0.465   0.491\n",
       "Black              0.185   0.190      0.196   0.172\n",
       "Hispanic           0.134   0.134      0.127   0.133\n",
       "White              0.609   0.600      0.598   0.633\n",
       "Other              0.072   0.077      0.079   0.062\n",
       "Key Variables                                      \n",
       "Positive Test     0.1582  0.1586     0.1721  0.1573\n",
       "Adverse Event     0.2888  0.2838     0.2764  0.3004"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8198, 80)\n"
     ]
    }
   ],
   "source": [
    "df_train_full_f = pd.concat([df_train_f, df_val_f], axis=0)\n",
    "df_full_f = pd.concat([df_train_f, df_val_f, df_test_f], axis=0)\n",
    "\n",
    "#summary_table = generate_summary_table(df_full_f,df_train_full_f,df_test_f)\n",
    "summary_table = generate_summary_table(df_train_f,df_val_f,df_test_f)\n",
    "display(summary_table)\n",
    "\n",
    "summary_table = generate_summary_table(df_train_full_f,df_val_f,df_test_f)\n",
    "display(summary_table)\n",
    "\n",
    "print(ecg_analysis_df_tested_all.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d9d4a1-1e47-4db4-95c5-5d290bf7a408",
   "metadata": {},
   "source": [
    "### Create filelist and wavforms for untested population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0abb3ecc-9d73-4327-b5d1-c570c0763824",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65194, 79)\n"
     ]
    }
   ],
   "source": [
    "ecg_analysis_df_included_untested = ecg_analysis_df_included[ecg_analysis_df_included['test_010_day']==False]\n",
    "ecg_analysis_df_untested = ecg_analysis_df[ecg_analysis_df['test_010_day']==False]\n",
    "print(ecg_analysis_df_included_untested_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12717a22-ce12-4421-91da-3f32eeaef0f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_458/1559359662.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ecg_analysis_df_included_untested_all['female'] = (ecg_analysis_df_included_untested_all['sex'] == \"Female\").astype(int)\n",
      "/tmp/ipykernel_458/1559359662.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_f['split'] = 'train'\n",
      "/tmp/ipykernel_458/1559359662.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_f['ecg_id'] = df_train_f['ecg_id'].astype(str).apply(lambda x: x + '.npy')\n",
      "/tmp/ipykernel_458/1559359662.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val_f['split'] = 'train'\n",
      "/tmp/ipykernel_458/1559359662.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val_f['ecg_id'] = df_val_f['ecg_id'].astype(str).apply(lambda x: x + '.npy')\n",
      "/tmp/ipykernel_458/1559359662.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_f['split'] = 'valid'\n",
      "/tmp/ipykernel_458/1559359662.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_f['ecg_id'] = df_test_f['ecg_id'].astype(str).apply(lambda x: x + '.npy')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33025\n",
      "['pat0001be15' 'pat0003b0dc' 'pat00071ea7' ... 'patfff73744' 'patfff9b317'\n",
      " 'patfffbbbe2']\n",
      "   patient_ngsci_id             ecg_id                  date p-r-t_axes   \n",
      "3       pat0003b0dc  ecg3906f61865.npy  2110-07-17T13:12:02Z    * 29 51  \\\n",
      "4       pat0003b0dc  ecg6bddcf866d.npy  2110-07-17T13:14:02Z    * 27 47   \n",
      "7       pat00083754  ecgc8d46dc7a3.npy  2114-06-24T17:44:35Z   48 43 39   \n",
      "8       pat00083754  ecgb052bf0ae2.npy  2114-06-24T17:44:35Z   48 43 39   \n",
      "16      pat000d398d  ecgab490959f0.npy  2111-03-16T05:04:59Z   67 76 72   \n",
      "\n",
      "    p_axes  r_axes  t_axes  pr_interval pr_interval_units  qrs_duration  ...   \n",
      "3      NaN    29.0    51.0          NaN                ms            86  ...  \\\n",
      "4      NaN    27.0    47.0          NaN                ms            86  ...   \n",
      "7     48.0    43.0    39.0        162.0                ms            80  ...   \n",
      "8     48.0    43.0    39.0        162.0                ms            80  ...   \n",
      "16    67.0    76.0    72.0        140.0                ms           102  ...   \n",
      "\n",
      "   race_other agi_under_25k  agi_25k_to_50k agi_50k_to_75k  agi_75k_to_100k   \n",
      "3           0      0.227273        0.111219       0.083172         0.069632  \\\n",
      "4           0      0.227273        0.111219       0.083172         0.069632   \n",
      "7           0      0.469675        0.315089       0.120562         0.048817   \n",
      "8           0      0.469675        0.315089       0.120562         0.048817   \n",
      "16          1      0.356511        0.216182       0.141593         0.082174   \n",
      "\n",
      "   agi_100k_to_200k  agi_above_200k ecg_cnt  female  split  \n",
      "3          0.204062        0.304642       1       0  valid  \n",
      "4          0.204062        0.304642       1       0  valid  \n",
      "7          0.038462        0.007396       1       1  valid  \n",
      "8          0.038462        0.007396       1       1  valid  \n",
      "16         0.117573        0.085967       1       0  valid  \n",
      "\n",
      "[5 rows x 81 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_458/1559359662.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_f['split'] = 'train'\n",
      "/tmp/ipykernel_458/1559359662.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_f['ecg_id'] = df_train_f['ecg_id'].astype(str).apply(lambda x: x + '.npy')\n",
      "/tmp/ipykernel_458/1559359662.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val_f['split'] = 'valid'\n",
      "/tmp/ipykernel_458/1559359662.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val_f['ecg_id'] = df_val_f['ecg_id'].astype(str).apply(lambda x: x + '.npy')\n",
      "/tmp/ipykernel_458/1559359662.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_f['split'] = 'test'\n",
      "/tmp/ipykernel_458/1559359662.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_f['ecg_id'] = df_test_f['ecg_id'].astype(str).apply(lambda x: x + '.npy')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   patient_ngsci_id             ecg_id                  date p-r-t_axes   \n",
      "3       pat0003b0dc  ecg3906f61865.npy  2110-07-17T13:12:02Z    * 29 51  \\\n",
      "4       pat0003b0dc  ecg6bddcf866d.npy  2110-07-17T13:14:02Z    * 27 47   \n",
      "7       pat00083754  ecgc8d46dc7a3.npy  2114-06-24T17:44:35Z   48 43 39   \n",
      "8       pat00083754  ecgb052bf0ae2.npy  2114-06-24T17:44:35Z   48 43 39   \n",
      "16      pat000d398d  ecgab490959f0.npy  2111-03-16T05:04:59Z   67 76 72   \n",
      "\n",
      "    p_axes  r_axes  t_axes  pr_interval pr_interval_units  qrs_duration  ...   \n",
      "3      NaN    29.0    51.0          NaN                ms            86  ...  \\\n",
      "4      NaN    27.0    47.0          NaN                ms            86  ...   \n",
      "7     48.0    43.0    39.0        162.0                ms            80  ...   \n",
      "8     48.0    43.0    39.0        162.0                ms            80  ...   \n",
      "16    67.0    76.0    72.0        140.0                ms           102  ...   \n",
      "\n",
      "   race_other agi_under_25k  agi_25k_to_50k agi_50k_to_75k  agi_75k_to_100k   \n",
      "3           0      0.227273        0.111219       0.083172         0.069632  \\\n",
      "4           0      0.227273        0.111219       0.083172         0.069632   \n",
      "7           0      0.469675        0.315089       0.120562         0.048817   \n",
      "8           0      0.469675        0.315089       0.120562         0.048817   \n",
      "16          1      0.356511        0.216182       0.141593         0.082174   \n",
      "\n",
      "   agi_100k_to_200k  agi_above_200k ecg_cnt  female  split  \n",
      "3          0.204062        0.304642       1       0   test  \n",
      "4          0.204062        0.304642       1       0   test  \n",
      "7          0.038462        0.007396       1       1   test  \n",
      "8          0.038462        0.007396       1       1   test  \n",
      "16         0.117573        0.085967       1       0   test  \n",
      "\n",
      "[5 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "# FOR ALL ECG\n",
    "ecg_analysis_df_included_untested_all['female'] = (ecg_analysis_df_included_untested_all['sex'] == \"Female\").astype(int)\n",
    "patient_ids = ecg_analysis_df_included_untested_all.patient_ngsci_id.unique() \n",
    "print(len(patient_ids))\n",
    "#print(ecg_analysis_df_tested.head())\n",
    "print(patient_ids)\n",
    "\n",
    "# Splitting the ids into train (50%) and temp (50%)\n",
    "train_ids, temp_ids = train_test_split(patient_ids, test_size=0.5, random_state=0)\n",
    "\n",
    "# Splitting the temp into val (20% of total) and test (30% of total)\n",
    "val_ids, test_ids = train_test_split(temp_ids, test_size=0.6, random_state=0)\n",
    "\n",
    "#final\n",
    "df_train_f = ecg_analysis_df_included_untested_all[ecg_analysis_df_included_untested_all['patient_ngsci_id'].isin(train_ids)]#[['ecg_id','stent_or_cabg_010_day', 'macetrop_pos_or_death_030', 'has_st_eleva', 'has_twave_inver', 'has_depress', 'ste_std_twi']]\n",
    "df_train_f['split'] = 'train'\n",
    "df_train_f['ecg_id'] = df_train_f['ecg_id'].astype(str).apply(lambda x: x + '.npy')\n",
    "df_val_f = ecg_analysis_df_included_untested_all[ecg_analysis_df_included_untested_all['patient_ngsci_id'].isin(val_ids)]#[['ecg_id','stent_or_cabg_010_day', 'macetrop_pos_or_death_030', 'has_st_eleva', 'has_twave_inver', 'has_depress', 'ste_std_twi']]\n",
    "df_val_f['split'] = 'train'\n",
    "df_val_f['ecg_id'] = df_val_f['ecg_id'].astype(str).apply(lambda x: x + '.npy')\n",
    "df_test_f = ecg_analysis_df_included_untested_all[ecg_analysis_df_included_untested_all['patient_ngsci_id'].isin(test_ids)]#[['ecg_id','stent_or_cabg_010_day', 'macetrop_pos_or_death_030', 'has_st_eleva', 'has_twave_inver', 'has_depress', 'ste_std_twi']]\n",
    "df_test_f['split'] = 'valid'\n",
    "df_test_f['ecg_id'] = df_test_f['ecg_id'].astype(str).apply(lambda x: x + '.npy')\n",
    "print(df_test_f.head())\n",
    "df_all_f = pd.concat([df_train_f, df_val_f, df_test_f])\n",
    "df_train_f.to_csv('train_ids_labels_untested_with_covars_all_final.csv')\n",
    "df_val_f.to_csv('val_ids_labels_untested_with_covars_all_final.csv')\n",
    "df_test_f.to_csv('test_ids_labels_untested_with_covars_all_final.csv')\n",
    "df_all_f.to_csv('all_ids_labels_untested_with_covars_all_final.csv')\n",
    "\n",
    "# Creating 3 versions of the dataframe\n",
    "df_train_f = ecg_analysis_df_included_untested_all[ecg_analysis_df_included_untested_all['patient_ngsci_id'].isin(train_ids)]#[['ecg_id','stent_or_cabg_010_day', 'macetrop_pos_or_death_030', 'has_st_eleva', 'has_twave_inver', 'has_depress', 'ste_std_twi']]\n",
    "df_train_f['split'] = 'train'\n",
    "df_train_f['ecg_id'] = df_train_f['ecg_id'].astype(str).apply(lambda x: x + '.npy')\n",
    "df_val_f = ecg_analysis_df_included_untested_all[ecg_analysis_df_included_untested_all['patient_ngsci_id'].isin(val_ids)]#[['ecg_id','stent_or_cabg_010_day', 'macetrop_pos_or_death_030', 'has_st_eleva', 'has_twave_inver', 'has_depress', 'ste_std_twi']]\n",
    "df_val_f['split'] = 'valid'\n",
    "df_val_f['ecg_id'] = df_val_f['ecg_id'].astype(str).apply(lambda x: x + '.npy')\n",
    "df_test_f = ecg_analysis_df_included_untested_all[ecg_analysis_df_included_untested_all['patient_ngsci_id'].isin(test_ids)]#[['ecg_id','stent_or_cabg_010_day', 'macetrop_pos_or_death_030', 'has_st_eleva', 'has_twave_inver', 'has_depress', 'ste_std_twi']]\n",
    "df_test_f['split'] = 'test'\n",
    "df_test_f['ecg_id'] = df_test_f['ecg_id'].astype(str).apply(lambda x: x + '.npy')\n",
    "print(df_test_f.head())\n",
    "df_all_f = pd.concat([df_train_f, df_val_f, df_test_f])\n",
    "df_train_f.to_csv('train_ids_labels_untested_with_covars_all.csv')\n",
    "df_val_f.to_csv('val_ids_labels_untested_with_covars_all.csv')\n",
    "df_test_f.to_csv('test_ids_labels_untested_with_covars_all.csv')\n",
    "df_all_f.to_csv('all_ids_labels_untested_with_covars_all.csv')\n",
    "\n",
    "\n",
    "# # FOR INCLUDED ECG\n",
    "# ecg_analysis_df_included_untested['female'] = (ecg_analysis_df_included_untested['sex'] == \"Female\").astype(int)\n",
    "\n",
    "# patient_ids = ecg_analysis_df_included_untested.patient_ngsci_id.unique() \n",
    "# print(len(patient_ids))\n",
    "# #print(ecg_analysis_df_tested.head())\n",
    "# print(patient_ids)\n",
    "\n",
    "# # Splitting the ids into train (50%) and temp (50%)\n",
    "# train_ids, temp_ids = train_test_split(patient_ids, test_size=0.5, random_state=0)\n",
    "\n",
    "# # Splitting the temp into val (20% of total) and test (30% of total)\n",
    "# val_ids, test_ids = train_test_split(temp_ids, test_size=0.6, random_state=0)\n",
    "\n",
    "# # Creating 3 versions of the dataframe\n",
    "# df_train = ecg_analysis_df_included_untested[ecg_analysis_df_included_untested['patient_ngsci_id'].isin(train_ids)]#[['ecg_id','stent_or_cabg_010_day', 'macetrop_pos_or_death_030', 'has_st_eleva', 'has_twave_inver', 'has_depress', 'ste_std_twi']]\n",
    "# df_train['split'] = 'train'\n",
    "# df_train['ecg_id'] = df_train['ecg_id'].astype(str).apply(lambda x: x + '.npy')\n",
    "# df_val = ecg_analysis_df_included_untested[ecg_analysis_df_included_untested['patient_ngsci_id'].isin(val_ids)]#[['ecg_id','stent_or_cabg_010_day', 'macetrop_pos_or_death_030', 'has_st_eleva', 'has_twave_inver', 'has_depress', 'ste_std_twi']]\n",
    "# df_val['split'] = 'valid'\n",
    "# df_val['ecg_id'] = df_val['ecg_id'].astype(str).apply(lambda x: x + '.npy')\n",
    "# df_test = ecg_analysis_df_included_untested[ecg_analysis_df_included_untested['patient_ngsci_id'].isin(test_ids)]#[['ecg_id','stent_or_cabg_010_day', 'macetrop_pos_or_death_030', 'has_st_eleva', 'has_twave_inver', 'has_depress', 'ste_std_twi']]\n",
    "# df_test['split'] = 'test'\n",
    "# df_test['ecg_id'] = df_test['ecg_id'].astype(str).apply(lambda x: x + '.npy')\n",
    "# print(df_test.head())\n",
    "# df_all = pd.concat([df_train, df_val, df_test])\n",
    "# df_train.to_csv('train_ids_labels_untested_with_covars.csv')\n",
    "# df_val.to_csv('val_ids_labels_untested_with_covars.csv')\n",
    "# df_test.to_csv('test_ids_labels_untested_with_covars.csv')\n",
    "# df_all.to_csv('all_ids_labels_untested_with_covars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33b80511-ba87-43db-9e8a-8e07f1571bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All</th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Visits</th>\n",
       "      <td>46,549</td>\n",
       "      <td>23,487</td>\n",
       "      <td>9,263</td>\n",
       "      <td>13,799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patients</th>\n",
       "      <td>33,025</td>\n",
       "      <td>16,512</td>\n",
       "      <td>6,605</td>\n",
       "      <td>9,908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECGs</th>\n",
       "      <td>65,194</td>\n",
       "      <td>32,985</td>\n",
       "      <td>13,020</td>\n",
       "      <td>19,189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demographics</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age Mean (years)</th>\n",
       "      <td>52.50</td>\n",
       "      <td>52.53</td>\n",
       "      <td>52.65</td>\n",
       "      <td>52.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age Std (years)</th>\n",
       "      <td>19.67</td>\n",
       "      <td>19.68</td>\n",
       "      <td>19.77</td>\n",
       "      <td>19.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>0.571</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black</th>\n",
       "      <td>0.198</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic</th>\n",
       "      <td>0.152</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.561</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.089</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Key Variables</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Test</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adverse Event</th>\n",
       "      <td>0.0627</td>\n",
       "      <td>0.0632</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     All   Train Validation    Test\n",
       "Visits            46,549  23,487      9,263  13,799\n",
       "Patients          33,025  16,512      6,605   9,908\n",
       "ECGs              65,194  32,985     13,020  19,189\n",
       "Demographics                                       \n",
       "Age Mean (years)   52.50   52.53      52.65   52.33\n",
       "Age Std (years)    19.67   19.68      19.77   19.56\n",
       "Female             0.571   0.569      0.571   0.576\n",
       "Black              0.198   0.197      0.192   0.203\n",
       "Hispanic           0.152   0.153      0.152   0.150\n",
       "White              0.561   0.560      0.566   0.561\n",
       "Other              0.089   0.090      0.089   0.087\n",
       "Key Variables                                      \n",
       "Positive Test     0.0000  0.0000     0.0000  0.0001\n",
       "Adverse Event     0.0627  0.0632     0.0590  0.0645"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All</th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Visits</th>\n",
       "      <td>55,812</td>\n",
       "      <td>32,750</td>\n",
       "      <td>13,799</td>\n",
       "      <td>9,263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patients</th>\n",
       "      <td>39,630</td>\n",
       "      <td>23,117</td>\n",
       "      <td>9,908</td>\n",
       "      <td>6,605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECGs</th>\n",
       "      <td>78,214</td>\n",
       "      <td>46,005</td>\n",
       "      <td>19,189</td>\n",
       "      <td>13,020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demographics</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age Mean (years)</th>\n",
       "      <td>52.50</td>\n",
       "      <td>52.57</td>\n",
       "      <td>52.33</td>\n",
       "      <td>52.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age Std (years)</th>\n",
       "      <td>19.67</td>\n",
       "      <td>19.71</td>\n",
       "      <td>19.56</td>\n",
       "      <td>19.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>0.571</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black</th>\n",
       "      <td>0.198</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic</th>\n",
       "      <td>0.152</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.561</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.089</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Key Variables</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Test</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adverse Event</th>\n",
       "      <td>0.0627</td>\n",
       "      <td>0.0620</td>\n",
       "      <td>0.0645</td>\n",
       "      <td>0.0590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     All   Train Validation    Test\n",
       "Visits            55,812  32,750     13,799   9,263\n",
       "Patients          39,630  23,117      9,908   6,605\n",
       "ECGs              78,214  46,005     19,189  13,020\n",
       "Demographics                                       \n",
       "Age Mean (years)   52.50   52.57      52.33   52.65\n",
       "Age Std (years)    19.67   19.71      19.56   19.77\n",
       "Female             0.571   0.569      0.576   0.571\n",
       "Black              0.198   0.196      0.203   0.192\n",
       "Hispanic           0.152   0.153      0.150   0.152\n",
       "White              0.561   0.561      0.561   0.566\n",
       "Other              0.089   0.090      0.087   0.089\n",
       "Key Variables                                      \n",
       "Positive Test     0.0000  0.0000     0.0001  0.0000\n",
       "Adverse Event     0.0627  0.0620     0.0645  0.0590"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_table = generate_summary_table(df_train_f,df_val_f,df_test_f)\n",
    "display(summary_table)\n",
    "\n",
    "df_train_full_f = pd.concat([df_train_f, df_val_f], axis=0)\n",
    "\n",
    "summary_table = generate_summary_table(df_train_full_f,df_test_f,df_val_f)\n",
    "display(summary_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b5e74dc-8f5c-4aaf-8231-0171badfa8a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65194, 81)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d96a802-b6fe-4c90-b08d-bc7fd2e8bad3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2010"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_test_f['race_black'].sum())\n",
    "\n",
    "pt_version_test = df_test_f.groupby('patient_ngsci_id').first()\n",
    "pt_version_test['race_black'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9adb22d-970e-4104-8804-0781ffd36371",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      All   Train Validation    Test\n",
      "Visits             93,098  46,549     32,750  13,799\n",
      "Patients           66,050  33,025     23,117   9,908\n",
      "ECGs              130,388  65,194     46,005  19,189\n",
      "Demographics                                        \n",
      "Age Mean (years)    52.50   52.50      52.57   52.33\n",
      "Age Std (years)     19.67   19.67      19.71   19.56\n",
      "Female              0.571   0.571      0.569   0.576\n",
      "Black               0.198   0.198      0.196   0.203\n",
      "Hispanic            0.152   0.152      0.153   0.150\n",
      "White               0.561   0.561      0.561   0.561\n",
      "Other               0.089   0.089      0.090   0.087\n",
      "Key Variables                                       \n",
      "Positive Test      0.0000  0.0000     0.0000  0.0001\n",
      "Adverse Event      0.0627  0.0627     0.0620  0.0645\n"
     ]
    }
   ],
   "source": [
    "#get summary table\n",
    "df_train_full = pd.concat([df_train_f, df_val_f], axis=0)\n",
    "df_full = pd.concat([df_train_f, df_val_f, df_test_f], axis=0)\n",
    "\n",
    "summary_table = generate_summary_table(df_full,df_train_full,df_test_f)\n",
    "print(summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ff188a4-5866-4a85-bdf2-ec983508ddb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      All   Train Validation    Test\n",
      "Visits             93,098  46,549     32,750  13,799\n",
      "Patients           66,050  33,025     23,117   9,908\n",
      "ECGs              130,388  65,194     46,005  19,189\n",
      "Demographics                                        \n",
      "Age Mean (years)    52.50   52.50      52.57   52.33\n",
      "Age Std (years)     19.67   19.67      19.71   19.56\n",
      "Female              0.571   0.571      0.569   0.576\n",
      "Black               0.198   0.198      0.196   0.203\n",
      "Hispanic            0.152   0.152      0.153   0.150\n",
      "White               0.561   0.561      0.561   0.561\n",
      "Other               0.089   0.089      0.090   0.087\n",
      "Key Variables                                       \n",
      "Positive Test      0.0000  0.0000     0.0000  0.0001\n",
      "Adverse Event      0.0627  0.0627     0.0620  0.0645\n"
     ]
    }
   ],
   "source": [
    "#get summary table\n",
    "df_train_full_f = pd.concat([df_train_f, df_val_f], axis=0)\n",
    "df_full_f = pd.concat([df_train_f, df_val_f, df_test_f], axis=0)\n",
    "\n",
    "summary_table = generate_summary_table(df_full_f,df_train_full_f,df_test_f)\n",
    "print(summary_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264ebc47-a4e4-4ca7-96b3-50f9535f8e0b",
   "metadata": {},
   "source": [
    "## Off-topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4bfa1d4b-f2cc-4df7-9e27-4d13b5541beb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61680, 80)\n",
      "(9975, 79)\n",
      "(7210, 80)\n"
     ]
    }
   ],
   "source": [
    "###############################################################\n",
    "## Restrict sample to patients that were tested\n",
    "###############################################################\n",
    "print(ecg_analysis_df_included.shape)\n",
    "ecg_analysis_df_included_tested = ecg_analysis_df_included[ecg_analysis_df_included['test_010_day']==True]\n",
    "print(ecg_analysis_df_tested.shape)\n",
    "print(ecg_analysis_df_included_tested.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
